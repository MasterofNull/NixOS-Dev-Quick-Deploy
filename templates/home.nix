# NixOS Quick Deploy - Home Manager Configuration
# Generated by: nixos-quick-deploy.sh vVERSIONPLACEHOLDER
# Template Hash: HASHPLACEHOLDER
# This hash is used to detect when the template changes
# If you edit this file manually, your edits will be preserved
# until the template itself changes (new packages added to script)
#
# Placeholders consumed by lib/config.sh:
#   VERSIONPLACEHOLDER / HASHPLACEHOLDER   → deployment metadata
#   GLF_HOME_DEFINITIONS                   → gaming overlay configuration
#   GPU_MONITORING_PACKAGES                → vendor-specific monitors
#   FLATPAK_MANAGED_PACKAGES               → Flatpak manifest snippet
#   Git user/email configured via programs.git.settings
# Additional placeholders appear throughout for optional services (Gitea, etc.)
# =============================================================================

{ config, pkgs, lib, options, ... }:

let
  # Prefer nix-ai-tools outputs if passed via _module.args; otherwise default to {}.
  nixAiToolsPackages =
    if config ? _module && config._module.args ? nixAiToolsPackages then
      config._module.args.nixAiToolsPackages
    else
      { };
  # Collect available derivations from the external nix-ai-tools flake so the
  # generated configuration gracefully degrades if certain outputs are missing.
  nixAiToolsPackageList =
    let
      candidateNames = [ "default" "nix-ai-tools" ];
    in
    lib.concatMap
      (name:
        lib.optional (lib.hasAttr name nixAiToolsPackages)
          (lib.getAttr name nixAiToolsPackages))
      candidateNames;
  giteaFlatpakAppId = "io.gitea.Gitea";
  giteaFlatpakConfigDir = ".var/app/${giteaFlatpakAppId}/config/gitea";
  giteaFlatpakDataDir = ".var/app/${giteaFlatpakAppId}/data/gitea";
  giteaNativeConfigDir = ".config/gitea";
  giteaNativeDataDir = ".local/share/gitea";
  giteaAiConfigFile = "ai-agents.json";
  # AI services migrated to user-level Podman with vLLM
  # See: ~/.config/ai-optimizer/ for the Podman-based AI stack
  huggingfaceCacheDir = ".cache/huggingface";
  huggingfaceModelId = HUGGINGFACE_MODEL_ID_PLACEHOLDER;
  huggingfaceScoutModelId = HUGGINGFACE_SCOUT_MODEL_ID_PLACEHOLDER;
  huggingfaceTgiEndpoint = HUGGINGFACE_TGI_ENDPOINT_PLACEHOLDER;
  huggingfaceScoutTgiEndpoint = HUGGINGFACE_SCOUT_TGI_ENDPOINT_PLACEHOLDER;
  huggingfaceTgiContainerEndpoint = HUGGINGFACE_TGI_CONTAINER_ENDPOINT_PLACEHOLDER;
  localAiStackEnabled = LOCAL_AI_STACK_ENABLED_PLACEHOLDER;
  # vLLM OpenAI-compatible endpoints (configured in ai-optimizer)
  vllmPrimaryEndpoint = "http://127.0.0.1:8000/v1";  # Primary vLLM instance
  vllmSecondaryEndpoint = "http://127.0.0.1:8001/v1";  # Secondary vLLM instance (if needed)
  ollamaPort = 11434;
  ollamaHost = "http://127.0.0.1:${toString ollamaPort}";
  openWebUiPort = 8081;
  openWebUiUrl = "http://127.0.0.1:${toString openWebUiPort}";
  openWebUiDataDir = ".local/share/open-webui";
  podmanAiStackDataDir = ".local/share/podman-ai-stack";
  podmanAiStackNetworkName = "local-ai";
  podmanAiStackLabelKey = "nixos.quick-deploy.ai-stack";
  podmanAiStackLabelValue = "true";
  podmanAiStackOpenWebUiContainerName = "${podmanAiStackNetworkName}-open-webui";
  podmanEnsureImage = image:
    let
      sanitized = lib.replaceStrings [ "/" ":" "." "@" ] [ "-" "-" "-" "-" ] image;
    in
    pkgs.writeShellScript "ensure-${sanitized}-image" ''
      set -euo pipefail
      if ! ${pkgs.podman}/bin/podman image exists ${lib.escapeShellArg image}; then
        ${pkgs.podman}/bin/podman pull --quiet ${lib.escapeShellArg image}
      fi
    '';
  gitPackage =
    if config ? programs && config.programs ? git && config.programs.git ? package then
      config.programs.git.package
    else
      pkgs.git;
  gitExecutablePath = lib.getExe gitPackage;
  claudeWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/claude-wrapper";
  claudeNodeModulesPath = "${config.home.homeDirectory}/.npm-global/lib/node_modules";
  gptCodexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gpt-codex-wrapper";
  codexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/codex-wrapper";
  openaiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/openai-wrapper";
  gooseAiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gooseai-wrapper";
  nixProfileBinPath = "${config.home.homeDirectory}/.nix-profile/bin";
  nodeExecutablePath = lib.makeBinPath [ pkgs.nodejs_22 ];
  claudePathValue = "${nixProfileBinPath}:${nodeExecutablePath}:/run/current-system/sw/bin:\${env:PATH}";
  aiPathValue = claudePathValue;
  aiNodeModulesPath = claudeNodeModulesPath;
  flathubRemoteName = "flathub";
  flathubRemoteUrl = "https://dl.flathub.org/repo/flathub.flatpakrepo";
  flathubRemoteFallbackUrl = "https://flathub.org/repo/flathub.flatpakrepo";
  # Duplicate desktop entries for COSMIC Settings appear on some releases.
  # Hide upstream variants and publish a single consistent launcher.
  cosmicSettingsDesktopFileNames = [
    "com.system76.CosmicSettings.desktop"
    "org.pop_os.CosmicSettings.desktop"
    "cosmic-settings.desktop"
  ];
  cosmicOnlyShowInEnvironments = [ "COSMIC" ];
  cosmicOnlyShowInValue =
    let
      joined = lib.concatStringsSep ";" cosmicOnlyShowInEnvironments;
    in
    if cosmicOnlyShowInEnvironments == [ ] then "" else "${joined};";
  commonPythonOverrides = import ./python-overrides.nix;
  overridePythonPackages = pkgSet:
    if pkgSet ? overrideScope' then
      pkgSet.overrideScope' (self: super: commonPythonOverrides self super)
    else
      pkgSet;
  pythonOverridesOverlay =
    final: prev:
      (lib.optionalAttrs (prev ? python3Packages) {
        python3Packages = overridePythonPackages prev.python3Packages;
      })
      // (lib.optionalAttrs (prev ? python311Packages) {
        python311Packages = overridePythonPackages prev.python311Packages;
      })
      // (lib.optionalAttrs (prev ? python312Packages) {
        python312Packages = overridePythonPackages prev.python312Packages;
      })
      // (lib.optionalAttrs (prev ? python313Packages) {
        python313Packages = overridePythonPackages prev.python313Packages;
      })
      // (lib.optionalAttrs (prev ? python314Packages) {
        python314Packages = overridePythonPackages prev.python314Packages;
      });
  pythonPreferLatest =
    let
      envPref = builtins.getEnv "PYTHON_PREFER_PY314";
    in
    envPref == "1" || envPref == "true";
  python14CompatibilityMask = [
    # Mask packages currently incompatible with Python 3.14 to avoid build failures.
    "llvmlite"
    "numba"
    "sparse"
    "dask-ml"
    "dask-glm"
  ];
  python14Masked = python14CompatibilityMask != [ ];
  pythonWithFallback =
    let
      python14Available = (pkgs ? python314) && (pkgs ? python314Packages);
    in
    if pythonPreferLatest && python14Available && !python14Masked then pkgs.python314 else pkgs.python313;

  # --------------------------------------------------------------------------
  # GLF (Gaming/Lifestyle Features) defaults. The deployment script injects
  # tuned values during generation, but we fall back to safe placeholders so
  # the template remains evaluatable on its own.
  glfDefaultValues = {
    glfMangoHudPresets = {
      disabled = [ ];
      light = [ ];
      full = [ ];
      desktop = [ ];
      "desktop-hybrid" = [ ];
    };
    glfMangoHudProfile = "disabled";
    glfMangoHudConfigFileContents = "";
    glfMangoHudHasEntries = false;
    glfMangoHudDesktopMode = false;
    glfMangoHudInjectsIntoApps = false;
    glfLutrisWithGtk = pkgs.lutris;
    glfGamingPackages = [ ];
    glfSteamPackage = pkgs.steam;
    glfSteamCompatPackages = [ ];
    glfSystemUtilities = [ ];
  };

  glfOverrideValues =
    let
      overrides = rec {
        @GLF_HOME_DEFINITIONS@
      };
    in overrides;

  # Merge defaults with deploy-time overrides so the template remains
  # evaluatable even when rendered outside the orchestrator (e.g., nix repl).
  glfHomeValues = glfDefaultValues // glfOverrideValues;

  inherit (glfHomeValues)
    glfMangoHudPresets
    glfMangoHudProfile
    glfMangoHudConfigFileContents
    glfMangoHudHasEntries
    glfMangoHudDesktopMode
    glfMangoHudInjectsIntoApps
    glfLutrisWithGtk
    glfGamingPackages
    glfSteamPackage
    glfSteamCompatPackages
    glfSystemUtilities;
  gpuMonitoringPackages =
    # Populated by nixos-quick-deploy.sh to enable vendor-specific GPU monitors.
    with pkgs; @GPU_MONITORING_PACKAGES@;
  nvtopPackagesAttr = if pkgs ? nvtopPackages then pkgs.nvtopPackages else { };
  fallbackNvtopPackages =
    if gpuMonitoringPackages != [ ] then
      [ ]
    else
      (lib.optionals (pkgs ? nvtop) [ pkgs.nvtop ])
      ++ (lib.optionals (nvtopPackagesAttr ? default) [ nvtopPackagesAttr.default ])
      ++ (lib.optionals (nvtopPackagesAttr ? nvidia) [ nvtopPackagesAttr.nvidia ])
      ++ (lib.optionals (nvtopPackagesAttr ? amd) [ nvtopPackagesAttr.amd ])
      ++ (lib.optionals (nvtopPackagesAttr ? intel) [ nvtopPackagesAttr.intel ]);
  # ============================================================================
  # Flatpak Applications (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Edit the list below to tailor the default Flatpak apps.
  # Comment out entries you do not need or append new App IDs.
  # Keep the DEFAULT_FLATPAK_APPS array in nixos-quick-deploy.sh in sync.
  @FLATPAK_MANAGED_PACKAGES@
  flatpakManagedInstallRuntimeInputs = [
    pkgs.coreutils
    pkgs.gawk
    pkgs.gnugrep
    pkgs.gnused
    pkgs.findutils
    pkgs.util-linux
    pkgs.flatpak
    pkgs.ostree
  ];
  flatpakManagedInstallScript =
    let
      packageArgs = lib.concatMapStringsSep " " (appId: lib.escapeShellArg appId) flathubPackages;
    in
    pkgs.writeShellApplication {
      name = "aidb-flatpak-managed-install";
      runtimeInputs = flatpakManagedInstallRuntimeInputs;
      text = ''
        set -euo pipefail

        remote_name=${flathubRemoteName}
        remote_url=${flathubRemoteUrl}
        remote_fallback_url=${flathubRemoteFallbackUrl}
        availability_message=""
        managed_state_marker="$HOME/.local/share/flatpak/.aidb-managed-state"
        flatpak_install_arch=""
        flatpak_arch_args=()

        log() {
          printf '[%s] %s\n' "$(date --iso-8601=seconds)" "$*"
        }

        detect_flatpak_install_arch() {
          local nix_system=""
          if command -v nix >/dev/null 2>&1; then
            nix_system="$(nix eval --raw --expr 'builtins.currentSystem' 2>/dev/null || true)"
            case "$nix_system" in
              x86_64-*) flatpak_install_arch="x86_64" ;;
              aarch64-*) flatpak_install_arch="aarch64" ;;
              armv7l-*|armv7-*) flatpak_install_arch="arm" ;;
            esac
          fi

          if [[ -z "$flatpak_install_arch" ]]; then
            local arch_guess
            arch_guess="$(flatpak --default-arch 2>/dev/null || uname -m)"
            case "$arch_guess" in
              x86_64|amd64) flatpak_install_arch="x86_64" ;;
              aarch64|arm64) flatpak_install_arch="aarch64" ;;
              armv7l|armv7hf|armv8l) flatpak_install_arch="arm" ;;
              *) flatpak_install_arch="$arch_guess" ;;
            esac
          fi

          if [[ -n "$flatpak_install_arch" ]]; then
            flatpak_arch_args=(--arch "$flatpak_install_arch")
            log "Using Flatpak architecture: $flatpak_install_arch"
          fi
        }

        should_retry_without_deltas() {
          local output="$1"
          if [[ -z "$output" ]]; then
            return 1
          fi

          if printf '%s\n' "$output" | grep -Eiq 'repo/deltas|static delta|delta.+failed'; then
            return 0
          fi
          return 1
        }

        run_flatpak_install() {
          local output_var="$1"
          shift
          local -a cmd=("$@")
          local deltas_disabled=0

          while true; do
            local install_output
            if install_output=$("''${cmd[@]}" 2>&1); then
              printf -v "$output_var" '%s' "$install_output"
              return 0
            fi

            local status=$?
            printf -v "$output_var" '%s' "$install_output"

            if [[ $deltas_disabled -eq 0 ]] && should_retry_without_deltas "$install_output"; then
              deltas_disabled=1
              log "  Static delta fetch failed; retrying without deltas..."
              cmd+=(--no-static-deltas)
              continue
            fi

            return $status
          done
        }

        detect_flatpak_install_arch

        backup_legacy_flatpak_configs() {
          local -a targets=(
            "$HOME/.config/flatpak"
            "$HOME/.local/share/flatpak/overrides"
            "$HOME/.local/share/flatpak/remotes.d"
          )
          local backup_root="$HOME/.local/share/flatpak/managed-backups"
          local timestamp
          local performed=false
          local encountered_error=false

          timestamp="$(date +%Y%m%d_%H%M%S)"

          for path in "''${targets[@]}"; do
            if [[ ! -e "$path" && ! -L "$path" ]]; then
              continue
            fi

            if [[ -d "$path" && ! -L "$path" ]]; then
              if [[ -z "$(find "$path" -mindepth 1 -print -quit 2>/dev/null)" ]]; then
                continue
              fi
            fi

            local relative="''${path#"$HOME"/}"
            if [[ "$relative" == "$path" ]]; then
              relative="$(basename "$path")"
            fi

            local relative_dir="''${relative%/*}"
            if [[ "$relative_dir" == "$relative" ]]; then
              relative_dir="."
            fi

            local dest_dir="$backup_root/$timestamp/$relative_dir"
            local dest_path
            dest_path="$dest_dir/$(basename "$path")"

            if mkdir -p "$dest_dir" 2>/dev/null \
              && cp -a "$path" "$dest_path" 2>/dev/null; then
              rm -rf "$path" 2>/dev/null || true
              performed=true
              log "Backed up legacy Flatpak path $path -> $dest_path"
            else
              encountered_error=true
              log "Failed to back up legacy Flatpak path $path" >&2
            fi
          done

          mkdir -p "$HOME/.config/flatpak" 2>/dev/null || true

          if [[ "$performed" == true ]]; then
            log "Legacy Flatpak configuration preserved under $backup_root/$timestamp"
          fi

          if [[ "$encountered_error" == true ]]; then
            return 1
          fi

          return 0
        }

        reset_flatpak_repo_if_corrupted() {
          local repo_dir="$HOME/.local/share/flatpak/repo"
          local repo_config="$repo_dir/config"
          local repo_parent="$HOME/.local/share/flatpak"
          local repair_output=""

          mkdir -p "$repo_parent" 2>/dev/null || true

          # Check if repository is valid and complete
          if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
            return 0
          fi

          # Detect corrupted repository (exists but missing essential directories)
          if [[ -e "$repo_dir" ]]; then
            if [[ ! -f "$repo_config" || ! -d "$repo_dir/objects" ]]; then
              log "Detected corrupted Flatpak repository, removing and reinitializing..." >&2
              rm -rf "$repo_dir" 2>/dev/null || true
            fi
          fi

          if [[ ! -e "$repo_dir" ]]; then
            log "Initializing Flatpak repository under ''${repo_dir#"$HOME"/}"
          fi

          if ! mkdir -p "$repo_dir" 2>/dev/null; then
            log "Unable to recreate $repo_dir" >&2
            return 1
          fi

          # Try ostree initialization first (more reliable for fresh repos)
          if command -v ostree >/dev/null 2>&1; then
            local ostree_output=""
            ostree_output="$(
              ostree --repo="$repo_dir" init --mode=bare-user-only 2>&1
            )"
            local ostree_status=$?

            if [[ -n "$ostree_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line"
              done <<<"$ostree_output"
            fi

            if [[ $ostree_status -eq 0 && -f "$repo_config" ]]; then
              log "Flatpak repository initialized via ostree"
              # Run flatpak repair to finalize the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            fi

            # ostree init failed - manually create essential directory structure
            log "ostree init failed, creating repository structure manually..."

            # Remove any partial initialization and start fresh
            rm -rf "$repo_dir" 2>/dev/null || true
            mkdir -p "$repo_dir" 2>/dev/null || true

            # Create essential directories
            if ! (mkdir -p "$repo_dir/objects" "$repo_dir/tmp" \
                  "$repo_dir/refs/heads" "$repo_dir/refs/remotes" \
                  "$repo_dir/state" 2>/dev/null); then
              log "Failed to create repository directory structure" >&2
              return 1
            fi

            # Create minimal config file for bare-user-only mode
            if ! cat > "$repo_config" 2>/dev/null <<'OSTREE_CONFIG'
[core]
repo_version=1
mode=bare-user-only
OSTREE_CONFIG
            then
              log "Failed to create repository config file" >&2
              return 1
            fi

            # Verify the manual structure was created
            if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
              log "Flatpak repository structure created manually"
              # Run flatpak repair to finalize and validate the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            else
              log "Repository structure verification failed" >&2
              return 1
            fi
          fi

          # Fall back to flatpak repair
          repair_output="$(
            flatpak --user repair 2>&1
          )"
          local repair_status=$?

          if [[ -n "$repair_output" ]]; then
            while IFS= read -r line; do
              log "  ↳ $line"
            done <<<"$repair_output"
          fi

          if [[ $repair_status -ne 0 ]]; then
            log "flatpak repair reported an error while attempting to recover the repository" >&2
          fi

          if [[ -f "$repo_config" ]]; then
            log "Flatpak repository initialized"
            return 0
          fi

          log "Flatpak repository configuration still missing after recovery attempts" >&2
          return 1
        }

        check_app_availability() {
          local app_id="$1"
          local user_output
          local user_status
          local system_output
          local system_status

          availability_message=""

          user_output="$(flatpak --user remote-info "''${flatpak_arch_args[@]}" "$remote_name" "$app_id" 2>&1 || true)"
          user_status=$?
          if [[ $user_status -eq 0 ]]; then
            return 0
          fi

          system_output="$(flatpak remote-info "''${flatpak_arch_args[@]}" "$remote_name" "$app_id" 2>&1 || true)"
          system_status=$?
          if [[ $system_status -eq 0 ]]; then
            return 0
          fi

          availability_message="$user_output"
          if [[ -n "$availability_message" && -n "$system_output" ]]; then
            availability_message+=$'
'
          fi
          availability_message+="$system_output"

          if printf '%s
' "$availability_message" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
            return 3
          fi

          return 1
        }

        ensure_remote() {
          if flatpak --user remotes --columns=name | awk 'NR == 1 && $1 == "Name" { next } { print $1 }' | grep -Fxq "$remote_name"; then
            log "Remote $remote_name already configured"
            return 0
          fi

          local -a remote_sources=()
          remote_sources+=("$remote_url")
          if [[ -n "$remote_fallback_url" && "$remote_fallback_url" != "$remote_url" ]]; then
            remote_sources+=("$remote_fallback_url")
          fi

          log "Adding Flatpak remote $remote_name"

          local source=""
          for source in "''${remote_sources[@]}"; do
            local from_output=""
            if from_output=$(flatpak --user remote-add --if-not-exists --from "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source (--from)"
              return 0
            fi

            if [[ -n "$from_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$from_output"
            fi

            local direct_output=""
            if direct_output=$(flatpak --user remote-add --if-not-exists "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source"
              return 0
            fi

            if [[ -n "$direct_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$direct_output"
            fi
          done

          log "Failed to add remote $remote_name after trying: ''${remote_sources[*]}" >&2
          return 1
        }

        install_app() {
          local app_id="$1"

          if flatpak --user info "$app_id" >/dev/null 2>&1; then
            log "Flatpak $app_id already installed"
            return 0
          fi

          local availability_status=0
          check_app_availability "$app_id"
          availability_status=$?
          if [[ $availability_status -ne 0 ]]; then
            if [[ $availability_status -eq 3 ]]; then
              log "Flatpak $app_id not available on $remote_name for this architecture; skipping"
              if [[ -n "$availability_message" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$availability_message"
              fi
              return 0
            fi

            log "Unable to query metadata for $app_id prior to installation" >&2
            if [[ -n "$availability_message" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$availability_message"
            fi
            return 1
          fi

          local attempt=1
          while (( attempt <= 3 )); do
            local install_output=""
            local -a install_cmd=(flatpak --noninteractive --assumeyes --user install)
            install_cmd+=("''${flatpak_arch_args[@]}")
            install_cmd+=("$remote_name" "$app_id")
            if run_flatpak_install install_output "''${install_cmd[@]}"; then
              log "Installed $app_id"
              return 0
            fi

            if printf '%s
' "$install_output" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
              log "Flatpak $app_id not available on $remote_name; skipping"
              if [[ -n "$install_output" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$install_output"
              fi
              return 0
            fi

            log "Attempt $attempt failed for $app_id" >&2
            if [[ -n "$install_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$install_output"
            fi
            sleep $(( attempt * 2 ))
            (( attempt += 1 ))
          done

          log "Giving up on $app_id after repeated failures" >&2
          return 1
        }

        batch_install_missing_apps() {
          # Accepts the package array as arguments to avoid hard-coding globals.
          local -a source_packages=("$@")
          if [[ ''${#source_packages[@]} -le 1 ]]; then
            return 1
          fi

          local -a to_install=()
          local pkg_id
          for pkg_id in "''${source_packages[@]}"; do
            if flatpak --user info "$pkg_id" >/dev/null 2>&1; then
              continue
            fi
            to_install+=("$pkg_id")
          done

          if [[ ''${#to_install[@]} -le 1 ]]; then
            return 1
          fi

          log "Attempting batch Flatpak install for ''${#to_install[@]} application(s)..."
          local install_output=""
          local -a install_cmd=(flatpak --noninteractive --assumeyes --user install)
          install_cmd+=("''${flatpak_arch_args[@]}")
          install_cmd+=("$remote_name" "''${to_install[@]}")
          if run_flatpak_install install_output "''${install_cmd[@]}"; then
            if [[ -n "$install_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line"
              done <<<"$install_output"
            fi
            return 0
          fi

          if [[ -n "$install_output" ]]; then
            while IFS= read -r line; do
              log "  ↳ $line" >&2
            done <<<"$install_output"
          fi
          return 1
        }

        if [[ -f "$managed_state_marker" ]]; then
          log "Managed Flatpak directories already prepared; skipping legacy backup"
        else
          if backup_legacy_flatpak_configs; then
            touch "$managed_state_marker" 2>/dev/null || true
          fi
        fi

        if ! reset_flatpak_repo_if_corrupted; then
          log "Flatpak repository recovery failed" >&2
          exit 1
        fi

        ensure_remote || exit 1

        # shellcheck disable=SC2206
        packages=( ${packageArgs} )
        if [ ''${#packages[@]} -eq 0 ]; then
          log "No Flatpak packages declared; exiting"
          exit 0
        fi

        batch_install_missing_apps "''${packages[@]}" || true

        failures=0
        for app_id in "''${packages[@]}"; do
          if ! install_app "$app_id"; then
            failures=1
          fi
        done

        flatpak --user update --noninteractive --appstream || log "Appstream refresh failed (continuing)" >&2
        flatpak --user update --noninteractive || log "Flatpak update failed (continuing)" >&2

        exit $failures
      '';
    };
  nixAiHelpScript =
    pkgs.writeShellApplication {
      name = "nix-ai-help";
      text = ''
        set -euo pipefail

        usage() {
          cat <<'USAGE'
Usage: nix-ai-help [topic]

Topics:
  overview        High-level deployment summary and workflow guidance (default)
  flakes          Flake management, updates, and switch best practices
  home-manager    Home Manager integration details and troubleshooting tips
  flatpak         Declarative Flatpak management overview
  security        Hardening reminders tailored to AIDB developer workstations
  options         Discovering module options and documenting overrides
  resources       Curated references for deeper reading
  help            Display this help message
USAGE
        }

        print_overview() {
          cat <<'OVERVIEW'
NixOS Quick Deploy provisions a reproducible AIDB workstation using:
  • A NixOS flake that stitches together system modules and Home Manager
  • Declarative user configuration driven by home-manager from nix-community
  • nix-flatpak to install GUI tooling under ~/.local/share/flatpak declaratively

Recommended workflow:
  1. Track all customisations inside configuration.nix and home.nix
  2. Apply system changes with: sudo nixos-rebuild switch --flake .#HOSTNAME
  3. Update user profiles with: home-manager switch --flake .#USERNAME
  4. Review build plans using nix flake check before activating major upgrades
OVERVIEW
        }

        print_flakes() {
          cat <<'FLAKES'
Flake hygiene tips inspired by https://wiki.nixos.org/wiki/Flakes:
  • Pin channels through the flake inputs block and use follows= for reuse
  • Refresh inputs routinely: nix flake update --commit-lock-file
  • Validate changes locally: nix flake check and nixos-rebuild test --flake
  • For experimental packages, add an overlay or extra input such as nixpkgs-unstable
FLAKES
        }

        print_home_manager() {
          cat <<'HM'
Home Manager integration (https://github.com/nix-community/home-manager):
  • Enable programs via home-manager.users.<name>.imports in the flake outputs
  • Prefer systemd.user.startServices = lib.mkDefault ... to cooperate with sd-switch
  • Inspect generated options: home-manager help or home-manager options
  • Keep home.stateVersion aligned with the target channel before upgrades
HM
        }

        print_flatpak() {
          cat <<'FLATPAK'
Flatpak automation via nix-flatpak (https://github.com/gmodena/nix-flatpak):
  • Packages listed under xdg.portal.enable and xdg.desktopEntries stay in sync
  • The deployment script installs Flatpak apps directly via flathub remote
  • Use flatpak list --user --app to see installed applications
FLATPAK
        }

        print_security() {
          cat <<'SECURITY'
Security checklist (see https://wiki.nixos.org/wiki/Security):
  • Harden shells with pam configuration and consider enabling security.apparmor
  • Audit services enabled by configuration.nix using nixos-rebuild test --flake
  • Rotate secrets in ~/.config/gitea and ~/.config/huggingface regularly
  • Track upstream advisories via https://nixos.org/manual/nixos/stable/#sec-upgrading
SECURITY
        }

        print_options() {
          cat <<'OPTIONS'
Discovering options quickly:
  • nix search nixpkgs <pattern> for package discovery
  • nixos-option <path> --json | jq '.' to inspect live system values
  • home-manager option search '<pattern>' to explore user-level modules
  • Web catalogue: https://search.nixos.org/options?channel=25.05
OPTIONS
        }

        print_resources() {
          cat <<'RESOURCES'
Essential references leveraged by this environment:
  • nix-community/home-manager – authoritative module documentation
  • NixOS manual – https://nixos.org/manual/nixos/stable/
  • Populated examples: github.com/nomadics9/NixOS-Flake and github.com/novoid/nixos-config
  • Declarative desktop apps: github.com/gmodena/nix-flatpak and github.com/fufexan/dotfiles
  • Security hardening: https://wiki.nixos.org/wiki/Security
  • COSMIC-focused setups: github.com/rascal999/maxos
RESOURCES
        }

        if [ "$#" -eq 0 ]; then
          topic="overview"
        else
          topic="$1"
        fi

        case "$topic" in
          overview)
            print_overview
            ;;
          flakes)
            print_flakes
            ;;
          home-manager|homemanager)
            print_home_manager
            ;;
          flatpak)
            print_flatpak
            ;;
          security)
            print_security
            ;;
          options)
            print_options
            ;;
          resources)
            print_resources
            ;;
          help|-h|--help)
            usage
            ;;
          *)
            printf 'Unknown topic: %s\n\n' "$topic" >&2
            usage >&2
            exit 1
            ;;
        esac
      '';
    };
  flatpakManagedInstallScriptExe = lib.getExe flatpakManagedInstallScript;
  pythonAi =
    pythonWithFallback.override {
      packageOverrides = commonPythonOverrides;
    };
  # ========================================================================
  # Python AI/ML Environment
  # ========================================================================
  # Comprehensive Python environment for AI/ML development including:
  # - Deep Learning: PyTorch, TensorFlow with GPU support
  # - Transformers: HuggingFace transformers, tokenizers, datasets
  # - LLM Frameworks: LangChain, LlamaIndex with all integrations
  # - Vector DBs: Chromadb, Qdrant, Pinecone, FAISS
  # - Data Science: NumPy, Pandas, Polars, Scikit-learn
  # - Visualization: Matplotlib, Seaborn, Gradio
  # - Development: JupyterLab, IPython, Black, Ruff, MyPy
  #
  # Optional packages to add if needed:
  # - jupyter-ai              # Jupyter AI chatbot (requires API keys)
  # - keras                   # High-level neural networks API
  # - xgboost                 # Gradient boosting framework
  # - lightgbm                # Light gradient boosting machine
  # - catboost                # Categorical gradient boosting
  # - optuna                  # Hyperparameter optimization
  # - mlflow                  # ML experiment tracking
  # - wandb                   # Weights & Biases tracking
  # - ray                     # Distributed computing framework
  # - streamlit               # Web app framework for ML

  pythonAiEnv =
    pythonAi.withPackages (ps:
      let
        # Core Python packages that should always be available
        base = with ps; [
          pip
          setuptools
          wheel
          # Jupyter and Interactive Development
          jupyterlab
          ipykernel
          ipython
          ipywidgets
          notebook
          # Data Science Core
          pandas
          numpy
          scikit-learn
          matplotlib
          seaborn
          # Code Quality Tools
          black
          ruff
          mypy
          pylint
          # AI/ML Fundamentals
          accelerate
          datasets
          diffusers
          peft
          safetensors
          sentencepiece
          tokenizers
          transformers
          evaluate
          gradio
          # Data Processing (Modern Alternatives)
          polars               # Fast DataFrame library (Rust-based)
          # LLM & AI APIs (Required)
          openai               # OpenAI API client
          anthropic            # Anthropic API client
          # Note: dask often causes build issues, added conditionally below
          # Deep Learning Frameworks (ALL REQUIRED - NOT OPTIONAL)
          torch
          torchaudio
          torchvision
          tensorflow
          bitsandbytes
          # LangChain Ecosystem
          langchain
          langchain-openai
          langchain-community
          langchain-core
          # LlamaIndex Ecosystem
          llama-index
          llama-index-core
          # Vector Databases & Embeddings
          chromadb
          qdrant-client
          pinecone-client
          faiss
          sentence-transformers
          # MCP & Agent Tooling
          litellm
          tiktoken
          fastapi
          uvicorn
          httpx
          aiohttp
          websockets
          pydantic
          typer
          rich
          sqlalchemy
          psycopg2
          asyncpg              # PostgreSQL async driver for AIDB
          redis
          alembic
          # AIDB Additional Requirements
          beautifulsoup4       # Web scraping for federation
          tabulate             # Table formatting
          cryptography         # Ed25519 signatures for Guardian
          inotify-simple       # Linux file watching
          watchdog             # macOS/Windows file watching
          # Specialized AI Tools
          llama-cpp-python
          # Data Processing
          duckdb
          dask
          dask-ml
        ];
      in
        base
    );
  pythonAiInterpreterPath = "${pythonAiEnv}/bin/python3";
  huggingfaceReadme = ''
    Hugging Face configuration lives here.

    - Store your personal access token in the file "token" within this directory (never commit it).
    - CLI caches and credentials are isolated from Git repositories.
    - The hf-model-sync helper will reuse this token and cache when downloading models.
  '';
  openWebUiReadme = ''
    Persistent storage for Open WebUI when launched with the open-webui-run helper.

    - All chat history, uploads, and custom prompts are written here.
    - The helper binds this directory into the container at /app/backend/data.
    - Remove this directory to reset the Open WebUI state safely.
    - When using podman-ai-stack, this path is shared with the Open WebUI container managed by the stack.
  '';
  podmanAiStackReadme = ''
    Podman AI Stack shared storage.

    - ollama/: persistent model cache for the Ollama container.
    - open-webui/: shared chat history for the Open WebUI container.
    - qdrant/: vector database state for embeddings and RAG pipelines.
    - mindsdb/: MindsDB database files for AI-assisted SQL workflows.

    Use the podman-ai-stack helper to manage the lifecycle of the stack.
    The helper orchestrates Home Manager's services.podman quadlets and keeps
    this directory synchronized with container volumes.
  '';
  giteaDomain = "@HOSTNAME@";
  giteaHttpPort = 3000;
  giteaSshPort = 2222;
  giteaRootUrl = "http://${giteaDomain}:${toString giteaHttpPort}/";
  giteaSharedSettings = {
    server = {
      PROTOCOL = "http";
      DOMAIN = giteaDomain;
      HTTP_ADDR = "0.0.0.0";
      HTTP_PORT = giteaHttpPort;
      ROOT_URL = giteaRootUrl;
      STATIC_ROOT_PATH = "%(APP_DATA_PATH)s/public";
      ENABLE_GZIP = true;
      LFS_START_SERVER = true;
      LFS_JWT_SECRET = @GITEA_LFS_JWT_SECRET@;
      DISABLE_SSH = false;
      SSH_DOMAIN = giteaDomain;
      SSH_PORT = giteaSshPort;
      SSH_LISTEN_PORT = giteaSshPort;
      START_SSH_SERVER = true;
      LANDING_PAGE = "explore";
    };
    database = {
      DB_TYPE = "sqlite3";
      PATH = "%(GITEA_WORK_DIR)s/gitea.db";
      LOG_SQL = false;
    };
    repository = {
      ROOT = "%(GITEA_WORK_DIR)s/repositories";
      FORCE_PRIVATE = false;
    };
    packages.ENABLED = true;
    actions = {
      ENABLED = true;
      DEFAULT_ACTIONS_URL = "https://gitea.com";
    };
    indexer = {
      ISSUE_INDEXER_TYPE = "bleve";
      ISSUE_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/issues.bleve";
      REPO_INDEXER_ENABLED = true;
      REPO_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/repos.bleve";
    };
    ui = {
      DEFAULT_THEME = "arc-green";
      THEMES = "arc-green,auto,github";
      DEFAULT_SHOW_FULL_NAME = true;
    };
    service = {
      REGISTER_EMAIL_CONFIRM = false;
      DISABLE_REGISTRATION = false;
      REQUIRE_SIGNIN_VIEW = false;
      ENABLE_NOTIFY_MAIL = false;
    };
    security = {
      INSTALL_LOCK = true;
      PASSWORD_HASH_ALGO = "argon2";
      SECRET_KEY = @GITEA_SECRET_KEY@;
      INTERNAL_TOKEN = @GITEA_INTERNAL_TOKEN@;
    };
    oauth2.JWT_SECRET = @GITEA_JWT_SECRET@;
    log = {
      MODE = "console";
      LEVEL = "info";
    };
    lfs = {
      STORAGE_TYPE = "local";
      PATH = "%(GITEA_WORK_DIR)s/lfs";
    };
  };
  giteaSharedAppIni = lib.generators.toINI { } giteaSharedSettings;
  giteaAiIntegrations = ''
    {
      "agents": [
        {
          "name": "aider-openai",
          "command": [
            "aider",
            "--model",
            "gpt-4o-mini",
            "--repo",
            "%REPO_PATH%",
            "--no-auto-commits"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "AIDER_LOG_DIR": "%HOME%/.local/share/aider/logs"
          },
          "description": "Use aider to provide AI pair-programming suggestions for the current Gitea repository."
        },
        {
          "name": "tea-commit-summarizer",
          "command": [
            "tea",
            "ai",
            "summarize",
            "--repo",
            "%REPO_PATH%",
            "--model",
            "gpt-4o-mini"
          ],
          "environment": {
            "TEA_TOKEN": "ENV[TEA_TOKEN]"
          },
          "description": "Generate commit summaries with the Tea CLI leveraging configured AI providers."
        },
        {
          "name": "gpt-cli-local",
          "command": [
            "%HOME%/.local/bin/gpt-cli",
            "--provider",
            "openai",
            "--model",
            "${huggingfaceModelId}",
            "--base-url",
            "${huggingfaceTgiEndpoint}/v1"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "GPT_CLI_DEFAULT_PROVIDER": "openai"
          },
          "description": "Run ad-hoc completions against the bundled Hugging Face Text Generation Inference endpoint via gpt-cli."
        },
        {
          "name": "podman-ai-stack-status",
          "command": [
            "%HOME%/.local/bin/podman-ai-stack",
            "status"
          ],
          "environment": {},
          "description": "Inspect the health of the local Podman AI stack (Ollama, Open WebUI, Qdrant, MindsDB)."
        },
        {
          "name": "launch-cursor",
          "command": [
            "%HOME%/.local/bin/code-cursor"
          ],
          "environment": {},
          "description": "Open the Cursor IDE configured for local model development sessions."
        }
      ],
      "notes": "Populate the referenced environment variables with the appropriate API tokens to enable AI workflows. The helpers bridge local containers, Cursor, and CLI tooling."
    }
  '';
  obsidianAiReadme = ''
    Obsidian AI integrations bootstrap directory.

    - Run `obsidian-ai-bootstrap` to install the Text Generator and other AI plugins.
    - The helper links plugins to Open WebUI or remote OpenAI-compatible endpoints configured on this system.
    - You can drop additional plugin ZIP files in this directory and rerun the helper to install them declaratively.
  '';
  systemdStartServicesDefault =
    let
      startServicesOption = options.systemd.user.startServices or null;
      allowedEnums =
        let
          rawValues =
            if startServicesOption == null || !(startServicesOption ? type) then
              [ ]
            else if lib.isAttrs startServicesOption.type && startServicesOption.type ? enum then
              startServicesOption.type.enum
            else
              [ ];
          attempt = builtins.tryEval rawValues;
        in
        if attempt.success && lib.isList attempt.value then attempt.value else [ ];
      optionDefault =
        if startServicesOption != null && startServicesOption ? default then
          startServicesOption.default
        else
          null;
      supportsLegacy = lib.elem "legacy" allowedEnums;
      supportsSdSwitch = lib.elem "sd-switch" allowedEnums;
    in
    if supportsLegacy then
      "legacy"
    else if optionDefault != null then
      optionDefault
    else
      # Home Manager 25.05+ removed the legacy activator; defer to sd-switch
      # (true) when it is the only supported backend.
      if supportsSdSwitch then "sd-switch" else true;
in

{
  # Declarative Flatpak management is enabled via nix-flatpak in flake.nix
  # The module is already included in the flake's module list, so no manual import is required here

  nixpkgs = {
    config.allowUnfree = true;
    overlays = [ pythonOverridesOverlay ];
  };

  home.username = "HOMEUSERNAME";
  home.homeDirectory = "HOMEDIR";
  home.stateVersion = "STATEVERSION_PLACEHOLDER";  # Auto-detected from home-manager channel
  programs.home-manager.enable = true;

  # Home Manager 25.05 set startServices=true (sd-switch) and removed the legacy
  # activator. Prefer legacy where still available on older channels; otherwise
  # keep the upstream default to avoid evaluation failures on 25.05/25.11+.
  systemd.user.startServices = lib.mkDefault systemdStartServicesDefault;
  xdg.desktopEntries =
    let
      hiddenCosmicEntry = {
        type = "Application";
        name = "COSMIC Settings";
        exec = "cosmic-settings";
        icon = "cosmic-settings";
        categories = [ "Settings" "System" ];
        noDisplay = true;
        settings =
          lib.optionalAttrs (cosmicOnlyShowInValue != "") {
            OnlyShowIn = cosmicOnlyShowInValue;
          };
      };
    in
    lib.mkMerge [
      (lib.genAttrs cosmicSettingsDesktopFileNames (_: hiddenCosmicEntry))
      {
        "aidb-cosmic-settings" = {
          name = "COSMIC Settings";
          type = "Application";
          exec = "cosmic-settings";
          icon = "cosmic-settings";
          categories = [ "Settings" "System" ];
          startupNotify = true;
          settings =
            lib.optionalAttrs (cosmicOnlyShowInValue != "") {
              OnlyShowIn = cosmicOnlyShowInValue;
            };
        };
        "goose-desktop" = {
          name = "Goose Desktop";
          type = "Application";
          exec = "${pkgs.goose-cli}/bin/goose";
          icon = "applications-engineering";
          categories = [ "Development" "Utility" ];
          terminal = false;
          startupNotify = true;
          comment = "Launch the Goose AI workspace";
        };
      }
    ];
  # ============================================================================
  # Home Packages (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Adjust the lists below to tailor developer tooling.
  # Preflight/runtime critical tools (e.g., podman, jq, curl) should remain enabled.
  home.packages =
    let
      # Fix gpt4all to work with Qt6 6.10+ where GuiPrivate requires explicit find_package
      gpt4all-fixed = pkgs.gpt4all.overrideAttrs (oldAttrs: {
        postPatch = (oldAttrs.postPatch or "") + ''
          # Fix Qt6::GuiPrivate CMake target for Qt 6.10+
          # Qt 6.10 requires explicit find_package for private modules
          sed -i '/find_package(Qt6/a \
find_package(Qt6 COMPONENTS GuiPrivate REQUIRED)' CMakeLists.txt
        '';
      });

      # ALL AI command-line packages are REQUIRED (not optional)
      aiCommandLinePackages = with pkgs; [
        ollama
        gpt4all-fixed  # Fixed for Qt6 6.10+ GuiPrivate compatibility
        llama-cpp
      ];
      # Optional GUI frontends for CLI-first network/security tooling.
      networkGuiPackages =
        lib.optionals (pkgs ? zenmap) [
          pkgs.zenmap             # Graphical frontend for nmap scans
        ];
      optionalDevTools =
        lib.optionals (pkgs ? pnpm) [ pkgs.pnpm ]
        ++ lib.optionals (pkgs ? biome) [ pkgs.biome ]
        ++ lib.optionals (pkgs ? pixi) [ pkgs.pixi ]
        ++ lib.optionals (pkgs ? ast-grep) [ pkgs.ast-grep ]
        ++ lib.optionals (pkgs ? nix-fast-build) [ pkgs.nix-fast-build ]
        ++ lib.optionals (pkgs ? lorri) [ pkgs.lorri ]
        ++ lib.optionals (pkgs ? cachix) [ pkgs.cachix ]
        ++ lib.optionals (pkgs ? distrobox) [ pkgs.distrobox ];

      optionalRustGoAccelerators =
        lib.optionals (pkgs ? sccache) [ pkgs.sccache ]
        ++ lib.optionals (pkgs ? cargo-binstall) [ pkgs.cargo-binstall ]
        ++ lib.optionals (pkgs ? gofumpt) [ pkgs.gofumpt ]
        ++ lib.optionals (pkgs ? staticcheck) [ pkgs.staticcheck ];

      optionalTerminalProductivity =
        lib.optionals (pkgs ? atuin) [ pkgs.atuin ]
        ++ lib.optionals (pkgs ? zellij) [ pkgs.zellij ];

      basePackages =
        [
          nixAiHelpScript
          # Python (REQUIRED for AIDB and AI model tooling)
          pythonAiEnv
        ]
        ++ optionalDevTools
        ++ optionalRustGoAccelerators
        ++ optionalTerminalProductivity
        ++ nixAiToolsPackageList  # Install helper binaries exported by numtide/nix-ai-tools when available
        ++ (with pkgs; [
          # ========================================================================
          # AIDB v4.0 Requirements (CRITICAL - Must be installed)
          # ========================================================================

          podman                  # Container runtime for AIDB
          podman-compose          # Docker-compose compatibility
          podman-tui              # Terminal dashboard for Podman and containers
          sqlite                  # Tier 1 Guardian database
          openssl                 # Cryptographic operations
          bc                      # Basic calculator
          qalculate-qt            # Advanced calculator (replaces Flatpak dependency)
          goose-cli               # Goose AI CLI/Desktop provided declaratively
          inotify-tools           # File watching for Guardian

          # ========================================================================
          # Core NixOS Development Tools
          # ========================================================================

          # Nix tools
          nix-tree                # Visualize Nix dependencies
          nix-index               # Index Nix packages for fast searching
          nix-prefetch-git        # Prefetch git repositories
          nixpkgs-fmt             # Nix code formatter
          alejandra               # Alternative Nix formatter
          statix                  # Linter for Nix
          deadnix                 # Find dead Nix code
          nix-output-monitor      # Better build output
          nix-du                  # Disk usage for Nix store
          nixpkgs-review          # Review nixpkgs PRs
          nix-diff                # Compare Nix derivations

          # ========================================================================
          # Development Tools
          # ========================================================================

          # Version control
          # Note: git installed via programs.git below (prevents collision)
          git-crypt               # Transparent file encryption in git
          tig                     # Text-mode interface for git
          lazygit                 # Terminal UI for git commands
          git-lfs                 # Large file storage (required for Hugging Face repos)

          # Text editors
          # Note: vim installed via programs.vim below (prevents collision)
          neovim                  # Modern Vim fork with async support
          # Note: vscodium installed via programs.vscode below
          code-cursor             # Cursor IDE (AI-powered editor)

          # Web browsers are now installed via Flatpak for better sandboxing:
          # Firefox: "org.mozilla.firefox" in services.flatpak.packages
          # Chromium: Available as "com.google.Chrome" if needed
          # (Both still available in home.packages comments if NixOS versions preferred)

          # Modern CLI tools
          ripgrep                 # Fast recursive grep (rg)
          ripgrep-all             # Ripgrep with PDF, archive support
          fd                      # Fast alternative to find
          deno                    # Secure TypeScript runtime for MCP tooling
          bun                     # High-performance JavaScript runtime
          bubblewrap              # Sandboxing utility for tool execution
          firejail                # Sandbox profiles for desktop/CLI apps
          criu                    # Checkpoint/restore utilities
          postgresql              # PostgreSQL client tools (psql)
          redis                   # Redis CLI tools
          fzf                     # Fuzzy finder for command line
          bat                     # Cat clone with syntax highlighting
          eza                     # Modern replacement for ls
          jq                      # JSON processor
          yq                      # YAML processor
          direnv                  # Automatic per-directory environment loading
          nix-direnv              # Direnv integration with Nix flakes
          choose                  # Human-friendly cut/awk alternative
          dust                    # Intuitive disk usage (du)
          duf                     # Disk usage/free utility (df)
          broot                   # Tree view with navigation
          dog                     # DNS lookup utility (dig)
          shellcheck              # Shell script static analysis
          uv                      # Drop-in replacement for pip

          # Terminal tools
          # Note: alacritty installed via programs.alacritty below (prevents collision)
          tmux                    # Terminal multiplexer
          zellij                  # Modern terminal workspace (Rust alternative to tmux)
          screen                  # Terminal session manager
          mosh                    # Mobile shell (SSH alternative)
          asciinema               # Terminal session recorder

          # File management
          ranger                  # Console file manager with VI bindings
          dos2unix                # Convert text file line endings
          unrar                   # Extract RAR archives
          p7zip                   # 7-Zip file archiver
          file                    # File type identification
          rsync                   # Fast incremental file transfer
          rclone                  # Rsync for cloud storage

          # Network tools
          wget                    # Network downloader
          curl                    # Transfer data with URLs
          netcat-gnu              # Network utility for TCP/UDP
          socat                   # Multipurpose relay (SOcket CAT)
          mtr                     # Network diagnostic tool (traceroute/ping)
          nmap                    # Network exploration and security scanner
          wireshark               # GUI network protocol analyzer (ships tshark CLI)

          # Security & privacy tooling
          clamav                  # Antivirus engine and CLI scanner
          clamtk                  # GTK frontend for ClamAV scanning
          # rkhunter is currently unavailable in nixpkgs; re-enable once restored upstream
          # rkhunter                # Rootkit hunter integrity scanner
          lynis                   # Auditing tool for UNIX-based systems (includes rootkit detection)
          # chkrootkit has been removed from nixpkgs (unmaintained/archived upstream, didn't work on NixOS)
          # Use lynis for comprehensive security auditing including rootkit detection, or aide for file integrity
          aide                    # Advanced Intrusion Detection Environment (file integrity & rootkit detection)
          keepassxc               # Cross-platform password manager (GUI)
          gnupg                   # GNU Privacy Guard for encryption workflows
          seahorse                # GNOME credential manager for GnuPG/SSH
          pinentry-gnome3         # Pinentry dialog compatible with COSMIC/GNOME
          # YubiKey Manager Qt was removed because upstream marked it EOL and nixpkgs flags it insecure.
          # Install `yubikey-manager` (CLI) or `yubioath-flutter` manually if YubiKey support is required.

          # System tools
          htop                    # Interactive process viewer
          btop                    # Resource monitor with modern UI
          gnome-disk-utility # GUI disk manager and formatter
          parted                  # Command-line partitioning utility
          flatpak                 # Flatpak CLI for sandboxed desktop apps
          tree                    # Display directory tree structure
          unzip                   # Extract ZIP archives
          zip                     # Create ZIP archives
          bc                      # Arbitrary precision calculator
          efibootmgr              # Modify EFI Boot Manager variables

          # Observability & monitoring stack
          glances                 # System dashboard with sensor, process, network metrics
          grafana                 # Metrics visualization web UI
          prometheus              # Metrics collection server
          loki                    # Log aggregation backend
          promtail                # Promtail agent for Loki pipelines
          vector                  # Data pipeline for logs and metrics
          cockpit                 # Web-based host management and reporting

          # ========================================================================
          # Programming Languages & Tools
          # ========================================================================


          # Additional languages
          go                      # Go programming language
          rustc                   # Rust compiler
          cargo                   # Rust package manager
          ruby                    # Ruby programming language

          # Development utilities
          gnumake                 # GNU Make build automation
          gcc                     # GNU C/C++ compiler
          nodejs_22               # Node.js JavaScript runtime v22

          # ========================================================================
          # Virtualization & Emulation
          # ========================================================================

          qemu            # Machine emulator and virtualizer
          virtiofsd       # VirtIO filesystem daemon

          # ========================================================================
          # Desktop Environment - Cosmic (Rust-based modern desktop)
          # ========================================================================

          #cosmic-edit             # Cosmic text editor
          #cosmic-files            # Cosmic file manager
          #cosmic-term             # Cosmic terminal

          # ========================================================================
          # ZSH Configuration
          # ========================================================================

          # Note: zsh installed via programs.zsh below (prevents collision)
          zsh-syntax-highlighting # Command syntax highlighting
          #zsh-autosuggestions     # Command suggestions from history
          zsh-completions         # Additional completion definitions
          zsh-powerlevel10k       # Powerlevel10k theme
          grc                     # Generic colorizer for commands
          pay-respects            # Modern replacement for 'fuck'

          # ========================================================================
          # Fonts (Required for Powerlevel10k)
          # ========================================================================

          nerd-fonts.meslo-lg     # MesloLGS Nerd Font (recommended for p10k)
          nerd-fonts.fira-code    # Fira Code Nerd Font with ligatures
          nerd-fonts.jetbrains-mono # JetBrains Mono Nerd Font
          nerd-fonts.hack         # Hack Nerd Font
          font-awesome            # Font Awesome icon font
          powerline-fonts         # Powerline-patched fonts

          # ========================================================================
          # Text Processing
          # ========================================================================

          tldr                    # Simplified man pages
          cht-sh                  # Community cheat sheets
          pandoc                  # Universal document converter

          # ========================================================================
          # AI/ML Development Tools (Code Review Recommendations)
          # ========================================================================

          # Vector Search & Databases
          #meilisearch             # Fast, typo-tolerant search engine (requires service)
          #typesense               # Open-source alternative to Algolia (requires service)
          #weaviate                # Vector search engine with ML models (requires service)

          # ML Ops & Experimentation
          #mlflow                  # ML lifecycle management (use service instead)
          dvc                     # Data version control for ML projects

          # Data Processing & ETL
          #apache-arrow            # Columnar data format (included in Python env)
          duckdb                  # Analytical database (SQL analytics on Parquet)

          # Code Quality for AI Projects
          #bandit                  # Security linter for Python (in Python env)
          #vulture                 # Find dead Python code (in Python env)
          #radon                   # Code complexity metrics (in Python env)

          # API Development & Testing
          httpie                  # Modern HTTP client (better than curl for APIs)
          grpcurl                 # Like curl for gRPC
          k6                      # Load testing tool

          # Documentation & Visualization
          mermaid-cli             # Generate diagrams from markdown
          graphviz                # Graph visualization
          plantuml                # UML diagrams

          # Database Tools
          sqlite-utils            # CLI tool for manipulating SQLite databases
          litecli                 # SQLite CLI with autocomplete
          pgcli                   # PostgreSQL CLI with autocomplete

          # Performance Profiling
          #py-spy                  # Sampling profiler for Python (in Python env)
          hyperfine               # Command-line benchmarking tool

          # Container Security
          trivy                   # Vulnerability scanner for containers
          (pkgs.cosign.overrideAttrs (old: { doCheck = false; }))  # Container signing and verification (tests disabled due to nil pointer issue in test suite)

          # Kubernetes (Optional - for model deployment)
          # Uncomment if deploying ML models to Kubernetes
          #kubectl                 # Kubernetes CLI
          #k9s                     # Kubernetes TUI
          #helm                    # Kubernetes package manager

          # Monitoring & Observability (Enhanced)
          #prometheus-node-exporter  # System metrics (use system service)
          #grafana-agent             # Metrics collector (use system service)

          # ========================================================================
          # Utilities
          # ========================================================================

          mcfly           # Command history search
          navi            # Interactive cheatsheet
          starship        # Shell prompt
          hexedit         # Hex editor
          qrencode        # QR code generator
          age             # Modern encryption tool (for secrets management)
          sops            # Secrets operations (encrypted config files)
        ])
        ++ networkGuiPackages
        ++ fallbackNvtopPackages
        ++ gpuMonitoringPackages;
      aiderPackage =
        if pkgs ? aider-chat then
          [ pkgs.aider-chat ]
        else if pkgs ? aider then
          [ pkgs.aider ]
        else
          [ ];
      giteaDevAiPackages =
        [
          pkgs.gitea               # Native Gitea server and CLI for local development
          pkgs.tea                 # Official Gitea CLI for automation and AI workflows
          # The OpenAI Python SDK is bundled via pythonAiEnv to avoid duplicate store paths.
        ]
        ++ aiderPackage;
    in
    basePackages ++ giteaDevAiPackages ++ aiCommandLinePackages;

  # ========================================================================
  # ZSH Configuration
  # ========================================================================

  programs.zsh = {
    enable = true;
    enableCompletion = true;
    syntaxHighlighting.enable = true;
    #autosuggestions.enable = false;

    history = {
      size = 100000;
      path = "${config.xdg.dataHome}/zsh/history";
    };

    shellAliases = {
      # Basic modern replacements
      ll = "eza -l --icons";
      la = "eza -la --icons";
      lt = "eza --tree --icons";
      cat = "bat";
      du = "dust";
      df = "duf";

      # NixOS specific
      nrs = "sudo nixos-rebuild switch";
      nrt = "sudo nixos-rebuild test";
      nrb = "sudo nixos-rebuild boot";
      hms = "home-manager switch";
      nfu = "nix flake update";
      nfc = "nix flake check";
      nfb = "nix build";
      nfd = "nix develop";

      # Nix development
      nix-dev = "nix develop -c $SHELL";
      nix-search = "nix search nixpkgs";
      nix-shell-pure = "nix-shell --pure";

      # Prefer uv over pip for Python package management
      pip = "uv pip";
      pip3 = "uv pip";

      # Git shortcuts
      gs = "git status";
      ga = "git add";
      gc = "git commit";
      gp = "git push";
      gl = "git pull";
      gd = "git diff";
      gco = "git checkout";
      gb = "git branch";

      # Lazy tools
      lg = "lazygit";
      hf-sync = "hf-model-sync";
      # AI services now managed via ai-optimizer Podman setup
      # Use: cd ~/.config/ai-optimizer && docker-compose up/down
      ai-stack = "podman-ai-stack";
      gpt = "gpt-cli";
      cursor = "code-cursor";
      obsidian-ai = "obsidian-ai-bootstrap";

      # Find shortcuts
      ff = "fd";
      rg = "rg --smart-case";
    };

    # NixOS 25.11+: Use 'initContent' instead of 'initExtra'
    initContent = ''
      # Powerlevel10k First-Run Setup Wizard
      P10K_MARKER="$HOME/.config/p10k/.configured"
      P10K_WIZARD="$HOME/.local/bin/p10k-setup-wizard.sh"

      # Run setup wizard on first shell launch
      if [[ ! -f "$P10K_MARKER" && -f "$P10K_WIZARD" ]]; then
        echo ""
        echo "╔══════════════════════════════════════════════════════╗"
        echo "║  Welcome to your new ZSH setup!                     ║"
        echo "║  Let's configure Powerlevel10k...                   ║"
        echo "╚══════════════════════════════════════════════════════╝"
        echo ""
        "$P10K_WIZARD"
        echo ""
        echo "Please restart your shell to see the changes: exec zsh"
        return
      fi

      # Powerlevel10k instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Load Powerlevel10k theme
      source ${pkgs.zsh-powerlevel10k}/share/zsh-powerlevel10k/powerlevel10k.zsh-theme

      # P10k configuration (dynamic - adapts to user preferences)
      [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh

      # Enhanced command history with mcfly
      if command -v mcfly &> /dev/null; then
        eval "$(mcfly init zsh)"
      fi

      # FZF configuration
      export FZF_DEFAULT_COMMAND='fd --type f --hidden --follow --exclude .git'
      export FZF_CTRL_T_COMMAND="$FZF_DEFAULT_COMMAND"
      export FZF_ALT_C_COMMAND='fd --type d --hidden --follow --exclude .git'

      # Nix-specific environment
      export NIX_PATH=$HOME/.nix-defexpr/channels''${NIX_PATH:+:}$NIX_PATH

      # Better error messages
      export NIXPKGS_ALLOW_UNFREE=1
      '';
  };

  # ========================================================================
  # Cryptography & Secret Management
  # ========================================================================

  programs.gpg = {
    enable = true;
  };

  services.gpg-agent = {
    enable = true;
    # COSMIC relies on GNOME Keyring for SSH agent duties so we keep gpg-agent scoped to GPG only.
    enableSshSupport = false;
    enableExtraSocket = true;
    defaultCacheTtl = 3600;
    defaultCacheTtlSsh = 3600;
    pinentry.package = pkgs.pinentry-gnome3;
  };

  programs.password-store = {
    enable = true;
    package = pkgs.pass;
  };

  services.gnome-keyring = {
    enable = true;
    # Secrets + PKCS#11 back up COSMIC's keyring UI while ssh replaces the vanilla agent we disabled above.
    components = [
      "secrets"
      "ssh"
      "pkcs11"
    ];
  };

  # ========================================================================
  # Git Configuration
  # ========================================================================
  # Using GitHub no-reply email (username@users.noreply.github.com) to:
  # - Protect your privacy (email not exposed in commits)
  # - Comply with GitHub email privacy settings
  # - Prevent push rejections due to GH007 errors

  programs.git = {
    enable = true;
    package = pkgs.git;

    settings =
      {
        init.defaultBranch = "main";
        pull.rebase = false;
        core.editor = "DEFAULTEDITOR";

        alias = {
          st = "status";
          co = "checkout";
          br = "branch";
          ci = "commit";
          unstage = "reset HEAD --";
          last = "log -1 HEAD";
          visual = "log --oneline --graph --decorate --all";
        };
      }
      // GIT_USER_SETTINGS_PLACEHOLDER;
  };

  # ========================================================================
  # Direnv - Automatic Development Environment Loading
  # ========================================================================
  # direnv automatically loads and unloads environment variables when entering
  # and leaving project directories. Combined with nix-direnv, it provides:
  # - Automatic activation of nix shells when cd'ing into projects
  # - Persistent dev shells (prevents garbage collection)
  # - Integration with VSCode and other editors
  # - No need to manually run 'nix develop' every time
  #
  # Usage: Add .envrc to your project with:
  #   use flake
  # Then run: direnv allow

  programs.direnv = {
    enable = true;
    nix-direnv.enable = true;

    # Silent mode - reduce terminal output noise
    enableBashIntegration = true;
    enableZshIntegration = true;

    # Configuration
    config = {
      global = {
        # Warn if direnv takes longer than 5 seconds to load
        warn_timeout = "5s";
      };
    };
  };

  # ========================================================================
  # Zellij - Modern Terminal Workspace
  # ========================================================================
  # Zellij is a modern terminal multiplexer (alternative to tmux) with:
  # - Floating panes and intuitive UI
  # - Client-server architecture (reconnect to sessions)
  # - Visual hints and discoverable keybindings
  # - Written in Rust for performance
  #
  # Usage:
  #   zellij           # Start new session
  #   zellij attach    # Reconnect to last session
  #   zellij ls        # List sessions
  #
  # Default keybindings (after Ctrl+g):
  #   Ctrl+g → p   # Panes mode (split, move, etc.)
  #   Ctrl+g → t   # Tabs mode
  #   Ctrl+g → s   # Scroll mode
  #   Ctrl+g → q   # Quit

  programs.zellij = {
    enable = true;

    # Configuration
    settings = {
      # Theme
      theme = "default";

      # Simplified mode (fewer modes for easier learning)
      simplified_ui = false;

      # Pane frames (borders around panes)
      pane_frames = true;

      # Default shell
      default_shell = "zsh";

      # Mouse support
      mouse_mode = true;

      # Copy on select
      copy_on_select = true;

      # Session serialization (save session layout)
      session_serialization = true;

      # Scroll buffer size (lines)
      scroll_buffer_size = 10000;
    };
  };

  # ========================================================================
  # Vim Configuration (minimal)
  # ========================================================================

  programs.vim = {
    enable = true;
    defaultEditor = false;  # Use DEFAULTEDITOR instead

    settings = {
      number = true;
      relativenumber = true;
      expandtab = true;
      tabstop = 2;
      shiftwidth = 2;
    };
  };

  # ========================================================================
  # VSCodium Configuration (Declarative)
  # ========================================================================

  programs.vscode = {
    enable = true;
    package = pkgs.vscodium;

    # NixOS 25.11: Use profiles.default for extensions and settings
    profiles.default = {
      # Extensions installed declaratively
      extensions =
        let
          fetchExtension = name:
            let
              path = lib.splitString "." name;
            in
              if lib.hasAttrByPath path pkgs.vscode-extensions then
                lib.getAttrFromPath path pkgs.vscode-extensions
              else
                null;
          extensionNames = [
            "jnoortheen.nix-ide"
            "arrterian.nix-env-selector"
            "eamodio.gitlens"
            "editorconfig.editorconfig"
            "esbenp.prettier-vscode"
            "ms-python.python"
            "ms-python.black-formatter"
            "ms-python.vscode-pylance"
            "ms-toolsai.jupyter"
            "ms-toolsai.jupyter-keymap"
            "ms-toolsai.jupyter-renderers"
            # AI coding assistants (locally hosted capable)
            "continue.continue"
            "codeium.codeium"
          ];
          curated = lib.filter (pkg: pkg != null) (map fetchExtension extensionNames);
          marketplaceExtensionNames = [
            # Keep Claude Code available; remove deprecated Codex/ChatGPT entries
            "Anthropic.claude-code"
            "Google.gemini-code-assist"
          ];
          fetchMarketplaceExtension = name:
            let
              path = lib.splitString "." name;
            in
              if pkgs ? vscode-marketplace && lib.hasAttrByPath path pkgs.vscode-marketplace then
                lib.getAttrFromPath path pkgs.vscode-marketplace
              else
                null;
          marketplaceExtensions = lib.filter (pkg: pkg != null) (map fetchMarketplaceExtension marketplaceExtensionNames);
        in
          curated ++ marketplaceExtensions;

      # VSCodium settings (declarative)
      # Note: Claude Code paths will be added by bash script (dynamic)
      userSettings = {
      # Editor Configuration
      "editor.fontSize" = 14;
      "editor.fontFamily" = "'Fira Code', 'Droid Sans Mono', 'monospace'";
      "editor.fontLigatures" = true;
      "editor.formatOnSave" = true;
      "editor.formatOnPaste" = true;
      "editor.tabSize" = 2;
      "editor.insertSpaces" = true;
      "editor.detectIndentation" = true;
      "editor.minimap.enabled" = true;
      "editor.bracketPairColorization.enabled" = true;
      "editor.guides.bracketPairs" = true;

      # Nix-specific settings
      "nix.enableLanguageServer" = true;
      "nix.serverPath" = "nil";
      "nix.formatterPath" = "nixpkgs-fmt";
      "[nix]" = {
        "editor.defaultFormatter" = "jnoortheen.nix-ide";
        "editor.tabSize" = 2;
      };

      # Python & Jupyter integration
      "python.defaultInterpreterPath" = pythonAiInterpreterPath;
      "python.terminal.activateEnvironment" = true;
      "python.languageServer" = "Pylance";
      "python.analysis.typeCheckingMode" = "basic";
      "python.analysis.autoImportCompletions" = true;
      "python.formatting.provider" = "black";
      "python.testing.pytestEnabled" = true;
      "python.testing.unittestEnabled" = false;
      "python.dataScience.jupyterServerURI" = "local";
      "jupyter.askForKernelRestart" = false;
      "jupyter.jupyterServerType" = "local";
      "jupyter.notebookFileRoot" = "${config.home.homeDirectory}";
      "[python]" = {
        "editor.defaultFormatter" = "ms-python.black-formatter";
        "editor.formatOnSave" = true;
      };
      "[jupyter]" = {
        "editor.defaultFormatter" = "ms-toolsai.jupyter";
      };

      # Local AI endpoints
      "huggingface.endpoint" = "${huggingfaceTgiEndpoint}";
      "huggingface.defaultModel" = "${huggingfaceModelId}";
      "huggingface.telemetry.enableTelemetry" = false;
      "continue.defaultModel" = "Llama 4 Scout (TGI-8085)";
      "continue.enableTelemetry" = false;
      "continue.telemetryEnabled" = false;
      "continue.serverUrl" = "${openWebUiUrl}";
      "continue.models" = [
        {
          title = "Llama 3.2 Instruct";
          provider = "ollama";
          model = "llama3.2";
          baseUrl = ollamaHost;
        }
        {
          title = "DeepSeek R1 Distill 7B (coding)";
          provider = "openai";
          model = huggingfaceModelId;
          baseUrl = "${huggingfaceTgiEndpoint}/v1";
        }
        {
          title = "Llama 4 Scout 17B";
          provider = "openai";
          model = huggingfaceScoutModelId;
          baseUrl = "${huggingfaceScoutTgiEndpoint}/v1";
        }
        {
          title = "Phi-4 (Ollama)";
          provider = "ollama";
          model = "phi4";
          baseUrl = ollamaHost;
        }
      ];
      "codeium.enableTelemetry" = false;
      "chatgpt.gpt3.apiBaseUrl" = "${huggingfaceTgiEndpoint}/v1";
      "chatgpt.gpt3.model" = "${huggingfaceModelId}";
      "chatgpt.response.showNotification" = false;

      # Git configuration
      "git.path" = gitExecutablePath;
      "git.enableSmartCommit" = true;
      "git.autofetch" = true;
      "gitlens.codeLens.enabled" = true;

      # Terminal
      "terminal.integrated.defaultProfile.linux" = "zsh";
      "terminal.integrated.fontSize" = 13;
      "terminal.integrated.env.linux" = {
        "OPENAI_API_BASE" = "${huggingfaceTgiEndpoint}/v1";
        "OLLAMA_HOST" = ollamaHost;
        "GPT_CLI_BASE_URL" = "${huggingfaceTgiEndpoint}/v1";
      };

      # Claude Code integration (managed declaratively so the wrapper path is always correct)
      "claudeCode.executablePath" = claudeWrapperPath;
      "claudeCode.claudeProcessWrapper" = claudeWrapperPath;
      "claudeCode.environmentVariables" = [
        {
          name = "PATH";
          value = claudePathValue;
        }
        {
          name = "NODE_PATH";
          value = claudeNodeModulesPath;
        }
      ];
      "claudeCode.autoStart" = false;

      # Additional AI CLI wrappers (single config per tool, no duplicates)
      "codex.executablePath" = codexWrapperPath;
      "codex.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "codex.autoStart" = false;

      "openai.executablePath" = openaiWrapperPath;
      "openai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "openai.autoStart" = false;

      "gooseai.executablePath" = gooseAiWrapperPath;
      "gooseai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "gooseai.autoStart" = false;

      # Theme
      "workbench.colorTheme" = "Default Dark Modern";

      # File associations
      "files.associations" = {
        "*.nix" = "nix";
        "flake.lock" = "json";
      };

      # Miscellaneous
      "files.autoSave" = "afterDelay";
      "files.autoSaveDelay" = 1000;
      "explorer.confirmDelete" = false;
      "explorer.confirmDragAndDrop" = false;
      };
    };
  };

  home.activation.vscodiumPersistSettings =
    lib.hm.dag.entryBefore [ "linkGeneration" ] ''
      set -eu

      settings="$HOME/.config/VSCodium/User/settings.json"
      rm -f "$settings.hm-bak" 2>/dev/null || true
      backup_dir="$HOME/.local/share/nixos-quick-deploy/state/vscodium"
      backup="$backup_dir/settings.json"

      if [ -f "$settings" ] && [ ! -L "$settings" ]; then
        mkdir -p "$backup_dir"
        cp "$settings" "$backup" 2>/dev/null || true
      fi
    '';

  home.activation.vscodiumMakeSettingsMutable =
    lib.hm.dag.entryAfter [ "reloadSystemd" ] ''
      set -eu

      settings="$HOME/.config/VSCodium/User/settings.json"
      settings_dir="$(dirname "$settings")"
      backup_dir="$HOME/.local/share/nixos-quick-deploy/state/vscodium"
      backup="$backup_dir/settings.json"
      mkdir -p "$settings_dir"

      restore_from_backup() {
        if [ -f "$backup" ]; then
          cp "$backup" "$settings" 2>/dev/null
          return 0
        fi
        return 1
      }

      if [ -L "$settings" ]; then
        target="$(readlink -f "$settings" 2>/dev/null || true)"
        rm -f "$settings"
        if ! restore_from_backup; then
          case "$target" in
            /nix/store/*)
              if [ -n "$target" ] && [ -f "$target" ]; then
                cp "$target" "$settings" 2>/dev/null || printf '{}' >"$settings"
              else
                printf '{}' >"$settings"
              fi
              ;;
            *)
              printf '{}' >"$settings"
              ;;
          esac
        fi
      elif [ ! -e "$settings" ]; then
        restore_from_backup || printf '{}' >"$settings"
      fi

      if [ -f "$settings" ]; then
        chmod u+rw "$settings" 2>/dev/null || true
        mkdir -p "$backup_dir"
        cp "$settings" "$backup" 2>/dev/null || true
      fi
    '';

  # Remove legacy flatpak-managed-install artifacts so systemd no longer reports
  # a degraded user session after the service was retired.
  home.activation.cleanupFlatpakManagedArtifacts =
    lib.hm.dag.entryBefore [ "reloadSystemd" ] ''
      set -eu

      flag_file="$${XDG_RUNTIME_DIR:-/run/user/$$(id -u)}/allow-flatpak-managed-install"
      service_dir="$HOME/.config/systemd/user"
      unit_path="$service_dir/flatpak-managed-install.service"

      remove_path() {
        local target="$1"
        if [ -z "$target" ]; then
          return 0
        fi
        if [ -L "$target" ] || [ -e "$target" ]; then
          rm -f "$target" 2>/dev/null || true
        fi
      }

      remove_path "$flag_file"
      remove_path "$unit_path"

      for wants in \
        "$service_dir/default.target.wants/flatpak-managed-install.service" \
        "$service_dir/graphical-session.target.wants/flatpak-managed-install.service" \
        "$service_dir/multi-user.target.wants/flatpak-managed-install.service"
      do
        remove_path "$wants"
      done

      if command -v systemctl >/dev/null 2>&1; then
        systemctl --user reset-failed flatpak-managed-install.service >/dev/null 2>&1 || true
      fi
    '';
  home.activation.ensurePodmanAiStackDirs =
    lib.hm.dag.entryBefore [ "writeBoundary" ] ''
      set -eu
      data_root="$HOME/${podmanAiStackDataDir}"
      required_paths="
        $data_root
        $data_root/ollama
        $data_root/open-webui
        $data_root/qdrant
        $data_root/mindsdb
      "

      for path in $required_paths; do
        if [ -L "$path" ] || { [ -e "$path" ] && [ ! -d "$path" ]; }; then
          rm -f "$path" 2>/dev/null || true
        fi
        mkdir -p "$path"
      done
    '';

  # ========================================================================
  # Alacritty Terminal Configuration
  # ========================================================================

  programs.alacritty = {
    enable = true;
    settings = {
      window = {
        opacity = 0.95;
        padding = {
          x = 10;
          y = 10;
        };
      };
      font = {
        size = 11.0;
        normal = {
          family = "MesloLGS NF";
        };
      };
      colors = {
        primary = {
          background = "0x1e1e1e";
          foreground = "0xd4d4d4";
        };
      };
    };
  };

  # ========================================================================
  # Session Variables
  # ========================================================================

  home.sessionVariables =
    {
      EDITOR = "DEFAULTEDITOR";
      VISUAL = "DEFAULTEDITOR";
      NIXPKGS_ALLOW_UNFREE = "1";
      MANGOHUD = if glfMangoHudInjectsIntoApps then "1" else "0";
      MANGOHUD_CONFIGFILE = "${config.home.homeDirectory}/.config/MangoHud/MangoHud.conf";
      MANGOHUD_DESKTOP_MODE = if glfMangoHudDesktopMode then "1" else "0";
      # NPM Configuration
      NPM_CONFIG_PREFIX = "$HOME/.npm-global";
      # AI Development Tools
      AIDER_DEFAULT_MODEL = "gpt-4o-mini";
      AIDER_LOG_DIR = "$HOME/.local/share/aider/logs";
      TEA_AI_MODEL = "gpt-4o-mini";
      # Hugging Face Configuration
      HF_HOME = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_HUB_CACHE = "$HOME/${huggingfaceCacheDir}";
      TRANSFORMERS_CACHE = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_TGI_ENDPOINT = "${huggingfaceTgiEndpoint}";
      HUGGINGFACE_SCOUT_TGI_ENDPOINT = "${huggingfaceScoutTgiEndpoint}";
      HUGGINGFACE_MODEL_ID = "${huggingfaceModelId}";
      HUGGINGFACE_SCOUT_MODEL_ID = "${huggingfaceScoutModelId}";
      HUGGINGFACE_TOKEN_PATH = "$HOME/.config/huggingface/token";
      HF_HUB_ENABLE_HF_TRANSFER = "1";
      # LLM Service Endpoints
      OLLAMA_HOST = "${ollamaHost}";
      OPEN_WEBUI_URL = "${openWebUiUrl}";
      GPT_CLI_DEFAULT_MODEL = "${huggingfaceModelId}";
      GPT_CLI_DEFAULT_PROVIDER = "openai";
      GPT_CLI_BASE_URL = "${huggingfaceTgiEndpoint}/v1";
      # Podman AI Stack
      PODMAN_AI_STACK_NETWORK = "local-ai";
      PODMAN_AI_STACK_DATA_ROOT = "$HOME/${podmanAiStackDataDir}";
      # Security & Credentials
      GNUPGHOME = "${config.home.homeDirectory}/.gnupg";
      PASSWORD_STORE_DIR = "${config.home.homeDirectory}/.local/share/password-store";
      # Ensure COSMIC sessions find the GNOME Keyring sockets started via systemd --user.
      GNOME_KEYRING_CONTROL = "$XDG_RUNTIME_DIR/keyring";
      SSH_AUTH_SOCK = "$XDG_RUNTIME_DIR/keyring/ssh";
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      GITEA_WORK_DIR = "$HOME/${giteaFlatpakDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaFlatpakConfigDir}";
    }
    // lib.optionalAttrs (!config.services.flatpak.enable) {
      GITEA_WORK_DIR = "$HOME/${giteaNativeDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaNativeConfigDir}";
    };

  # Note: Podman rootless storage configuration is handled within the
  # services.podman block below (line ~3312) to avoid duplicate attribute errors.
  # Previous placeholder-based injection was removed to prevent conflicts.

  # ========================================================================
  # Session Path
  # ========================================================================
  # Ensure critical directories are in PATH for all shells and desktop sessions
  # This fixes issues where home-manager, claude-wrapper, and custom scripts
  # are not accessible after login or in new terminal sessions

  home.sessionPath = [
    "$HOME/.local/bin"           # Custom user scripts and wrappers
    "$HOME/.npm-global/bin"      # NPM global packages (claude-wrapper, etc.)
  ];

  # ========================================================================
  # Home Files
  # ========================================================================

  home.file =
    {
    # Remove legacy flatpak-managed-install units and symlinks managed by older
    # releases so systemd stops referencing the retired service.
    ".config/systemd/user/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/default.target.wants/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/graphical-session.target.wants/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/multi-user.target.wants/flatpak-managed-install.service".enable = false;

    # Create local bin directory
    ".local/bin/.keep".text = "";

    # Declarative VSCodium wrapper so the Claude CLI stays on PATH
    ".local/bin/codium-wrapped" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        export NPM_CONFIG_PREFIX="$HOME/.npm-global"
        export PATH="$HOME/.npm-global/bin:$HOME/.local/bin:$PATH"

        exec codium "$@"
      '';
      executable = true;
    };

    # P10k Setup Wizard
    ".local/bin/p10k-setup-wizard.sh" = {
      source = ./p10k-setup-wizard.sh;
      executable = true;
    };

    # Launcher for the Gitea editor that prefers Flatpak but falls back to native binaries
    ".local/bin/gitea-editor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ${giteaFlatpakAppId} >/dev/null 2>&1; then
          exec flatpak run ${giteaFlatpakAppId} "$@"
        elif command -v gitea >/dev/null 2>&1; then
          exec gitea "$@"
        elif command -v tea >/dev/null 2>&1; then
          exec tea "$@"
        else
          echo "error: gitea editor is not installed. Install via Flatpak or enable the native package." >&2
          exit 127
        fi
      '';
      executable = true;
    };

    # Helper to bridge local repositories with aider for AI-driven workflows
    ".local/bin/gitea-ai-assistant" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        usage() {
          echo "Usage: gitea-ai-assistant <repository-path> [-- <aider-args>...]" >&2
          exit 1
        }

        if [[ $# -lt 1 ]]; then
          usage
        fi

        repo_path="$1"
        shift

        if [[ "$repo_path" == "--" ]]; then
          usage
        fi

        if [[ ! -d "$repo_path/.git" ]]; then
          echo "error: $repo_path is not a git repository" >&2
          exit 2
        fi

        repo_path="$(realpath "$repo_path")"

        if [[ $# -gt 0 && "$1" == "--" ]]; then
          shift
        fi

        log_dir="$AIDER_LOG_DIR"
        if [[ -z "$log_dir" ]]; then
          log_dir="$HOME/.local/share/aider/logs"
        fi
        mkdir -p "$log_dir"

        model="$AIDER_DEFAULT_MODEL"
        if [[ -z "$model" ]]; then
          model="gpt-4o-mini"
        fi

        exec aider --model "$model" --repo "$repo_path" "$@"
      '';
      executable = true;
    };

    ".config/openskills/install.sh" = {
      text = ''
        #!/usr/bin/env bash
        #
        # OpenSkills automation hook – append the commands that install your project-specific tools here.
        #
        set -euo pipefail

        echo "OpenSkills custom tooling hook – no actions defined."
      '';
      executable = true;
    };

    # NPM Configuration
    ".npmrc".text = ''
      prefix=''${HOME}/.npm-global
    '';

    # Git configuration template
    # Note: Set your name and email with:
    #   git config --global user.name "Your Name"
    #   git config --global user.email "you@example.com"
    ".gitconfig".text = ''
      [user]
      	# TODO: Set your name and email then run this command in the terminal: home-manager switch -b backup --flake ~/.dotfiles/home-manager
      	# name = Your Name
      	# email = you@example.com

      [init]
      	defaultBranch = main

      [pull]
      	rebase = false

      [core]
      	editor = ${if (config.home.sessionVariables.EDITOR or "") != "" then config.home.sessionVariables.EDITOR else "vim"}

      [alias]
      	st = status
      	co = checkout
      	br = branch
      	ci = commit
      	unstage = reset HEAD --
      	last = log -1 HEAD
      	visual = log --oneline --graph --decorate --all
    '';

    # Hugging Face configuration and cache keepers
    ".config/MangoHud/.keep".text = "";
    ".config/MangoHud/MangoHud.conf".text =
      if glfMangoHudConfigFileContents != "" then
        glfMangoHudConfigFileContents
      else
        "";
    ".config/huggingface/.keep".text = "";
    ".config/huggingface/README".text = huggingfaceReadme;
    "${huggingfaceCacheDir}/.keep".text = "";
    "${openWebUiDataDir}/.keep".text = "";
    "${openWebUiDataDir}/README".text = openWebUiReadme;
    "${podmanAiStackDataDir}/.keep".text = "";
    "${podmanAiStackDataDir}/README".text = podmanAiStackReadme;
    "${podmanAiStackDataDir}/ollama/.keep".text = "";
    "${podmanAiStackDataDir}/open-webui/.keep".text = "";
    "${podmanAiStackDataDir}/qdrant/.keep".text = "";
    "${podmanAiStackDataDir}/mindsdb/.keep".text = "";
  }
  // (lib.mkIf localAiStackEnabled {
    ".config/systemd/user/podman-local-ai-network.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=120
      TimeoutStopSec=60
      RestartSec=5
    '';

    ".config/systemd/user/podman-local-ai-ollama.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=600
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "docker.io/ollama/ollama:latest"}
    '';

    ".config/systemd/user/podman-local-ai-open-webui.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=600
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "ghcr.io/open-webui/open-webui:latest"}
    '';

    ".config/systemd/user/podman-local-ai-qdrant.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=600
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "docker.io/qdrant/qdrant:latest"}
    '';

    ".config/systemd/user/podman-local-ai-mindsdb.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=900
      TimeoutStopSec=240
      RestartSec=15
      ExecStartPre=${podmanEnsureImage "docker.io/mindsdb/mindsdb:latest"}
    '';
  })
  // {
    ".config/obsidian/ai-integrations/.keep".text = "";
    ".config/obsidian/ai-integrations/README".text = obsidianAiReadme;

    # Helper to sync Hugging Face models into the local cache
    ".local/bin/hf-model-sync" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if [[ $# -lt 1 ]]; then
          echo "Usage: hf-model-sync <model-id> [-- <extra-args>]" >&2
          exit 1
        fi

        model="$1"
        shift

        cache_root="''${HF_HOME:-$HOME/${huggingfaceCacheDir}}"
        mkdir -p "''${cache_root}/models"

        exec ${pythonAiEnv}/bin/huggingface-cli download "''${model}" "$@" \
          --local-dir "''${cache_root}/models/''${model}" \
          --cache-dir "''${cache_root}"
      '';
      executable = true;
    };


    # Launch Open WebUI via Podman for local AI experimentation
    ".local/bin/open-webui-run" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"
        image="''${OPEN_WEBUI_IMAGE:-ghcr.io/open-webui/open-webui:latest}"
        port="''${OPEN_WEBUI_PORT:-${toString openWebUiPort}}"
        data_dir="''${OPEN_WEBUI_DATA_DIR:-$HOME/${openWebUiDataDir}}"
        network="''${PODMAN_AI_STACK_NETWORK:-local-ai}"

        mkdir -p "''${data_dir}"

        if ! ${pkgs.podman}/bin/podman network exists "''${network}" >/dev/null 2>&1; then
          ${pkgs.podman}/bin/podman network create "''${network}" >/dev/null
        fi

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          echo "Open WebUI container '""''${container_name}""' is already running" >&2
          exit 0
        fi

        exec ${pkgs.podman}/bin/podman run --rm \
          --name "''${container_name}" \
          --network "''${network}" \
          -p "''${port}:8080" \
          -v "''${data_dir}:/app/backend/data" \
          -e "OLLAMA_BASE_URL=http://host.containers.internal:${toString ollamaPort}" \
          -e "OPENAI_API_BASE=${huggingfaceTgiContainerEndpoint}/v1" \
          -e "HF_HOME=''${HF_HOME:-$HOME/${huggingfaceCacheDir}}" \
          "''${image}"
      '';
      executable = true;
    };

    # Stop the Open WebUI container gracefully
    ".local/bin/open-webui-stop" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          exec ${pkgs.podman}/bin/podman stop "''${container_name}"
        else
          echo "Open WebUI container '""''${container_name}""' is not running" >&2
          exit 0
        fi
      '';
      executable = true;
    };

    ".local/bin/gpt-cli" = {
      text = ''
        #!${pythonAiInterpreterPath}
        import argparse
        import json
        import os
        import sys
        import textwrap
        import urllib.error
        import urllib.request

        try:
          from openai import OpenAI
        except Exception:
          OpenAI = None  # type: ignore


        def _read_prompt(args: argparse.Namespace) -> str:
          if args.prompt:
            return " ".join(args.prompt)

          data = sys.stdin.read()
          if not data.strip():
            raise SystemExit("gpt-cli: provide a prompt as arguments or via stdin")
          return data


        def _stream_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          stream = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
            stream=True,
          )

          for chunk in stream:
            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
              sys.stdout.write(chunk.choices[0].delta.content)
              sys.stdout.flush()
          print()


        def _complete_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          completion = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
          )
          print(completion.choices[0].message.content.strip())


        def _ollama_request(base_url: str, payload: dict[str, object]) -> urllib.request.Request:
          data = json.dumps(payload).encode("utf-8")
          headers = {"Content-Type": "application/json"}
          return urllib.request.Request(base_url, data=data, headers=headers)


        def _ollama_stream(url: str, payload: dict[str, object]) -> None:
          request = _ollama_request(url, payload | {"stream": True})
          with urllib.request.urlopen(request) as response:
            for raw in response:
              line = raw.decode("utf-8").strip()
              if not line:
                continue
              event = json.loads(line)
              message = event.get("message") or {}
              content = message.get("content")
              if content:
                sys.stdout.write(content)
                sys.stdout.flush()
            print()


        def _ollama_complete(url: str, payload: dict[str, object]) -> None:
          request = _ollama_request(url, payload | {"stream": False})
          with urllib.request.urlopen(request) as response:
            body = json.load(response)
          message = body.get("message") or {}
          content = message.get("content", "")
          print(content.strip())


        def main() -> None:
          parser = argparse.ArgumentParser(
            prog="gpt-cli",
            description="Talk to local Ollama models or any OpenAI-compatible endpoint.",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog=textwrap.dedent(
              """
              Examples:
                gpt-cli "summarize the latest git commits"
                gpt-cli --provider ollama --model llama3 "write unit tests for foo()"
                gpt-cli --system "You are a SQL assistant" < query.sql
              """
            ),
          )
          parser.add_argument("prompt", nargs=argparse.REMAINDER, help="Prompt text or leave empty to read stdin")
          parser.add_argument("--model", "-m", default=os.environ.get("GPT_CLI_DEFAULT_MODEL", "gpt-4o-mini"))
          parser.add_argument(
            "--provider",
            choices=["openai", "ollama"],
            default=os.environ.get("GPT_CLI_DEFAULT_PROVIDER", "openai"),
            help="Select backend provider (default: openai)",
          )
          parser.add_argument(
            "--base-url",
            default=os.environ.get("GPT_CLI_BASE_URL", os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")),
            help="Override the OpenAI/Ollama base URL",
          )
          parser.add_argument("--system", default=os.environ.get("GPT_CLI_SYSTEM", "You are a helpful AI assistant."))
          parser.add_argument("--temperature", type=float, default=float(os.environ.get("GPT_CLI_TEMPERATURE", "0.2")))
          parser.add_argument("--stream", action="store_true", help="Stream tokens as they arrive")

          args = parser.parse_args()
          prompt = _read_prompt(args)

          if args.provider == "openai":
            if OpenAI is None:
              raise SystemExit("gpt-cli: openai python package is unavailable in the current environment")
            api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACEHUB_API_TOKEN")
            if not api_key:
              raise SystemExit("gpt-cli: set OPENAI_API_KEY or HUGGINGFACEHUB_API_TOKEN for OpenAI-compatible backends")

            client = OpenAI(base_url=args.base_url.rstrip("/"), api_key=api_key)
            if args.stream:
              _stream_openai(client, args.model, args.system, prompt, args.temperature)
            else:
              _complete_openai(client, args.model, args.system, prompt, args.temperature)
            return

          base = args.base_url.rstrip("/") or os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
          url = f"{base}/api/chat"
          payload: dict[str, object] = {
            "model": args.model,
            "messages": [
              {"role": "system", "content": args.system},
              {"role": "user", "content": prompt},
            ],
            "stream": args.stream,
            "options": {"temperature": args.temperature},
          }

          try:
            if args.stream:
              _ollama_stream(url, payload)
            else:
              _ollama_complete(url, payload)
          except urllib.error.URLError as exc:
            raise SystemExit(f"gpt-cli: failed to reach Ollama at {base}: {exc}")


        if __name__ == "__main__":
          main()
      '';
      executable = true;
    };

    ".local/bin/podman-ai-stack" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if ! command -v podman >/dev/null 2>&1; then
          echo "podman-ai-stack: podman CLI is required" >&2
          exit 127
        fi

        if ! systemctl --user --help >/dev/null 2>&1; then
          echo "podman-ai-stack: systemd --user is unavailable; log in to a graphical or linger-enabled session" >&2
          exit 1
        fi

        network="''${PODMAN_AI_STACK_NETWORK:-${podmanAiStackNetworkName}}"
        data_root="''${PODMAN_AI_STACK_DATA_ROOT:-$HOME/${podmanAiStackDataDir}}"
        label_key="${podmanAiStackLabelKey}"
        label_value="${podmanAiStackLabelValue}"
        network_unit="podman-''${network}.network"

        mapfile -t container_names <<'EOCONTAINERS'
${podmanAiStackOllamaContainerName}
${podmanAiStackOpenWebUiContainerName}
${podmanAiStackQdrantContainerName}
${podmanAiStackMindsdbContainerName}
EOCONTAINERS

        container_units=()
        for name in "''${container_names[@]}"; do
          container_units+=("podman-''${name}.service")
        done

        usage() {
          cat <<USAGE >&2
Usage: podman-ai-stack <command>

Commands:
  up         Start the Podman network and all AI services
  down       Stop the managed containers and network (volumes kept)
  restart    Restart all services (down + up)
  status     Show systemd and Podman status information
  logs       Stream journald logs from the managed units

Environment overrides:
  PODMAN_AI_STACK_DATA_ROOT  Base directory for persistent bind mounts
  PODMAN_AI_STACK_NETWORK    Custom network name (default: ${podmanAiStackNetworkName})
USAGE
        }

        ensure_directories() {
          mkdir -p "''${data_root}/ollama" "''${data_root}/open-webui" "''${data_root}/qdrant" "''${data_root}/mindsdb"
        }

        start_units() {
          local unit
          for unit in "$@"; do
            systemctl --user start "$unit"
          done
        }

        stop_units() {
          local unit
          for unit in "$@"; do
            systemctl --user stop "$unit" || true
          done
        }

        cmd=""
        if [[ $# -gt 0 ]]; then
          cmd="$1"
          shift
        fi

        [[ -n "$cmd" ]] || { usage; exit 1; }

        case "$cmd" in
          up)
            ensure_directories
            start_units "$network_unit"
            start_units "''${container_units[@]}"
            echo "podman-ai-stack: started services: ${podmanAiStackOllamaContainerName}, ${podmanAiStackOpenWebUiContainerName}, ${podmanAiStackQdrantContainerName}, ${podmanAiStackMindsdbContainerName}"
            ;;
          down)
            stop_units "''${container_units[@]}"
            stop_units "$network_unit"
            ;;
          restart)
            "$0" down
            "$0" up
            ;;
          status)
            echo "-- systemd unit status --"
            for unit in "$network_unit" "''${container_units[@]}"; do
              echo "[$unit]"
              systemctl --user --no-pager status "$unit" || true
              echo
            done

            echo "-- podman ps (running) --"
            podman ps --filter "label=$label_key=$label_value" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
            echo
            echo "-- podman ps -a (all managed containers) --"
            podman ps -a --filter "label=$label_key=$label_value" --format "table {{.Names}}\t{{.Status}}\t{{.CreatedAt}}"
            ;;
          logs)
            log_args=()
            for unit in "$network_unit" "''${container_units[@]}"; do
              log_args+=("-u" "$unit")
            done
            exec journalctl --user -f "''${log_args[@]}" "$@"
            ;;
          *)
            usage
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    ".local/bin/ai-servicectl" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        declare -a SYSTEM_COMPONENTS=(gitea)
        declare -a ALL_COMPONENTS=(gitea stack)
        declare -A SYSTEM_UNITS=(
          [gitea]="gitea.service"
        )

        usage() {
          cat <<'USAGE'
usage: ai-servicectl <command> [component...]

Commands:
  start     Start one or more components (defaults to 'all')
  stop      Stop one or more components (defaults to 'all')
  restart   Restart one or more components (defaults to 'all')
  status    Show a concise status summary (defaults to 'all')
  logs      Stream logs for a single component
  list      Show available components
  help      Show this message

Components:
  gitea, stack
  Groups: all, system, stack
USAGE
        }

        expand_components() {
          local -a input=("$@")
          local -a expanded=()
          local item
          for item in "''${input[@]}"; do
            case "$item" in
              all)
                expanded+=("''${ALL_COMPONENTS[@]}")
                ;;
              system)
                expanded+=("''${SYSTEM_COMPONENTS[@]}")
                ;;
              stack)
                expanded+=("stack")
                ;;
              *)
                expanded+=("$item")
                ;;
            esac
          done

          declare -A seen=()
          local -a deduped=()
          for item in "''${expanded[@]}"; do
            if [[ -n "$item" && -z "''${seen[$item]:-}" ]]; then
              seen[$item]=1
              deduped+=("$item")
            fi
          done

          printf '%s\n' "''${deduped[@]}"
        }

        ensure_stack_helper() {
          if ! command -v podman-ai-stack >/dev/null 2>&1; then
            echo "ai-servicectl: podman-ai-stack helper is not installed" >&2
            exit 1
          fi
        }

        system_unit_for() {
          local component="$1"
          local unit="''${SYSTEM_UNITS[$component]:-}"
          if [[ -z "$unit" ]]; then
            echo "ai-servicectl: unknown component '$component'" >&2
            exit 1
          fi
          printf '%s\n' "$unit"
        }

        run_action() {
          local action="$1"
          local component="$2"
          case "$component" in
            stack)
              ensure_stack_helper
              case "$action" in
                start) podman-ai-stack up ;;
                stop) podman-ai-stack down ;;
                restart) podman-ai-stack restart ;;
                status) podman-ai-stack status ;;
                logs) podman-ai-stack logs ;;
                *) echo "ai-servicectl: unsupported action '$action' for stack" >&2; exit 1 ;;
              esac
              ;;
            *)
              local unit
              unit=$(system_unit_for "$component")
              case "$action" in
                start) sudo systemctl start "$unit" ;;
                stop) sudo systemctl stop "$unit" ;;
                restart) sudo systemctl restart "$unit" ;;
                status)
                  if systemctl is-active --quiet "$unit"; then
                    echo "$component: active"
                  else
                    echo "$component: inactive"
                  fi
                  ;;
                logs) sudo journalctl -u "$unit" -f ;;
                *)
                  echo "ai-servicectl: unsupported action '$action'" >&2
                  exit 1
                  ;;
              esac
              ;;
          esac
        }

        cmd="''${1:-}"
        shift || true

        case "$cmd" in
          start|stop|restart)
            if [[ "$#" -eq 0 ]]; then
              set -- all
            fi
            mapfile -t components < <(expand_components "$@")
            for component in "''${components[@]}"; do
              run_action "$cmd" "$component"
            done
            ;;
          status)
            if [[ "$#" -eq 0 ]]; then
              set -- all
            fi
            mapfile -t components < <(expand_components "$@")
            for component in "''${components[@]}"; do
              run_action status "$component"
            done
            ;;
          logs)
            if [[ "$#" -eq 0 ]]; then
              echo "ai-servicectl: specify a component for logs" >&2
              exit 1
            fi
            if [[ "$#" -gt 1 ]]; then
              echo "ai-servicectl: logs supports exactly one component" >&2
              exit 1
            fi
            mapfile -t components < <(expand_components "$@")
            run_action logs "''${components[0]}"
            ;;
          list)
            echo "Available components:"
            printf '  - %s\n' "''${ALL_COMPONENTS[@]}"
            ;;
          help|-h|--help|"")
            usage
            ;;
          *)
            echo "ai-servicectl: unknown command '$cmd'" >&2
            usage
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    ".local/bin/code-cursor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ai.cursor.Cursor >/dev/null 2>&1; then
          exec flatpak run ai.cursor.Cursor "$@"
        fi

        echo "code-cursor: install the Cursor Flatpak (ai.cursor.Cursor) to use this helper" >&2
        exit 127
      '';
      executable = true;
    };

    ".local/bin/obsidian-ai-bootstrap" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        vault="''${1:-$HOME/Documents/ObsidianVault}"
        plugin_dir="''${2:-textgenerator}"
        plugin_url="''${OBSIDIAN_AI_PLUGIN_URL:-https://github.com/nhaouari/obsidian-textgenerator-plugin/releases/latest/download/obsidian-textgenerator-plugin.zip}"

        if [[ "$vault" == "--help" || "$vault" == "-h" ]]; then
          cat <<USAGE
Usage: obsidian-ai-bootstrap [vault-path] [plugin-directory]

Install AI-centric community plugins (Text Generator by default) into an Obsidian vault.

Environment variables:
  OBSIDIAN_AI_PLUGIN_URL   Override plugin bundle URL (zip file)
  OBSIDIAN_AI_BACKEND_URL  Override API endpoint (defaults to \$OPEN_WEBUI_URL)
USAGE
          exit 0
        fi

        if [[ -z "$vault" ]]; then
          echo "obsidian-ai-bootstrap: missing vault path" >&2
          exit 1
        fi

        backend_url="''${OBSIDIAN_AI_BACKEND_URL:-${openWebUiUrl}}"
        tmp_zip="$(mktemp -t obsidian-plugin.XXXXXX.zip)"
        trap "rm -f \"$tmp_zip\"" EXIT

        mkdir -p "$vault/.obsidian/plugins/$plugin_dir"

        echo "Downloading Obsidian AI plugin bundle..."
        curl -fsSL "$plugin_url" -o "$tmp_zip"

        unzip -qo "$tmp_zip" -d "$vault/.obsidian/plugins/$plugin_dir"

        cat >"$vault/.obsidian/plugins/$plugin_dir/data.json" <<PLUGINCFG
{
  "openAiBaseUrl": "${huggingfaceTgiEndpoint}/v1",
  "openAiKey": "",
  "defaultModel": "${huggingfaceModelId}",
  "stream": true,
  "useCustomEndpoint": true,
  "customEndpoint": "$backend_url"
}
PLUGINCFG

        echo "Obsidian AI plugins ready in: $vault/.obsidian/plugins/$plugin_dir"
      '';
      executable = true;
    };

    # Default configuration for aider so it respects repository structure
    ".config/aider/config.toml".text = ''
      # Aider configuration tailored for NixOS & Gitea workflows
      [core]
      auto_commits = false
      detect_language = true
      use_git = true

      [files]
      include = ["flake.nix", "home.nix", "configuration.nix", "**/*.nix", "**/*.md"]

      [editor]
      command = "DEFAULTEDITOR"
    '';

    # Tea CLI configuration pointing to the generated AI agent catalog
    ".config/tea/config.yml".text = ''
      default:
        host: http://localhost:3000
        user: gitea-admin

      ai:
        model: gpt-4o-mini
        agent_catalog: "$GITEA_CUSTOM/ai-agents.json"
        editor_command:
          - "$HOME/.local/bin/gitea-ai-assistant"
          - "%REPO%"
    '';

    # P10k configuration (dynamic - loads user preferences)
    ".p10k.zsh".text = ''
      # Powerlevel10k configuration for NixOS
      # This config adapts to your preferences set via p10k-setup-wizard
      # To reconfigure: rm ~/.config/p10k/.configured && exec zsh

      # Load user theme preferences (set by p10k-setup-wizard.sh)
      THEME_FILE="$HOME/.config/p10k/theme.sh"
      if [[ -f "$THEME_FILE" ]]; then
        source "$THEME_FILE"
      else
        # Defaults if not configured yet
        export P10K_STYLE="lean"
        export P10K_COLORS="dark"
        export P10K_SHOW_TIME=false
        export P10K_SHOW_OS=true
        export P10K_SHOW_CONTEXT=false
        export P10K_TRANSIENT=true
      fi

      # Enable instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Build prompt elements based on user preferences
      left_elements=(dir vcs prompt_char)
      [[ "$P10K_SHOW_OS" == "true" ]] && left_elements=(os_icon "''${left_elements[@]}")

      right_elements=(status command_execution_time background_jobs)
      [[ "$P10K_SHOW_TIME" == "true" ]] && right_elements=(time "''${right_elements[@]}")
      [[ "$P10K_SHOW_CONTEXT" == "true" ]] && right_elements+=(context)

      typeset -g POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=("''${left_elements[@]}")
      typeset -g POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=("''${right_elements[@]}")

      # Visual style
      typeset -g POWERLEVEL9K_MODE=nerdfont-complete
      typeset -g POWERLEVEL9K_ICON_PADDING=moderate

      # Prompt layout based on style
      case "$P10K_STYLE" in
        lean|pure)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
        classic|rainbow)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=true
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
      esac

      # Transient prompt
      [[ "$P10K_TRANSIENT" == "true" ]] && typeset -g POWERLEVEL9K_TRANSIENT_PROMPT=always

      # Enhanced Color schemes with better contrast
      case "$P10K_COLORS" in
        high-contrast-dark)
          # High contrast bright colors for dark terminals (RECOMMENDED)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=46
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=196
          ;;
        custom-high-contrast)
          # Maximum contrast for accessibility
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=15           # White
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=10     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=11  # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=13 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=9   # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=15       # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=10
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=9
          ;;
        light)
          # High contrast for light backgrounds
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=24
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=28
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=130
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=21
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=124
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=24
          ;;
        solarized)
          # Solarized Dark colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=81           # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=106    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=221 # Brighter yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=125 # Brighter magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=81
          ;;
        gruvbox)
          # Gruvbox colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=214
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=142
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=208
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=175
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=167
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=223
          ;;
        nord)
          # Nord colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=111          # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=150    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=147 # Brighter purple
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=210 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=153
          ;;
        dracula)
          # Dracula colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=141
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=121    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=177 # Brighter pink
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=212
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=183
          ;;
        *)
          # Dark (default) - bright colors
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          ;;
      esac

      # Common settings
      typeset -g POWERLEVEL9K_DIR_SHORTEN_STRATEGY=truncate_to_last
      typeset -g POWERLEVEL9K_DIR_SHORTEN_DIR_LENGTH=3
      typeset -g POWERLEVEL9K_STATUS_OK=false
      typeset -g POWERLEVEL9K_LINUX_NIXOS_ICON='❄️'
    '';
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      "${giteaFlatpakConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaFlatpakConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaFlatpakDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the Gitea Flatpak deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    }
    // {
      "${giteaNativeConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaNativeConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaNativeDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the native Gitea deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    };

  services.podman = lib.mkIf localAiStackEnabled {
    enable = true;

    # Rootless storage tuning for AI stack containers
    settings.storage = {
      storage = {
        driver = "vfs";
        runroot = "/run/user/${let
          hmUid = if config.home ? uidNumber then config.home.uidNumber else null;
          osUsers =
            if config ? users && config.users ? users then config.users.users else {};
          osUser = osUsers.${config.home.username} or null;
          osUserUid = if osUser != null && osUser ? uid then osUser.uid else null;
          accountUsers =
            if config ? accounts && config.accounts ? users then config.accounts.users else {};
          accountUser = accountUsers.${config.home.username} or null;
          accountUid =
            if accountUser != null && accountUser ? uid then accountUser.uid else null;
          resolvedUid =
            if hmUid != null then hmUid
            else if osUserUid != null then osUserUid
            else if accountUid != null then accountUid
          else 1000;
          in toString resolvedUid}/containers";
        graphroot = "${config.home.homeDirectory}/.local/share/containers/storage";
        rootless_storage_path = "${config.home.homeDirectory}/.local/share/containers/storage";
      };
    };

    networks."${podmanAiStackNetworkName}" = {
      description = "Isolated network for the local AI development stack";
      autoStart = false;
      labels = {
        "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
      };
    };

    containers = {
      "${podmanAiStackOllamaContainerName}" = {
        image = "docker.io/ollama/ollama:latest";
        description = "Ollama inference runtime (rootless Podman)";
        autoStart = false;
        autoUpdate = "local";  # Use local images to avoid timeout during home-manager switch
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "ollama" ];
        ports = [ "${toString ollamaPort}:11434" ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/ollama:/root/.ollama"
        ];
        environment = {
          OLLAMA_HOST = "0.0.0.0";
        };
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackOpenWebUiContainerName}" = {
        image = "ghcr.io/open-webui/open-webui:latest";
        description = "Open WebUI interface for the local AI stack";
        autoStart = false;
        autoUpdate = "local";  # Use local images to avoid timeout during home-manager switch
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "open-webui" ];
        ports = [ "${toString openWebUiPort}:8080" ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/open-webui:/app/backend/data"
        ];
        environment = {
          OLLAMA_BASE_URL = "http://ollama:${toString ollamaPort}";
          OPENAI_API_BASE = "${huggingfaceTgiContainerEndpoint}/v1";
        };
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackQdrantContainerName}" = {
        image = "docker.io/qdrant/qdrant:latest";
        description = "Qdrant vector database for embeddings";
        autoStart = false;
        autoUpdate = "local";  # Use local images to avoid timeout during home-manager switch
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "qdrant" ];
        ports = [
          "${toString qdrantHttpPort}:6333"
          "${toString qdrantGrpcPort}:6334"
        ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/qdrant:/qdrant/storage"
        ];
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackMindsdbContainerName}" = {
        image = "docker.io/mindsdb/mindsdb:latest";
        description = "MindsDB orchestration layer for AI workflows";
        autoStart = false;
        autoUpdate = "local";  # Use local images to avoid timeout during home-manager switch
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "mindsdb" ];
        ports = [
          "${toString mindsdbApiPort}:47334"
          "${toString mindsdbGuiPort}:7735"
        ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/mindsdb:/var/lib/mindsdb"
        ];
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };
    };
  };

  # ========================================================================
  # Gitea Native Service (runs alongside Flatpak when present)
  # ========================================================================

  systemd.user.services =
    lib.mkMerge [
      # DISABLED: flatpak-managed-install systemd service
      # Reason: Direct flatpak remote installation is more reliable and avoids timeout issues
      # The deployment script now uses flatpak_bulk_install_apps() which calls
      # flatpak --noninteractive --assumeyes install --user flathub <apps...>
      # This provides better error handling and progress reporting than the systemd service.
      #
      # (lib.mkIf config.services.flatpak.enable {
      #   "flatpak-managed-install" = {
      #     Unit = {
      #       Description = "Declarative Flatpak managed installer";
      #       Documentation = [
      #         "https://nix-community.github.io/nix-flatpak/"
      #         "man:flatpak(1)"
      #       ];
      #       After = [ "graphical-session.target" "network-online.target" ];
      #       Wants = [ "network-online.target" ];
      #       ConditionPathExists = "/run/user/%U/allow-flatpak-managed-install";
      #       X-SwitchMethod = "keep-old";
      #     };
      #     Service = {
      #       Type = "oneshot";
      #       ExecStart = lib.mkForce flatpakManagedInstallScriptExe;
      #       ExecCondition = "${pkgs.coreutils}/bin/test -x ${pkgs.flatpak}/bin/flatpak";
      #       ExecStartPre = [
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.local/share/flatpak"
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.config/flatpak"
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.var/app"
      #       ];
      #       Environment = [
      #         "HOME=%h"
      #         "XDG_RUNTIME_DIR=%t"
      #         "DBUS_SESSION_BUS_ADDRESS=unix:path=%t/bus"
      #       ];
      #       TimeoutStartSec = 3600;
      #       Restart = lib.mkForce "no";
      #       RemainAfterExit = false;
      #       StandardOutput = "journal";
      #       StandardError = "journal";
      #       SuccessExitStatus = "0 1";
      #     };
      #   };
      # })
      (lib.mkIf (glfMangoHudDesktopMode && glfMangoHudHasEntries && pkgs ? mangohud) {
        "mangohud-desktop" = {
          Unit = {
            Description = "MangoHud desktop overlay";
            Documentation = [ "https://github.com/flightlessmango/MangoHud" ];
            After = [ "graphical-session.target" ];
            PartOf = [ "graphical-session.target" ];
            ConditionPathExists = "%h/.config/MangoHud/MangoHud.conf";
          };
          Service = {
            Type = "simple";
            Environment = [
              "MANGOHUD=1"
              "MANGOHUD_CONFIGFILE=%h/.config/MangoHud/MangoHud.conf"
            ];
            ExecStart = "${pkgs.mangohud}/bin/mangoapp";
            Restart = "on-failure";
            RestartSec = 5;
            StandardOutput = "journal";
            StandardError = "journal";
          };
          Install = {
            WantedBy = [ "graphical-session.target" ];
          };
        };
      })
      {
        "gitea-dev" = {
          Unit = {
            Description = "Gitea development forge (user)";
            After = [ "network.target" ];
            PartOf = [ "default.target" ];
          };
          Service = {
            Environment = [
              "GITEA_WORK_DIR=%h/${giteaNativeDataDir}"
              "GITEA_CUSTOM=%h/${giteaNativeConfigDir}"
            ];
            ExecStart = "${pkgs.gitea}/bin/gitea web --config %h/${giteaNativeConfigDir}/app.ini";
            WorkingDirectory = "%h/${giteaNativeDataDir}";
            Restart = "on-failure";
            RestartSec = 3;
            TimeoutStopSec = 60;
          };
          Install = {
            WantedBy = [ "default.target" ];
          };
        };
        # Jupyter Lab server (user service for interactive development)
        # Disabled by default - enable manually with: systemctl --user enable --now jupyter-lab
        "jupyter-lab" = {
          Unit = {
            Description = "Jupyter Lab server for interactive AI/ML development";
            Documentation = [ "https://jupyter.org/documentation" ];
            After = [ "network.target" ];
          };
          Service = {
            Type = "simple";
            Environment = [
              "JUPYTER_DATA_DIR=%h/.local/share/jupyter"
              "JUPYTER_CONFIG_DIR=%h/.config/jupyter"
              "JUPYTER_RUNTIME_DIR=%h/.local/share/jupyter/runtime"
            ];
            ExecStartPre = [
              "${pkgs.coreutils}/bin/mkdir -p %h/.local/share/jupyter"
              "${pkgs.coreutils}/bin/mkdir -p %h/.config/jupyter"
              "${pkgs.coreutils}/bin/mkdir -p %h/notebooks"
            ];
            ExecStart = ''
              ${pythonAiEnv}/bin/jupyter-lab \
                --ip=127.0.0.1 \
                --port=8888 \
                --no-browser \
                --notebook-dir=%h/notebooks
            '';
            WorkingDirectory = "%h/notebooks";
            Restart = "on-failure";
            RestartSec = 5;
            TimeoutStopSec = 30;
          };
          Install = {
            # Enable by default so notebooks are available immediately after switch.
            # Disable with: systemctl --user disable --now jupyter-lab
            WantedBy = [ "default.target" ];
          };
        };
      }
    ];

  # ========================================================================
  # Flatpak Integration - Manual Setup Instructions
  # ========================================================================
  # NOTE: Flatpak is installed at system level via:
  #   services.flatpak.enable = true  (in ~/.config/home-manager/configuration.nix)
  #
  # INSTALLATION INSTRUCTIONS (Run these once after system setup):
  #
  # 1. Add Flathub repository (one-time setup):
  #    flatpak remote-add --if-not-exists flathub \
  #      https://dl.flathub.org/repo/flathub.flatpakrepo
  #
  # 2. Install Flatpak applications (use commands below):
  #    # System Tools
  #    flatpak install -y flathub com.github.tchx84.Flatseal
  #    flatpak install -y flathub org.gnome.FileRoller
  #    flatpak install -y flathub net.nokyan.Resources
  #
  #    # Media Players
  #    flatpak install -y flathub org.videolan.VLC
  #    flatpak install -y flathub io.mpv.Mpv
  #
  #    # Web Browser
  #    flatpak install -y flathub org.mozilla.firefox
  #
  #    # Productivity
  #    flatpak install -y flathub md.obsidian.Obsidian
  #
  # 3. OR: Copy the list below and use this command:
  #    for app in com.github.tchx84.Flatseal org.gnome.FileRoller \
  #                net.nokyan.Resources org.videolan.VLC io.mpv.Mpv \
  #                org.mozilla.firefox md.obsidian.Obsidian; do
  #      flatpak install -y flathub "$app"
  #    done
  #
  # DECLARATIVE FLATPAK APPS (for reference - install manually):
  # ====================================================================
  # System Tools
  # flatpak install -y flathub com.github.tchx84.Flatseal
  # flatpak install -y flathub org.gnome.FileRoller
  # flatpak install -y flathub net.nokyan.Resources
  #
  # Media Players
  # flatpak install -y flathub org.videolan.VLC
  # flatpak install -y flathub io.mpv.Mpv
  #
  # Web Browsers
  # flatpak install -y flathub org.mozilla.firefox
  #
  # Productivity & Office
  # flatpak install -y flathub md.obsidian.Obsidian
  # # flatpak install -y flathub org.libreoffice.LibreOffice
  # # flatpak install -y flathub app.standard-notes.StandardNotes
  # # flatpak install -y flathub org.joplin.Joplin
  #
  # Development & Content Tools (GUI Applications)
  # # flatpak install -y flathub io.github.gitui.gitui
  # # flatpak install -y flathub fr.handbrake.ghb
  # # flatpak install -y flathub org.audacityteam.Audacity
  # # flatpak install -y flathub org.gimp.GIMP
  # # flatpak install -y flathub org.inkscape.Inkscape
  # # flatpak install -y flathub org.pitivi.Pitivi
  # # flatpak install -y flathub org.blender.Blender
  # # flatpak install -y flathub org.darktable.Darktable
  #
  # Additional Web Browsers (If needed)
  # # flatpak install -y flathub com.google.Chrome
  #
  # Internet & Communication (Desktop Apps)
  # # flatpak install -y flathub org.telegram.desktop
  # # flatpak install -y flathub com.slack.Slack
  # # flatpak install -y flathub org.thunderbird.Thunderbird
  # # flatpak install -y flathub io.Riot.Riot
  # # flatpak install -y flathub com.obsproject.Studio
  #
  # Database & Tools (GUI Applications)
  # # flatpak install -y flathub org.dbeaver.DBeaverCommunity
  # # flatpak install -y flathub com.beekeeperstudio.Studio
  # # flatpak install -y flathub com.mongodb.Compass
  #
  # Remote Access & Virtualization (GUI)
  # # flatpak install -y flathub org.remmina.Remmina
  # # flatpak install -y flathub com.freerdp.FreeRDP
  # # flatpak install -y flathub org.virt_manager.virt-manager
  #
  # Security & Privacy Tools (GUI Applications)
  # # flatpak install -y flathub org.gnome.Secrets
  # # flatpak install -y flathub org.keepassxc.KeePassXC
  # # flatpak install -y flathub com.github.Eloston.UngoogledChromium
  # # flatpak install -y flathub com.tutanota.Tutanota
  #
  # Entertainment & Gaming
  # # flatpak install -y flathub com.valvesoftware.Steam
  # # flatpak install -y flathub org.DolphinEmu.dolphin-emu
  # # flatpak install -y flathub net.rpcs3.RPCS3
  # # flatpak install -y flathub org.libretro.RetroArch
  #
  # ====================================================================
  # ALTERNATIVE: Use COSMIC App Store
  # ====================================================================
  # Simply open the COSMIC App Store from your application menu
  # and search for desired applications. Click Install to download
  # from Flathub. This is the most user-friendly method!
  #
  # MANAGE PERMISSIONS:
  # ====================================================================
  # flatpak run com.github.tchx84.Flatseal
  # (or open Flatseal from app menu)
  #
  # Then select app from sidebar and toggle permissions as needed.

  # services.flatpak: Declarative Flatpak management via nix-flatpak
  # When using flakes with the nix-flatpak module provided via flake imports, this section
  # defines all Flatpak applications declaratively.
  # When nix-flatpak is NOT available (channel-based install), this section
  # is ignored and you can install apps manually via flatpak CLI.
  #
  services.flatpak =
    let
      packagesElemTypePath = [ "services" "flatpak" "packages" "type" "elemType" ];
      packageOptionTypePath = [ "services" "flatpak" "package" "type" ];
      remoteTypePath = [ "services" "flatpak" "remotes" "type" "elemType" ];
      flatpakPackagesElemType =
        if lib.hasAttrByPath packagesElemTypePath options then
          lib.attrByPath packagesElemTypePath options null
        else
          null;
      flatpakPackageOptionType =
        if lib.hasAttrByPath packageOptionTypePath options then
          lib.attrByPath packageOptionTypePath options null
        else
          null;
      flatpakRemoteType =
        if lib.hasAttrByPath remoteTypePath options then
          lib.attrByPath remoteTypePath options null
        else
          null;
      checkCandidate = type: candidate:
        if type == null then true else (builtins.tryEval (type.check candidate)).success;
      selectCandidate = type: defaultCandidate: candidates:
        let
          found = lib.findFirst (candidate: checkCandidate type candidate) null candidates;
        in
          if found != null then found else defaultCandidate;
      mkFlathubRemote =
        selectCandidate
          flatpakRemoteType
          { name = flathubRemoteName; location = flathubRemoteUrl; }
          [
            { name = flathubRemoteName; location = flathubRemoteUrl; }
            { name = flathubRemoteName; url = flathubRemoteUrl; }
          ];
      mkFlathubPackage =
        appId:
          selectCandidate
            flatpakPackagesElemType
            { inherit appId; origin = flathubRemoteName; }
            [
              { inherit appId; origin = flathubRemoteName; }
              { inherit appId; remote = flathubRemoteName; }
            ];

    in
      {
        enable = true;
        remotes = [ mkFlathubRemote ];
        packages = map mkFlathubPackage flathubPackages;

        # Optional: Set permissions globally for all Flatpak packages
        # permissions = {
        #   "org.freedesktop.Flatpak" = {
        #     # Grant host filesystem access
        #     Context.filesystems = [
        #       "home"
        #       "/mnt"
        #     ];
        #   };
        # };
      }
      // lib.optionalAttrs (flatpakPackageOptionType != null) {
        package = selectCandidate flatpakPackageOptionType pkgs.flatpak [ pkgs.flatpak ];
      };

  # ========================================================================
  # Home Manager Auto-Upgrade Service (Optional)
  # ========================================================================
  # Automatically update your Home Manager configuration on a schedule.
  # This service uses flakes and pulls updates from your configuration directory.
  #
  # To enable: Set 'services.home-manager.autoUpgrade.enable = true;'
  # Schedule: Runs daily at 03:00 by default
  #
  # Reference: Home Manager news 2025-10-25
  # ========================================================================
  services.home-manager.autoUpgrade = {
    enable = false;  # Set to true to enable automatic updates
    frequency = "daily";  # Options: "daily", "weekly", "monthly"

    # Enable flake support (recommended for this deployment)
    useFlake = true;

    # Flake directory (uses the symlinked config location)
    flakeDir = "${config.home.homeDirectory}/.config/home-manager";
  };

}
