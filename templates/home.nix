# NixOS Quick Deploy - Home Manager Configuration
# Generated by: nixos-quick-deploy.sh vVERSIONPLACEHOLDER
# Template Hash: HASHPLACEHOLDER
# This hash is used to detect when the template changes
# If you edit this file manually, your edits will be preserved
# until the template itself changes (new packages added to script)
#
# Placeholders consumed by lib/config.sh:
#   VERSIONPLACEHOLDER / HASHPLACEHOLDER   → deployment metadata
#   GLF_HOME_DEFINITIONS                   → gaming overlay configuration
#   GPU_MONITORING_PACKAGES                → vendor-specific monitors
#   FLATPAK_MANAGED_PACKAGES               → Flatpak manifest snippet
#   Git user/email configured via programs.git.settings
# Additional placeholders appear throughout for optional services (Gitea, etc.)
# =============================================================================

{ config, pkgs, lib, options, ... }:

let
  # Prefer nix-ai-tools outputs if passed via _module.args; otherwise default to {}.
  nixAiToolsPackages =
    if config ? _module && config._module.args ? nixAiToolsPackages then
      config._module.args.nixAiToolsPackages
    else
      { };
  # Collect available derivations from the external nix-ai-tools flake so the
  # generated configuration gracefully degrades if certain outputs are missing.
  nixAiToolsPackageList =
    let
      candidateNames = [ "default" "nix-ai-tools" ];
    in
    lib.concatMap
      (name:
        lib.optional (lib.hasAttr name nixAiToolsPackages)
          (lib.getAttr name nixAiToolsPackages))
      candidateNames;
  giteaFlatpakAppId = "io.gitea.Gitea";
  giteaFlatpakConfigDir = ".var/app/${giteaFlatpakAppId}/config/gitea";
  giteaFlatpakDataDir = ".var/app/${giteaFlatpakAppId}/data/gitea";
  giteaNativeConfigDir = ".config/gitea";
  giteaNativeDataDir = ".local/share/gitea";
  giteaAiConfigFile = "ai-agents.json";
  # AI services run in user-level Podman (llama.cpp + Ollama + Qdrant)
  # See: ~/.config/ai-optimizer/ for the Podman-based AI stack
  huggingfaceCacheDir = ".cache/huggingface";
  huggingfaceModelId = HUGGINGFACE_MODEL_ID_PLACEHOLDER;
  huggingfaceScoutModelId = HUGGINGFACE_SCOUT_MODEL_ID_PLACEHOLDER;
  huggingfaceTgiEndpoint = HUGGINGFACE_TGI_ENDPOINT_PLACEHOLDER;
  huggingfaceScoutTgiEndpoint = HUGGINGFACE_SCOUT_TGI_ENDPOINT_PLACEHOLDER;
  huggingfaceTgiContainerEndpoint = HUGGINGFACE_TGI_CONTAINER_ENDPOINT_PLACEHOLDER;
  # OpenAI-compatible local endpoints (llama.cpp/llama.cpp)
  vllmPrimaryEndpoint = "http://127.0.0.1:8080/v1";  # Primary local inference
  vllmSecondaryEndpoint = "http://127.0.0.1:8081/v1";  # Secondary local inference (if needed)
  # ===========================================================================
  # LLM Configuration (December 2025 - Optimized for Coding)
  # ===========================================================================
  # 
  # RECOMMENDED LOCAL MODELS FOR CODING:
  # ---------------------------------------------------------------------------
  # Tier 1 - Primary (pick based on VRAM):
  #   qwen2.5-coder:14b    - Best overall coding model (~10GB VRAM)
  #   qwen2.5-coder:7b     - Fast, efficient (~5GB VRAM)
  #   deepseek-coder-v2    - Excellent debugging/reasoning
  #   codestral:22b        - Strong completions (~14GB VRAM)
  #
  # Tier 2 - Specialized:
  #   starcoder2:15b       - 80+ languages, permissive license
  #   llama3.2:8b          - General purpose, good instruction following
  #   phi-4:14b            - Microsoft's efficient reasoning model
  #
  # MOBILE WORKSTATION RECOMMENDATIONS:
  #   8GB VRAM:   qwen2.5-coder:7b,deepseek-coder:6.7b
  #   16GB VRAM:  qwen2.5-coder:14b,deepseek-coder-v2,starcoder2:7b
  #   32GB+ VRAM: qwen2.5-coder:32b,codestral:22b,llama3.2:70b
  #
  # REMOTE LLM FALLBACK (for complex tasks):
  #   Claude 4.5 Sonnet - Best for coding (77% SWE-bench)
  #   GPT-4o / o3-mini  - Fast, reliable, good tool calling
  #   Gemini 3 Flash    - Multimodal, real-time
  # ---------------------------------------------------------------------------
  
  # LLM Backend Configuration (llama_cpp via llama.cpp server)
  # llama.cpp is optimized for AMD GPUs with ROCm
  llmBackend = LLM_BACKEND_PLACEHOLDER;  # "llama_cpp"
  llmModels = LLM_MODELS_PLACEHOLDER;    # Comma-separated model list
  llmModelsList = lib.splitString "," llmModels;
  
  # Backend-specific ports
  llamaCppPort = 8080;  # llama.cpp server default port
  llmInferencePort = llamaCppPort;
  llamaCppHost = "http://127.0.0.1:${toString llamaCppPort}";
  llmInferenceHost = llamaCppHost;
  
  # Remote LLM Configuration (for hybrid local/remote workflows)
  # Set these environment variables for remote LLM access:
  #   OPENAI_API_KEY, ANTHROPIC_API_KEY, OPENROUTER_API_KEY
  remoteLlmProviders = {
    openrouter = "https://openrouter.ai/api/v1";
    openai = "https://api.openai.com/v1";
    anthropic = "https://api.anthropic.com/v1";
  };
  # Recommended remote models for coding (December 2025)
  remoteLlmRecommended = [
    "anthropic/claude-4.5-sonnet"  # Best for coding
    "openai/o3-mini"               # Fast, cheap
    "google/gemini-3-flash"        # Multimodal
  ];
  
  openWebUiPort = 3001;
  openWebUiUrl = "http://127.0.0.1:${toString openWebUiPort}";
  openWebUiDataDir = ".local/share/open-webui";
  podmanAiStackDataDir = ".local/share/podman-ai-stack";
  podmanAiStackNetworkName = "local-ai";
  podmanAiStackLabelKey = "nixos.quick-deploy.ai-stack";
  podmanAiStackLabelValue = "true";
  podmanAiStackLlamaCppContainerName = "${podmanAiStackNetworkName}-llama-cpp";
  podmanAiStackLlmContainerName = podmanAiStackLlamaCppContainerName;
  podmanAiStackOpenWebUiContainerName = "${podmanAiStackNetworkName}-open-webui";
  podmanAiStackQdrantContainerName = "${podmanAiStackNetworkName}-qdrant";
  podmanAiStackMindsdbContainerName = "${podmanAiStackNetworkName}-mindsdb";
  qdrantHttpPort = 6333;
  qdrantGrpcPort = 6334;
  mindsdbApiPort = 47334;
  mindsdbGuiPort = 7735;
  podmanEnsureImage = image:
    let
      sanitized = lib.replaceStrings [ "/" ":" "." "@" ] [ "-" "-" "-" "-" ] image;
    in
    pkgs.writeShellScript "ensure-${sanitized}-image" ''
      set -euo pipefail
      if ! ${pkgs.podman}/bin/podman image exists ${lib.escapeShellArg image}; then
        ${pkgs.podman}/bin/podman pull --quiet ${lib.escapeShellArg image}
      fi
    '';
  podmanWaitForNetworkScript = pkgs.writeShellScript "podman-wait-for-network" ''
    set -euo pipefail
    if ! ${pkgs.systemd}/bin/systemctl --system is-active --quiet NetworkManager.service; then
      echo "NetworkManager is not active; skipping network wait." >&2
      exit 0
    fi
    for attempt in $(seq 1 120); do
      if ${pkgs.networkmanager}/bin/nm-online -q -t 5; then
        exit 0
      fi
      sleep 1
    done
    echo "NetworkManager did not report online status within timeout; continuing." >&2
    exit 0
  '';
  gitPackage =
    if config ? programs && config.programs ? git && config.programs.git ? package then
      config.programs.git.package
    else
      pkgs.git;
  gitExecutablePath = lib.getExe gitPackage;
  claudeWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/claude-wrapper";
  claudeNodeModulesPath = "${config.home.homeDirectory}/.npm-global/lib/node_modules";
  gptCodexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gpt-codex-wrapper";
  codexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/codex-wrapper";
  openaiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/openai-wrapper";
  gooseAiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gooseai-wrapper";
  nixProfileBinPath = "${config.home.homeDirectory}/.nix-profile/bin";
  nodeExecutablePath = lib.makeBinPath [ pkgs.nodejs_22 ];
  claudePathValue = "${nixProfileBinPath}:${nodeExecutablePath}:/run/current-system/sw/bin:\${env:PATH}";
  aiPathValue = claudePathValue;
  aiNodeModulesPath = claudeNodeModulesPath;
  flathubRemoteName = "flathub";
  flathubRemoteUrl = "https://dl.flathub.org/repo/flathub.flatpakrepo";
  flathubRemoteFallbackUrl = "https://flathub.org/repo/flathub.flatpakrepo";
  # Duplicate desktop entries for COSMIC Settings appear on some releases.
  # Hide upstream variants and publish a single consistent launcher.
  cosmicSettingsDesktopFileNames = [
    "com.system76.CosmicSettings.desktop"
    "org.pop_os.CosmicSettings.desktop"
    "cosmic-settings.desktop"
  ];
  cosmicOnlyShowInEnvironments = [ "COSMIC" ];
  cosmicOnlyShowInValue =
    let
      joined = lib.concatStringsSep ";" cosmicOnlyShowInEnvironments;
    in
    if cosmicOnlyShowInEnvironments == [ ] then "" else "${joined};";
  commonPythonOverrides = import ./python-overrides.nix;
  overridePythonPackages = pkgSet:
    if pkgSet ? overrideScope' then
      pkgSet.overrideScope' (self: super: commonPythonOverrides self super)
    else
      pkgSet;
  pythonOverridesOverlay =
    final: prev:
      (lib.optionalAttrs (prev ? python3Packages) {
        python3Packages = overridePythonPackages prev.python3Packages;
      })
      // (lib.optionalAttrs (prev ? python311Packages) {
        python311Packages = overridePythonPackages prev.python311Packages;
      })
      // (lib.optionalAttrs (prev ? python312Packages) {
        python312Packages = overridePythonPackages prev.python312Packages;
      })
      // (lib.optionalAttrs (prev ? python313Packages) {
        python313Packages = overridePythonPackages prev.python313Packages;
      })
      // (lib.optionalAttrs (prev ? python314Packages) {
        python314Packages = overridePythonPackages prev.python314Packages;
      });
  pythonPreferLatest =
    let
      envPref = builtins.getEnv "PYTHON_PREFER_PY314";
    in
    envPref == "1" || envPref == "true";
  python14CompatibilityMask = [
    # Mask packages currently incompatible with Python 3.14 to avoid build failures.
    "llvmlite"
    "numba"
    "sparse"
    "dask-ml"
    "dask-glm"
  ];
  python14Masked = python14CompatibilityMask != [ ];
  pythonWithFallback =
    let
      python14Available = (pkgs ? python314) && (pkgs ? python314Packages);
    in
    if pythonPreferLatest && python14Available && !python14Masked then pkgs.python314 else pkgs.python313;

  # --------------------------------------------------------------------------
  # GLF (Gaming/Lifestyle Features) defaults. The deployment script injects
  # tuned values during generation, but we fall back to safe placeholders so
  # the template remains evaluatable on its own.
  glfDefaultValues = {
    glfMangoHudPresets = {
      disabled = [ ];
      light = [ ];
      full = [ ];
      desktop = [ ];
      "desktop-hybrid" = [ ];
    };
    glfMangoHudProfile = "disabled";
    glfMangoHudConfigFileContents = "";
    glfMangoHudHasEntries = false;
    glfMangoHudDesktopMode = false;
    glfMangoHudInjectsIntoApps = false;
    glfLutrisWithGtk = pkgs.lutris;
    glfGamingPackages = [ ];
    glfSteamPackage = pkgs.steam;
    glfSteamCompatPackages = [ ];
    glfSystemUtilities = [ ];
  };

  glfOverrideValues =
    let
      overrides = rec {
        @GLF_HOME_DEFINITIONS@
      };
    in overrides;

  # Merge defaults with deploy-time overrides so the template remains
  # evaluatable even when rendered outside the orchestrator (e.g., nix repl).
  glfHomeValues = glfDefaultValues // glfOverrideValues;

  inherit (glfHomeValues)
    glfMangoHudPresets
    glfMangoHudProfile
    glfMangoHudConfigFileContents
    glfMangoHudHasEntries
    glfMangoHudDesktopMode
    glfMangoHudInjectsIntoApps
    glfLutrisWithGtk
    glfGamingPackages
    glfSteamPackage
    glfSteamCompatPackages
    glfSystemUtilities;
  gpuMonitoringPackages =
    # Populated by nixos-quick-deploy.sh to enable vendor-specific GPU monitors.
    with pkgs; @GPU_MONITORING_PACKAGES@;
  nvtopPackagesAttr = if pkgs ? nvtopPackages then pkgs.nvtopPackages else { };
  fallbackNvtopPackages =
    if gpuMonitoringPackages != [ ] then
      [ ]
    else
      (lib.optionals (pkgs ? nvtop) [ pkgs.nvtop ])
      ++ (lib.optionals (nvtopPackagesAttr ? default) [ nvtopPackagesAttr.default ])
      ++ (lib.optionals (nvtopPackagesAttr ? nvidia) [ nvtopPackagesAttr.nvidia ])
      ++ (lib.optionals (nvtopPackagesAttr ? amd) [ nvtopPackagesAttr.amd ])
      ++ (lib.optionals (nvtopPackagesAttr ? intel) [ nvtopPackagesAttr.intel ]);
  # ============================================================================
  # Flatpak Applications (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Edit the list below to tailor the default Flatpak apps.
  # Comment out entries you do not need or append new App IDs.
  # Keep the DEFAULT_FLATPAK_APPS array in nixos-quick-deploy.sh in sync.
  @FLATPAK_MANAGED_PACKAGES@
  flatpakManagedInstallRuntimeInputs = [
    pkgs.coreutils
    pkgs.gawk
    pkgs.gnugrep
    pkgs.gnused
    pkgs.findutils
    pkgs.util-linux
    pkgs.flatpak
    pkgs.ostree
  ];
  flatpakManagedInstallScript =
    let
      packageArgs = lib.concatMapStringsSep " " (appId: lib.escapeShellArg appId) flathubPackages;
    in
    pkgs.writeShellApplication {
      name = "aidb-flatpak-managed-install";
      runtimeInputs = flatpakManagedInstallRuntimeInputs;
      text = ''
        set -euo pipefail

        remote_name=${flathubRemoteName}
        remote_url=${flathubRemoteUrl}
        remote_fallback_url=${flathubRemoteFallbackUrl}
        availability_message=""
        managed_state_marker="$HOME/.local/share/flatpak/.aidb-managed-state"
        flatpak_install_arch=""
        flatpak_arch_args=()

        log() {
          printf '[%s] %s\n' "$(date --iso-8601=seconds)" "$*"
        }

        detect_flatpak_install_arch() {
          local nix_system=""
          if command -v nix >/dev/null 2>&1; then
            nix_system="$(nix eval --raw --expr 'builtins.currentSystem' 2>/dev/null || true)"
            case "$nix_system" in
              x86_64-*) flatpak_install_arch="x86_64" ;;
              aarch64-*) flatpak_install_arch="aarch64" ;;
              armv7l-*|armv7-*) flatpak_install_arch="arm" ;;
            esac
          fi

          if [[ -z "$flatpak_install_arch" ]]; then
            local arch_guess
            arch_guess="$(flatpak --default-arch 2>/dev/null || uname -m)"
            case "$arch_guess" in
              x86_64|amd64) flatpak_install_arch="x86_64" ;;
              aarch64|arm64) flatpak_install_arch="aarch64" ;;
              armv7l|armv7hf|armv8l) flatpak_install_arch="arm" ;;
              *) flatpak_install_arch="$arch_guess" ;;
            esac
          fi

          if [[ -n "$flatpak_install_arch" ]]; then
            flatpak_arch_args=(--arch "$flatpak_install_arch")
            log "Using Flatpak architecture: $flatpak_install_arch"
          fi
        }

        should_retry_without_deltas() {
          local output="$1"
          if [[ -z "$output" ]]; then
            return 1
          fi

          if printf '%s\n' "$output" | grep -Eiq 'repo/deltas|static delta|delta.+failed'; then
            return 0
          fi
          return 1
        }

        run_flatpak_install() {
          local output_var="$1"
          shift
          local -a cmd=("$@")
          local deltas_disabled=0

          while true; do
            local install_output
            if install_output=$("''${cmd[@]}" 2>&1); then
              printf -v "$output_var" '%s' "$install_output"
              return 0
            fi

            local status=$?
            printf -v "$output_var" '%s' "$install_output"

            if [[ $deltas_disabled -eq 0 ]] && should_retry_without_deltas "$install_output"; then
              deltas_disabled=1
              log "  Static delta fetch failed; retrying without deltas..."
              cmd+=(--no-static-deltas)
              continue
            fi

            return $status
          done
        }

        detect_flatpak_install_arch

        backup_legacy_flatpak_configs() {
          local -a targets=(
            "$HOME/.config/flatpak"
            "$HOME/.local/share/flatpak/overrides"
            "$HOME/.local/share/flatpak/remotes.d"
          )
          local backup_root="$HOME/.local/share/flatpak/managed-backups"
          local timestamp
          local performed=false
          local encountered_error=false

          timestamp="$(date +%Y%m%d_%H%M%S)"

          for path in "''${targets[@]}"; do
            if [[ ! -e "$path" && ! -L "$path" ]]; then
              continue
            fi

            if [[ -d "$path" && ! -L "$path" ]]; then
              if [[ -z "$(find "$path" -mindepth 1 -print -quit 2>/dev/null)" ]]; then
                continue
              fi
            fi

            local relative="''${path#"$HOME"/}"
            if [[ "$relative" == "$path" ]]; then
              relative="$(basename "$path")"
            fi

            local relative_dir="''${relative%/*}"
            if [[ "$relative_dir" == "$relative" ]]; then
              relative_dir="."
            fi

            local dest_dir="$backup_root/$timestamp/$relative_dir"
            local dest_path
            dest_path="$dest_dir/$(basename "$path")"

            if mkdir -p "$dest_dir" 2>/dev/null \
              && cp -a "$path" "$dest_path" 2>/dev/null; then
              rm -rf "$path" 2>/dev/null || true
              performed=true
              log "Backed up legacy Flatpak path $path -> $dest_path"
            else
              encountered_error=true
              log "Failed to back up legacy Flatpak path $path" >&2
            fi
          done

          mkdir -p "$HOME/.config/flatpak" 2>/dev/null || true

          if [[ "$performed" == true ]]; then
            log "Legacy Flatpak configuration preserved under $backup_root/$timestamp"
          fi

          if [[ "$encountered_error" == true ]]; then
            return 1
          fi

          return 0
        }

        reset_flatpak_repo_if_corrupted() {
          local repo_dir="$HOME/.local/share/flatpak/repo"
          local repo_config="$repo_dir/config"
          local repo_parent="$HOME/.local/share/flatpak"
          local repair_output=""

          mkdir -p "$repo_parent" 2>/dev/null || true

          # Check if repository is valid and complete
          if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
            return 0
          fi

          # Detect corrupted repository (exists but missing essential directories)
          if [[ -e "$repo_dir" ]]; then
            if [[ ! -f "$repo_config" || ! -d "$repo_dir/objects" ]]; then
              log "Detected corrupted Flatpak repository, removing and reinitializing..." >&2
              rm -rf "$repo_dir" 2>/dev/null || true
            fi
          fi

          if [[ ! -e "$repo_dir" ]]; then
            log "Initializing Flatpak repository under ''${repo_dir#"$HOME"/}"
          fi

          if ! mkdir -p "$repo_dir" 2>/dev/null; then
            log "Unable to recreate $repo_dir" >&2
            return 1
          fi

          # Try ostree initialization first (more reliable for fresh repos)
          if command -v ostree >/dev/null 2>&1; then
            local ostree_output=""
            ostree_output="$(
              ostree --repo="$repo_dir" init --mode=bare-user-only 2>&1
            )"
            local ostree_status=$?

            if [[ -n "$ostree_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line"
              done <<<"$ostree_output"
            fi

            if [[ $ostree_status -eq 0 && -f "$repo_config" ]]; then
              log "Flatpak repository initialized via ostree"
              # Run flatpak repair to finalize the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            fi

            # ostree init failed - manually create essential directory structure
            log "ostree init failed, creating repository structure manually..."

            # Remove any partial initialization and start fresh
            rm -rf "$repo_dir" 2>/dev/null || true
            mkdir -p "$repo_dir" 2>/dev/null || true

            # Create essential directories
            if ! (mkdir -p "$repo_dir/objects" "$repo_dir/tmp" \
                  "$repo_dir/refs/heads" "$repo_dir/refs/remotes" \
                  "$repo_dir/state" 2>/dev/null); then
              log "Failed to create repository directory structure" >&2
              return 1
            fi

            # Create minimal config file for bare-user-only mode
            if ! cat > "$repo_config" 2>/dev/null <<'OSTREE_CONFIG'
[core]
repo_version=1
mode=bare-user-only
OSTREE_CONFIG
            then
              log "Failed to create repository config file" >&2
              return 1
            fi

            # Verify the manual structure was created
            if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
              log "Flatpak repository structure created manually"
              # Run flatpak repair to finalize and validate the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            else
              log "Repository structure verification failed" >&2
              return 1
            fi
          fi

          # Fall back to flatpak repair
          repair_output="$(
            flatpak --user repair 2>&1
          )"
          local repair_status=$?

          if [[ -n "$repair_output" ]]; then
            while IFS= read -r line; do
              log "  ↳ $line"
            done <<<"$repair_output"
          fi

          if [[ $repair_status -ne 0 ]]; then
            log "flatpak repair reported an error while attempting to recover the repository" >&2
          fi

          if [[ -f "$repo_config" ]]; then
            log "Flatpak repository initialized"
            return 0
          fi

          log "Flatpak repository configuration still missing after recovery attempts" >&2
          return 1
        }

        check_app_availability() {
          local app_id="$1"
          local user_output
          local user_status
          local system_output
          local system_status

          availability_message=""

          user_output="$(flatpak --user remote-info "''${flatpak_arch_args[@]}" "$remote_name" "$app_id" 2>&1 || true)"
          user_status=$?
          if [[ $user_status -eq 0 ]]; then
            return 0
          fi

          system_output="$(flatpak remote-info "''${flatpak_arch_args[@]}" "$remote_name" "$app_id" 2>&1 || true)"
          system_status=$?
          if [[ $system_status -eq 0 ]]; then
            return 0
          fi

          availability_message="$user_output"
          if [[ -n "$availability_message" && -n "$system_output" ]]; then
            availability_message+=$'
'
          fi
          availability_message+="$system_output"

          if printf '%s
' "$availability_message" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
            return 3
          fi

          return 1
        }

        ensure_remote() {
          if flatpak --user remotes --columns=name | awk 'NR == 1 && $1 == "Name" { next } { print $1 }' | grep -Fxq "$remote_name"; then
            log "Remote $remote_name already configured"
            return 0
          fi

          local -a remote_sources=()
          remote_sources+=("$remote_url")
          if [[ -n "$remote_fallback_url" && "$remote_fallback_url" != "$remote_url" ]]; then
            remote_sources+=("$remote_fallback_url")
          fi

          log "Adding Flatpak remote $remote_name"

          local source=""
          for source in "''${remote_sources[@]}"; do
            local from_output=""
            if from_output=$(flatpak --user remote-add --if-not-exists --from "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source (--from)"
              return 0
            fi

            if [[ -n "$from_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$from_output"
            fi

            local direct_output=""
            if direct_output=$(flatpak --user remote-add --if-not-exists "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source"
              return 0
            fi

            if [[ -n "$direct_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$direct_output"
            fi
          done

          log "Failed to add remote $remote_name after trying: ''${remote_sources[*]}" >&2
          return 1
        }

        install_app() {
          local app_id="$1"
          local current_num="''${2:-}"
          local total_num="''${3:-}"
          local progress_prefix=""
          
          if [[ -n "$current_num" && -n "$total_num" ]]; then
            progress_prefix="[$current_num/$total_num] "
          fi

          if flatpak --user info "$app_id" >/dev/null 2>&1; then
            log "''${progress_prefix}✓ $app_id (already installed)"
            return 0
          fi

          log "''${progress_prefix}Installing $app_id..."
          
          local availability_status=0
          check_app_availability "$app_id"
          availability_status=$?
          if [[ $availability_status -ne 0 ]]; then
            if [[ $availability_status -eq 3 ]]; then
              log "''${progress_prefix}⊘ $app_id (not available for this architecture)"
              if [[ -n "$availability_message" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$availability_message"
              fi
              return 0
            fi

            log "Unable to query metadata for $app_id prior to installation" >&2
            if [[ -n "$availability_message" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$availability_message"
            fi
            return 1
          fi

          local attempt=1
          while (( attempt <= 3 )); do
            local install_output=""
            # Use --or-update to install or update to latest version
            local -a install_cmd=(flatpak --noninteractive --assumeyes --user install --or-update)
            install_cmd+=("''${flatpak_arch_args[@]}")
            install_cmd+=("$remote_name" "$app_id")
            if run_flatpak_install install_output "''${install_cmd[@]}"; then
              log "''${progress_prefix}✓ $app_id (installed)"
              return 0
            fi

            if printf '%s
' "$install_output" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
              log "Flatpak $app_id not available on $remote_name; skipping"
              if [[ -n "$install_output" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$install_output"
              fi
              return 0
            fi

            log "Attempt $attempt failed for $app_id" >&2
            if [[ -n "$install_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$install_output"
            fi
            sleep $(( attempt * 2 ))
            (( attempt += 1 ))
          done

          log "Giving up on $app_id after repeated failures" >&2
          return 1
        }

        batch_install_missing_apps() {
          # Accepts the package array as arguments to avoid hard-coding globals.
          local -a source_packages=("$@")
          if [[ ''${#source_packages[@]} -le 1 ]]; then
            return 1
          fi

          local -a to_install=()
          local pkg_id
          for pkg_id in "''${source_packages[@]}"; do
            if flatpak --user info "$pkg_id" >/dev/null 2>&1; then
              continue
            fi
            to_install+=("$pkg_id")
          done

          if [[ ''${#to_install[@]} -le 1 ]]; then
            return 1
          fi

          log "Attempting batch Flatpak install for ''${#to_install[@]} application(s)..."
          local install_output=""
          # Use --or-update to install or update to latest version
          local -a install_cmd=(flatpak --noninteractive --assumeyes --user install --or-update)
          install_cmd+=("''${flatpak_arch_args[@]}")
          install_cmd+=("$remote_name" "''${to_install[@]}")
          if run_flatpak_install install_output "''${install_cmd[@]}"; then
            if [[ -n "$install_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line"
              done <<<"$install_output"
            fi
            return 0
          fi

          if [[ -n "$install_output" ]]; then
            while IFS= read -r line; do
              log "  ↳ $line" >&2
            done <<<"$install_output"
          fi
          return 1
        }

        if [[ -f "$managed_state_marker" ]]; then
          log "Managed Flatpak directories already prepared; skipping legacy backup"
        else
          if backup_legacy_flatpak_configs; then
            touch "$managed_state_marker" 2>/dev/null || true
          fi
        fi

        if ! reset_flatpak_repo_if_corrupted; then
          log "Flatpak repository recovery failed" >&2
          exit 1
        fi

        ensure_remote || exit 1

        # shellcheck disable=SC2206
        packages=( ${packageArgs} )
        if [ ''${#packages[@]} -eq 0 ]; then
          log "No Flatpak packages declared; exiting"
          exit 0
        fi

        # Count already installed vs to-install
        already_installed=0
        to_install_count=0
        for pkg_id in "''${packages[@]}"; do
          if flatpak --user info "$pkg_id" >/dev/null 2>&1; then
            (( already_installed += 1 ))
          else
            (( to_install_count += 1 ))
          fi
        done
        
        total_count=''${#packages[@]}
        log "=========================================="
        log "Flatpak Installation Summary"
        log "=========================================="
        log "Total apps in profile: $total_count"
        log "Already installed:     $already_installed"
        log "To install:            $to_install_count"
        log "=========================================="
        
        if [[ $to_install_count -gt 0 ]]; then
          log "Starting installation of $to_install_count app(s)..."
          batch_install_missing_apps "''${packages[@]}" || true
        else
          log "All apps already installed. Checking for updates..."
        fi

        failures=0
        current=0
        for app_id in "''${packages[@]}"; do
          (( current += 1 ))
          if ! install_app "$app_id" "$current" "$total_count"; then
            failures=1
          fi
        done

        log "Refreshing Flatpak metadata..."
        flatpak --user update --noninteractive --appstream || log "Appstream refresh failed (continuing)" >&2
        flatpak --user update --noninteractive || log "Flatpak update failed (continuing)" >&2

        # Final summary
        final_installed=$(flatpak --user list --app --columns=application 2>/dev/null | wc -l)
        log "=========================================="
        log "Flatpak Installation Complete"
        log "=========================================="
        log "Apps now installed: $final_installed"
        if [[ $failures -eq 0 ]]; then
          log "Status: ✓ All apps installed successfully"
        else
          log "Status: ⚠ Some apps failed to install"
        fi
        log "=========================================="

        exit $failures
      '';
    };
  nixAiHelpScript =
    pkgs.writeShellApplication {
      name = "nix-ai-help";
      text = ''
        set -euo pipefail

        usage() {
          cat <<'USAGE'
Usage: nix-ai-help [topic]

Topics:
  overview        High-level deployment summary and workflow guidance (default)
  flakes          Flake management, updates, and switch best practices
  home-manager    Home Manager integration details and troubleshooting tips
  flatpak         Declarative Flatpak management overview
  security        Hardening reminders tailored to AIDB developer workstations
  options         Discovering module options and documenting overrides
  resources       Curated references for deeper reading
  help            Display this help message
USAGE
        }

        print_overview() {
          cat <<'OVERVIEW'
NixOS Quick Deploy provisions a reproducible AIDB workstation using:
  • A NixOS flake that stitches together system modules and Home Manager
  • Declarative user configuration driven by home-manager from nix-community
  • nix-flatpak to install GUI tooling under ~/.local/share/flatpak declaratively

Recommended workflow:
  1. Track all customisations inside configuration.nix and home.nix
  2. Apply system changes with: sudo nixos-rebuild switch --flake .#HOSTNAME
  3. Update user profiles with: home-manager switch --flake .#USERNAME
  4. Review build plans using nix flake check before activating major upgrades
OVERVIEW
        }

        print_flakes() {
          cat <<'FLAKES'
Flake hygiene tips inspired by https://wiki.nixos.org/wiki/Flakes:
  • Pin channels through the flake inputs block and use follows= for reuse
  • Refresh inputs routinely: nix flake update --commit-lock-file
  • Validate changes locally: nix flake check and nixos-rebuild test --flake
  • For experimental packages, add an overlay or extra input such as nixpkgs-unstable
FLAKES
        }

        print_home_manager() {
          cat <<'HM'
Home Manager integration (https://github.com/nix-community/home-manager):
  • Enable programs via home-manager.users.<name>.imports in the flake outputs
  • Prefer systemd.user.startServices = lib.mkDefault ... to cooperate with sd-switch
  • Inspect generated options: home-manager help or home-manager options
  • Keep home.stateVersion aligned with the target channel before upgrades
HM
        }

        print_flatpak() {
          cat <<'FLATPAK'
Flatpak automation via nix-flatpak (https://github.com/gmodena/nix-flatpak):
  • Packages listed under xdg.portal.enable and xdg.desktopEntries stay in sync
  • The deployment script installs Flatpak apps directly via flathub remote
  • Use flatpak list --user --app to see installed applications
FLATPAK
        }

        print_security() {
          cat <<'SECURITY'
Security checklist (see https://wiki.nixos.org/wiki/Security):
  • Harden shells with pam configuration and consider enabling security.apparmor
  • Audit services enabled by configuration.nix using nixos-rebuild test --flake
  • Rotate secrets in ~/.config/gitea and ~/.config/huggingface regularly
  • Track upstream advisories via https://nixos.org/manual/nixos/stable/#sec-upgrading
SECURITY
        }

        print_options() {
          cat <<'OPTIONS'
Discovering options quickly:
  • nix search nixpkgs <pattern> for package discovery
  • nixos-option <path> --json | jq '.' to inspect live system values
  • home-manager option search '<pattern>' to explore user-level modules
  • Web catalogue: https://search.nixos.org/options?channel=26.05
OPTIONS
        }

        print_resources() {
          cat <<'RESOURCES'
Essential references leveraged by this environment:
  • nix-community/home-manager – authoritative module documentation
  • NixOS manual – https://nixos.org/manual/nixos/stable/
  • Populated examples: github.com/nomadics9/NixOS-Flake and github.com/novoid/nixos-config
  • Declarative desktop apps: github.com/gmodena/nix-flatpak and github.com/fufexan/dotfiles
  • Security hardening: https://wiki.nixos.org/wiki/Security
  • COSMIC-focused setups: github.com/rascal999/maxos
RESOURCES
        }

        if [ "$#" -eq 0 ]; then
          topic="overview"
        else
          topic="$1"
        fi

        case "$topic" in
          overview)
            print_overview
            ;;
          flakes)
            print_flakes
            ;;
          home-manager|homemanager)
            print_home_manager
            ;;
          flatpak)
            print_flatpak
            ;;
          security)
            print_security
            ;;
          options)
            print_options
            ;;
          resources)
            print_resources
            ;;
          help|-h|--help)
            usage
            ;;
          *)
            printf 'Unknown topic: %s\n\n' "$topic" >&2
            usage >&2
            exit 1
            ;;
        esac
      '';
    };
  flatpakManagedInstallScriptExe = lib.getExe flatpakManagedInstallScript;
  pythonAi =
    pythonWithFallback.override {
      packageOverrides = commonPythonOverrides;
    };
  # ========================================================================
  # Python AI/ML Environment
  # ========================================================================
  # Comprehensive Python environment for AI/ML development including:
  # - Deep Learning: PyTorch, TensorFlow with GPU support
  # - Transformers: HuggingFace transformers, tokenizers, datasets
  # - LLM Frameworks: LangChain, LlamaIndex with all integrations
  # - Vector DBs: Chromadb, Qdrant, Pinecone, FAISS
  # - Data Science: NumPy, Pandas, Polars, Scikit-learn
  # - Visualization: Matplotlib, Seaborn, Gradio
  # - Development: JupyterLab, IPython, Black, Ruff, MyPy
  #
  # Optional packages to add if needed:
  # - jupyter-ai              # Jupyter AI chatbot (requires API keys)
  # - keras                   # High-level neural networks API
  # - xgboost                 # Gradient boosting framework
  # - lightgbm                # Light gradient boosting machine
  # - catboost                # Categorical gradient boosting
  # - optuna                  # Hyperparameter optimization
  # - mlflow                  # ML experiment tracking
  # - wandb                   # Weights & Biases tracking
  # - ray                     # Distributed computing framework
  # - streamlit               # Web app framework for ML

  pythonAiEnv =
    pythonAi.withPackages (ps:
      let
        # Core Python packages that should always be available
        base = with ps; [
          pip
          setuptools
          wheel
          # Jupyter and Interactive Development
          # jupyterlab - removed, using Flatpak version (org.jupyter.JupyterLab)
          ipykernel
          ipython
          ipywidgets
          notebook
          # Data Science Core
          pandas
          numpy
          scikit-learn
          matplotlib
          seaborn
          # Code Quality Tools
          black
          ruff
          mypy
          pylint
          # AI/ML Fundamentals
          accelerate
          datasets
          diffusers
          peft
          safetensors
          sentencepiece
          tokenizers
          transformers
          evaluate
          # gradio removed - causes typer vs typer-slim conflict in nixpkgs
          # Install via pip if needed: pip install gradio
          # Data Processing (Modern Alternatives)
          polars               # Fast DataFrame library (Rust-based)
          # LLM & AI APIs (Required)
          openai               # OpenAI API client
          anthropic            # Anthropic API client
          # Note: dask often causes build issues, added conditionally below
          # Deep Learning Frameworks (ALL REQUIRED - NOT OPTIONAL)
          torch
          torchaudio
          torchvision
          tensorflow
          bitsandbytes
          # LangChain Ecosystem
          langchain
          langchain-openai
          langchain-community
          langchain-core
          # LlamaIndex Ecosystem
          # llama-index removed - causes typer vs typer-slim conflict in nixpkgs
          # Install via pip if needed: pip install llama-index llama-index-core
          # llama-index
          # llama-index-core
          # Vector Databases & Embeddings
          # chromadb removed - causes typer vs typer-slim conflict with spacy in nixpkgs
          # Install via pip if needed: pip install chromadb
          qdrant-client
          pinecone-client
          faiss
          sentence-transformers
          # MCP & Agent Tooling
          # litellm removed - causes typer vs typer-slim conflict in nixpkgs
          # Install via pip if needed: pip install litellm
          tiktoken
          fastapi
          uvicorn
          httpx
          aiohttp
          websockets
          pydantic
          # typer removed - gradio brings its own typer dependency
          rich
          
          # AI Agent Frameworks (December 2025)
          # Note: Some cutting-edge packages need pip install
          # Use: pip install -r ~/.config/ai-agents/requirements.txt
          instructor              # Structured LLM outputs
          sqlalchemy
          psycopg2
          asyncpg              # PostgreSQL async driver for AIDB
          redis
          alembic
          # AIDB Additional Requirements
          beautifulsoup4       # Web scraping for federation
          tabulate             # Table formatting
          cryptography         # Ed25519 signatures for Guardian
          inotify-simple       # Linux file watching
          watchdog             # macOS/Windows file watching
          # Specialized AI Tools
          llama-cpp-python
          # Data Processing
          duckdb
          dask
          dask-ml
        ];
      in
        base
    );
  pythonAiInterpreterPath = "${pythonAiEnv}/bin/python3";
  huggingfaceReadme = ''
    Hugging Face configuration lives here.

    - Store your personal access token in the file "token" within this directory (never commit it).
    - CLI caches and credentials are isolated from Git repositories.
    - The hf-model-sync helper will reuse this token and cache when downloading models.
  '';
  openWebUiReadme = ''
    Persistent storage for Open WebUI when launched with the open-webui-run helper.

    - All chat history, uploads, and custom prompts are written here.
    - The helper binds this directory into the container at /app/backend/data.
    - Remove this directory to reset the Open WebUI state safely.
    - When using podman-ai-stack, this path is shared with the Open WebUI container managed by the stack.
  '';
  podmanAiStackReadme = ''
    Podman AI Stack shared storage.

    - llama-cpp-models/: persistent GGUF cache for the llama.cpp server.
    - open-webui/: shared chat history for the Open WebUI container.
    - qdrant/: vector database state for embeddings and RAG pipelines.
    - mindsdb/: MindsDB database files for AI-assisted SQL workflows.

    Use the podman-ai-stack helper to manage the lifecycle of the stack.
    The helper orchestrates Home Manager's services.podman quadlets and keeps
    this directory synchronized with container volumes.
  '';
  giteaDomain = "@HOSTNAME@";
  giteaHttpPort = 3000;
  giteaSshPort = 2222;
  giteaRootUrl = "http://${giteaDomain}:${toString giteaHttpPort}/";
  giteaSharedSettings = {
    server = {
      PROTOCOL = "http";
      DOMAIN = giteaDomain;
      HTTP_ADDR = "0.0.0.0";
      HTTP_PORT = giteaHttpPort;
      ROOT_URL = giteaRootUrl;
      STATIC_ROOT_PATH = "%(APP_DATA_PATH)s/public";
      ENABLE_GZIP = true;
      LFS_START_SERVER = true;
      LFS_JWT_SECRET = @GITEA_LFS_JWT_SECRET@;
      DISABLE_SSH = false;
      SSH_DOMAIN = giteaDomain;
      SSH_PORT = giteaSshPort;
      SSH_LISTEN_PORT = giteaSshPort;
      START_SSH_SERVER = true;
      LANDING_PAGE = "explore";
    };
    database = {
      DB_TYPE = "sqlite3";
      PATH = "%(GITEA_WORK_DIR)s/gitea.db";
      LOG_SQL = false;
    };
    repository = {
      ROOT = "%(GITEA_WORK_DIR)s/repositories";
      FORCE_PRIVATE = false;
    };
    packages.ENABLED = true;
    actions = {
      ENABLED = true;
      # Gitea 1.25+ only accepts "github" or "internal" - "https://gitea.com" fails
      DEFAULT_ACTIONS_URL = "github";
    };
    indexer = {
      ISSUE_INDEXER_TYPE = "bleve";
      ISSUE_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/issues.bleve";
      REPO_INDEXER_ENABLED = true;
      REPO_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/repos.bleve";
    };
    ui = {
      DEFAULT_THEME = "arc-green";
      THEMES = "arc-green,auto,github";
      DEFAULT_SHOW_FULL_NAME = true;
    };
    service = {
      REGISTER_EMAIL_CONFIRM = false;
      DISABLE_REGISTRATION = false;
      REQUIRE_SIGNIN_VIEW = false;
      ENABLE_NOTIFY_MAIL = false;
    };
    security = {
      INSTALL_LOCK = true;
      PASSWORD_HASH_ALGO = "argon2";
      SECRET_KEY = @GITEA_SECRET_KEY@;
      INTERNAL_TOKEN = @GITEA_INTERNAL_TOKEN@;
    };
    oauth2.JWT_SECRET = @GITEA_JWT_SECRET@;
    log = {
      MODE = "console";
      LEVEL = "info";
    };
    lfs = {
      STORAGE_TYPE = "local";
      PATH = "%(GITEA_WORK_DIR)s/lfs";
    };
  };
  giteaSharedAppIni = lib.generators.toINI { } giteaSharedSettings;
  giteaAiIntegrations = ''
    {
      "agents": [
        {
          "name": "aider-openai",
          "command": [
            "aider",
            "--model",
            "gpt-4o-mini",
            "--repo",
            "%REPO_PATH%",
            "--no-auto-commits"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "AIDER_LOG_DIR": "%HOME%/.local/share/aider/logs"
          },
          "description": "Use aider to provide AI pair-programming suggestions for the current Gitea repository."
        },
        {
          "name": "tea-commit-summarizer",
          "command": [
            "tea",
            "ai",
            "summarize",
            "--repo",
            "%REPO_PATH%",
            "--model",
            "gpt-4o-mini"
          ],
          "environment": {
            "TEA_TOKEN": "ENV[TEA_TOKEN]"
          },
          "description": "Generate commit summaries with the Tea CLI leveraging configured AI providers."
        },
        {
          "name": "gpt-cli-local",
          "command": [
            "%HOME%/.local/bin/gpt-cli",
            "--provider",
            "openai",
            "--model",
            "${huggingfaceModelId}",
            "--base-url",
            "${huggingfaceTgiEndpoint}/v1"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "GPT_CLI_DEFAULT_PROVIDER": "openai"
          },
          "description": "Run ad-hoc completions against the bundled Hugging Face Text Generation Inference endpoint via gpt-cli."
        },
        {
          "name": "podman-ai-stack-status",
          "command": [
            "%HOME%/.local/bin/podman-ai-stack",
            "status"
          ],
          "environment": {},
          "description": "Inspect the health of the local Podman AI stack (Ollama, Open WebUI, Qdrant, MindsDB)."
        },
        {
          "name": "launch-cursor",
          "command": [
            "%HOME%/.local/bin/code-cursor"
          ],
          "environment": {},
          "description": "Open the Cursor IDE configured for local model development sessions."
        }
      ],
      "notes": "Populate the referenced environment variables with the appropriate API tokens to enable AI workflows. The helpers bridge local containers, Cursor, and CLI tooling."
    }
  '';
  obsidianAiReadme = ''
    Obsidian AI integrations bootstrap directory.

    - Run `obsidian-ai-bootstrap` to install the Text Generator and other AI plugins.
    - The helper links plugins to Open WebUI or remote OpenAI-compatible endpoints configured on this system.
    - You can drop additional plugin ZIP files in this directory and rerun the helper to install them declaratively.
  '';
  systemdStartServicesDefault =
    let
      startServicesOption = options.systemd.user.startServices or null;
      allowedEnums =
        let
          rawValues =
            if startServicesOption == null || !(startServicesOption ? type) then
              [ ]
            else if lib.isAttrs startServicesOption.type && startServicesOption.type ? enum then
              startServicesOption.type.enum
            else
              [ ];
          attempt = builtins.tryEval rawValues;
        in
        if attempt.success && lib.isList attempt.value then attempt.value else [ ];
      optionDefault =
        if startServicesOption != null && startServicesOption ? default then
          startServicesOption.default
        else
          null;
      supportsLegacy = lib.elem "legacy" allowedEnums;
      supportsSdSwitch = lib.elem "sd-switch" allowedEnums;
    in
    if supportsLegacy then
      "legacy"
    else if optionDefault != null then
      optionDefault
    else
      # Home Manager 25.05+ removed the legacy activator; defer to sd-switch
      # (true) when it is the only supported backend.
      if supportsSdSwitch then "sd-switch" else true;
in

{
  #imports = [
  #  ./nixos-improvements/testing.nix
  #];

  # Declarative Flatpak management is enabled via nix-flatpak in flake.nix
  # The module is already included in the flake's module list, so no manual import is required here

  nixpkgs = {
    config.allowUnfree = true;
    overlays = [ pythonOverridesOverlay ];
  };

  home.username = "HOMEUSERNAME";
  home.homeDirectory = "HOMEDIR";
  home.stateVersion = "STATEVERSION_PLACEHOLDER";  # Auto-detected from home-manager channel
  programs.home-manager.enable = true;

  # Home Manager 25.05 set startServices=true (sd-switch) and removed the legacy
  # activator. Prefer legacy where still available on older channels; otherwise
  # keep the upstream default to avoid evaluation failures on 25.05/25.11+.
  systemd.user.startServices = lib.mkDefault systemdStartServicesDefault;
  xdg.desktopEntries =
    let
      hiddenCosmicEntry = {
        type = "Application";
        name = "COSMIC Settings";
        exec = "cosmic-settings";
        icon = "cosmic-settings";
        categories = [ "Settings" "System" ];
        noDisplay = true;
        settings =
          lib.optionalAttrs (cosmicOnlyShowInValue != "") {
            OnlyShowIn = cosmicOnlyShowInValue;
          };
      };
    in
    lib.mkMerge [
      (lib.genAttrs cosmicSettingsDesktopFileNames (_: hiddenCosmicEntry))
      {
        "aidb-cosmic-settings" = {
          name = "COSMIC Settings";
          type = "Application";
          exec = "cosmic-settings";
          icon = "cosmic-settings";
          categories = [ "Settings" "System" ];
          startupNotify = true;
          settings =
            lib.optionalAttrs (cosmicOnlyShowInValue != "") {
              OnlyShowIn = cosmicOnlyShowInValue;
            };
        };
        "goose-desktop" = {
          name = "Goose Desktop";
          type = "Application";
          exec = "${pkgs.goose-cli}/bin/goose";
          icon = "applications-engineering";
          categories = [ "Development" "Utility" ];
          terminal = false;
          startupNotify = true;
          comment = "Launch the Goose AI workspace";
        };
      }
    ];
  # ============================================================================
  # Home Packages (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Adjust the lists below to tailor developer tooling.
  # Preflight/runtime critical tools (e.g., podman, jq, curl) should remain enabled.
  home.packages =
    let
      # Fix gpt4all to work with Qt6 6.10+ where GuiPrivate requires explicit find_package
      gpt4all-fixed = pkgs.gpt4all.overrideAttrs (oldAttrs: {
        postPatch = (oldAttrs.postPatch or "") + ''
          # Fix Qt6::GuiPrivate CMake target for Qt 6.10+
          # Qt 6.10 requires explicit find_package for private modules
          sed -i '/find_package(Qt6/a \
find_package(Qt6 COMPONENTS GuiPrivate REQUIRED)' CMakeLists.txt
        '';
      });

      # ALL AI command-line packages are REQUIRED (not optional)
      aiCommandLinePackages = with pkgs; [
        gpt4all-fixed  # Fixed for Qt6 6.10+ GuiPrivate compatibility
        llama-cpp
      ];
      # Optional GUI frontends for CLI-first network/security tooling.
      networkGuiPackages =
        lib.optionals (pkgs ? zenmap) [
          pkgs.zenmap             # Graphical frontend for nmap scans
        ];
      optionalDevTools =
        lib.optionals (pkgs ? pnpm) [ pkgs.pnpm ]
        ++ lib.optionals (pkgs ? biome) [ pkgs.biome ]
        ++ lib.optionals (pkgs ? pixi) [ pkgs.pixi ]
        ++ lib.optionals (pkgs ? ast-grep) [ pkgs.ast-grep ]
        ++ lib.optionals (pkgs ? nix-fast-build) [ pkgs.nix-fast-build ]
        ++ lib.optionals (pkgs ? lorri) [ pkgs.lorri ]
        ++ lib.optionals (pkgs ? cachix) [ pkgs.cachix ]
        ++ lib.optionals (pkgs ? distrobox) [ pkgs.distrobox ];

      optionalRustGoAccelerators =
        lib.optionals (pkgs ? sccache) [ pkgs.sccache ]
        ++ lib.optionals (pkgs ? cargo-binstall) [ pkgs.cargo-binstall ]
        ++ lib.optionals (pkgs ? gofumpt) [ pkgs.gofumpt ]
        ++ lib.optionals (pkgs ? staticcheck) [ pkgs.staticcheck ];

      optionalTerminalProductivity =
        lib.optionals (pkgs ? atuin) [ pkgs.atuin ]
        ++ lib.optionals (pkgs ? zellij) [ pkgs.zellij ];

      basePackages =
        [
          nixAiHelpScript
          # Python (REQUIRED for AIDB and AI model tooling)
          pythonAiEnv
        ]
        ++ optionalDevTools
        ++ optionalRustGoAccelerators
        ++ optionalTerminalProductivity
        ++ nixAiToolsPackageList  # Install helper binaries exported by numtide/nix-ai-tools when available
        ++ (with pkgs; [
          # ========================================================================
          # AIDB v4.0 Requirements (CRITICAL - Must be installed)
          # ========================================================================

          podman                  # Container runtime for AIDB
          podman-compose          # Docker-compose compatibility
          podman-tui              # Terminal dashboard for Podman and containers
          sqlite                  # Tier 1 Guardian database
          openssl                 # Cryptographic operations
          bc                      # Basic calculator
          qalculate-qt            # Advanced calculator (replaces Flatpak dependency)
          goose-cli               # Goose AI CLI/Desktop provided declaratively
          inotify-tools           # File watching for Guardian

          # ========================================================================
          # Core NixOS Development Tools
          # ========================================================================

          # Nix tools
          # Language servers
          nil                     # Nix language server for IDE support
          nixd                    # Alternative Nix language server with advanced features

          # Package creation & development
          nurl                    # Generate Nix fetcher calls from repository URLs
          nix-init                # Interactive tool to generate Nix packages
          nix-update              # Automatically update package versions

          # Dependency analysis & visualization
          nix-tree                # Visualize Nix dependencies
          nix-index               # Index Nix packages for fast searching
          nvd                     # Nix/NixOS package version diff (better than nix-diff)
          nix-diff                # Compare Nix derivations

          # Build & fetch utilities
          nix-prefetch-git        # Prefetch git repositories
          nix-output-monitor      # Better build output
          cachix                  # Binary cache service CLI

          # Code quality & formatting
          nixpkgs-fmt             # Nix code formatter
          alejandra               # Alternative Nix formatter
          statix                  # Linter for Nix
          deadnix                 # Find dead Nix code

          # Development environments
          devenv                  # Fast, declarative dev environments using Nix

          # Storage & maintenance
          nix-du                  # Disk usage for Nix store

          # Package review
          nixpkgs-review          # Review nixpkgs PRs

          # ========================================================================
          # Development Tools
          # ========================================================================

          # Version control
          # Note: git installed via programs.git below (prevents collision)
          git-crypt               # Transparent file encryption in git
          tig                     # Text-mode interface for git
          lazygit                 # Terminal UI for git commands
          git-lfs                 # Large file storage (required for Hugging Face repos)

          # Text editors
          # Note: vim installed via programs.vim below (prevents collision)
          neovim                  # Modern Vim fork with async support
          # Note: vscodium installed via programs.vscode below
          code-cursor             # Cursor IDE (AI-powered editor)

          # Web browsers are now installed via Flatpak for better sandboxing:
          # Firefox: "org.mozilla.firefox" in services.flatpak.packages
          # Chromium: Available as "com.google.Chrome" if needed
          # (Both still available in home.packages comments if NixOS versions preferred)

          # Modern CLI tools
          ripgrep                 # Fast recursive grep (rg)
          ripgrep-all             # Ripgrep with PDF, archive support
          fd                      # Fast alternative to find
          deno                    # Secure TypeScript runtime for MCP tooling
          bun                     # High-performance JavaScript runtime
          bubblewrap              # Sandboxing utility for tool execution
          firejail                # Sandbox profiles for desktop/CLI apps
          criu                    # Checkpoint/restore utilities
          postgresql              # PostgreSQL client tools (psql)
          redis                   # Redis CLI tools
          fzf                     # Fuzzy finder for command line
          bat                     # Cat clone with syntax highlighting
          eza                     # Modern replacement for ls
          jq                      # JSON processor
          yq                      # YAML processor
          direnv                  # Automatic per-directory environment loading
          nix-direnv              # Direnv integration with Nix flakes
          choose                  # Human-friendly cut/awk alternative
          dust                    # Intuitive disk usage (du)
          duf                     # Disk usage/free utility (df)
          broot                   # Tree view with navigation
          dog                     # DNS lookup utility (dig)
          shellcheck              # Shell script static analysis
          uv                      # Drop-in replacement for pip

          # Terminal tools
          # Note: alacritty installed via programs.alacritty below (prevents collision)
          tmux                    # Terminal multiplexer
          zellij                  # Modern terminal workspace (Rust alternative to tmux)
          screen                  # Terminal session manager
          mosh                    # Mobile shell (SSH alternative)
          asciinema               # Terminal session recorder

          # File management
          ranger                  # Console file manager with VI bindings
          dos2unix                # Convert text file line endings
          unrar                   # Extract RAR archives
          p7zip                   # 7-Zip file archiver
          file                    # File type identification
          rsync                   # Fast incremental file transfer
          rclone                  # Rsync for cloud storage

          # Network tools
          wget                    # Network downloader
          curl                    # Transfer data with URLs
          netcat-gnu              # Network utility for TCP/UDP
          socat                   # Multipurpose relay (SOcket CAT)
          mtr                     # Network diagnostic tool (traceroute/ping)
          nmap                    # Network exploration and security scanner
          wireshark               # GUI network protocol analyzer (ships tshark CLI)

          # Security & privacy tooling
          clamav                  # Antivirus engine and CLI scanner
          clamtk                  # GTK frontend for ClamAV scanning
          # rkhunter is currently unavailable in nixpkgs; re-enable once restored upstream
          # rkhunter                # Rootkit hunter integrity scanner
          lynis                   # Auditing tool for UNIX-based systems (includes rootkit detection)
          # chkrootkit has been removed from nixpkgs (unmaintained/archived upstream, didn't work on NixOS)
          # Use lynis for comprehensive security auditing including rootkit detection, or aide for file integrity
          aide                    # Advanced Intrusion Detection Environment (file integrity & rootkit detection)
          keepassxc               # Cross-platform password manager (GUI)
          gnupg                   # GNU Privacy Guard for encryption workflows
          seahorse                # GNOME credential manager for GnuPG/SSH
          pinentry-gnome3         # Pinentry dialog compatible with COSMIC/GNOME
          libsecret               # Library for storing/retrieving passwords (required for OS keyring)
          gcr_4                   # GNOME crypto library (keyring UI components + SSH agent)
          # YubiKey Manager Qt was removed because upstream marked it EOL and nixpkgs flags it insecure.
          # Install `yubikey-manager` (CLI) or `yubioath-flutter` manually if YubiKey support is required.

          # System tools
          htop                    # Interactive process viewer
          btop                    # Resource monitor with modern UI
          gnome-disk-utility # GUI disk manager and formatter
          parted                  # Command-line partitioning utility
          flatpak                 # Flatpak CLI for sandboxed desktop apps
          tree                    # Display directory tree structure
          unzip                   # Extract ZIP archives
          zip                     # Create ZIP archives
          # bc already included above in utility tools section
          efibootmgr              # Modify EFI Boot Manager variables

          # Observability & monitoring stack
          glances                 # System dashboard with sensor, process, network metrics
          grafana                 # Metrics visualization web UI
          prometheus              # Metrics collection server
          # loki/promtail removed - use grafana-loki in engineeringToolsPackages (includes both)
          vector                  # Data pipeline for logs and metrics
          cockpit                 # Web-based host management and reporting

          # ========================================================================
          # Programming Languages & Tools
          # ========================================================================


          # Additional languages
          go                      # Go programming language
          rustc                   # Rust compiler
          cargo                   # Rust package manager
          ruby                    # Ruby programming language

          # Development utilities
          gnumake                 # GNU Make build automation
          gcc                     # GNU C/C++ compiler
          cmake                   # Cross-platform build system
          # ninja removed - conflicts with Python environment (provides ninja)

          # ========================================================================
          # Web Development
          # ========================================================================
          nodejs_22               # Node.js JavaScript runtime v22
          yarn                    # Alternative npm package manager
          # bun and deno already included above in MCP tooling section
          typescript              # TypeScript compiler

          # Frontend tools
          tailwindcss             # Utility-first CSS framework CLI
          esbuild                 # Extremely fast JS bundler
          # sass                  # Sass CSS preprocessor (uncomment if needed)

          # Backend frameworks CLI
          # prisma                # Database ORM (uncomment if needed)
          # drizzle-kit           # TypeScript ORM (uncomment if needed)

          # ========================================================================
          # Virtualization & Emulation
          # ========================================================================
          # Core virtualization tools for safe NixOS development and testing
          # These allow testing configurations in VMs before applying to base system

          qemu            # Machine emulator and virtualizer
          qemu_kvm        # QEMU with KVM acceleration
          virtiofsd       # VirtIO filesystem daemon
          # virt-manager - removed, using Flatpak version (org.virt_manager.virt-manager)
          # virt-viewer - removed, using Flatpak version (included with virt-manager)
          libvirt         # Libvirt CLI tools (virsh, virt-install, etc.)
          # Note: virt-install is provided by system-level virtualization.nix if available
          virt-top        # VM resource monitoring
          libguestfs-with-appliance # Guest filesystem tools (includes libguestfs)
          vagrant         # VM provisioning and automation tool
          quickemu        # Quick VM testing (Windows, macOS, Linux ISOs)
          bridge-utils    # Network bridge management for VMs

          # ========================================================================
          # Desktop Environment - Cosmic (Rust-based modern desktop)
          # ========================================================================

          #cosmic-edit             # Cosmic text editor
          #cosmic-files            # Cosmic file manager
          #cosmic-term             # Cosmic terminal

          # ========================================================================
          # ZSH Configuration
          # ========================================================================

          # Note: zsh installed via programs.zsh below (prevents collision)
          zsh-syntax-highlighting # Command syntax highlighting
          #zsh-autosuggestions     # Command suggestions from history
          zsh-completions         # Additional completion definitions
          zsh-powerlevel10k       # Powerlevel10k theme
          grc                     # Generic colorizer for commands
          pay-respects            # Modern replacement for 'fuck'

          # ========================================================================
          # Fonts (Required for Powerlevel10k)
          # ========================================================================

          nerd-fonts.meslo-lg     # MesloLGS Nerd Font (recommended for p10k)
          nerd-fonts.fira-code    # Fira Code Nerd Font with ligatures
          nerd-fonts.jetbrains-mono # JetBrains Mono Nerd Font
          nerd-fonts.hack         # Hack Nerd Font
          font-awesome            # Font Awesome icon font
          powerline-fonts         # Powerline-patched fonts

          # ========================================================================
          # Text Processing
          # ========================================================================

          tldr                    # Simplified man pages
          cht-sh                  # Community cheat sheets
          pandoc                  # Universal document converter

          # ========================================================================
          # AI/ML Development Tools (Code Review Recommendations)
          # ========================================================================

          # Vector Search & Databases
          #meilisearch             # Fast, typo-tolerant search engine (requires service)
          #typesense               # Open-source alternative to Algolia (requires service)
          #weaviate                # Vector search engine with ML models (requires service)

          # ML Ops & Experimentation
          #mlflow                  # ML lifecycle management (use service instead)
          dvc                     # Data version control for ML projects

          # Data Processing & ETL
          #apache-arrow            # Columnar data format (included in Python env)
          duckdb                  # Analytical database (SQL analytics on Parquet)

          # Code Quality for AI Projects
          #bandit                  # Security linter for Python (in Python env)
          #vulture                 # Find dead Python code (in Python env)
          #radon                   # Code complexity metrics (in Python env)

          # API Development & Testing
          httpie                  # Modern HTTP client (better than curl for APIs)
          grpcurl                 # Like curl for gRPC
          k6                      # Load testing tool

          # Documentation & Visualization
          mermaid-cli             # Generate diagrams from markdown
          graphviz                # Graph visualization
          plantuml                # UML diagrams

          # Database Tools
          sqlite-utils            # CLI tool for manipulating SQLite databases
          litecli                 # SQLite CLI with autocomplete
          pgcli                   # PostgreSQL CLI with autocomplete

          # Performance Profiling
          #py-spy                  # Sampling profiler for Python (in Python env)
          hyperfine               # Command-line benchmarking tool

          # Container Security
          trivy                   # Vulnerability scanner for containers
          (pkgs.cosign.overrideAttrs (old: { doCheck = false; }))  # Container signing and verification (tests disabled due to nil pointer issue in test suite)

          # Kubernetes (Optional - for model deployment)
          # Uncomment if deploying ML models to Kubernetes
          #kubectl                 # Kubernetes CLI
          #k9s                     # Kubernetes TUI
          #helm                    # Kubernetes package manager

          # Monitoring & Observability (Enhanced)
          #prometheus-node-exporter  # System metrics (use system service)
          #grafana-agent             # Metrics collector (use system service)

          # ========================================================================
          # Utilities
          # ========================================================================

          mcfly           # Command history search
          navi            # Interactive cheatsheet
          starship        # Shell prompt
          hexedit         # Hex editor
          qrencode        # QR code generator
          age             # Modern encryption tool (for secrets management)
          sops            # Secrets operations (encrypted config files)
        ])
        ++ networkGuiPackages
        ++ fallbackNvtopPackages
        ++ gpuMonitoringPackages;
      aiderPackage =
        if pkgs ? aider-chat then
          [ pkgs.aider-chat ]
        else if pkgs ? aider then
          [ pkgs.aider ]
        else
          [ ];
      giteaDevAiPackages =
        [
          pkgs.gitea               # Native Gitea server and CLI for local development
          pkgs.tea                 # Official Gitea CLI for automation and AI workflows
          # The OpenAI Python SDK is bundled via pythonAiEnv to avoid duplicate store paths.
        ]
        ++ aiderPackage;
      engineeringToolsPackages = with pkgs; [
        # ========================================================================
        # PCB & Electronics Design
        # ========================================================================
        # kicad - removed, using Flatpak version (org.kicad.KiCad)
        ngspice                 # SPICE simulation for circuit analysis
        # kicad-nightly          # Bleeding edge KiCad (uncomment if needed)

        # ========================================================================
        # Mechanical CAD / 3D Modeling
        # ========================================================================
        # freecad - removed, using Flatpak version (org.freecad.FreeCAD)
        # openscad - removed, using Flatpak version (org.openscad.OpenSCAD)
        blender                 # 3D creation suite (modeling, animation, rendering)
        # solvespace            # Parametric 2D/3D CAD (lightweight, uncomment if available)

        # ========================================================================
        # 3D Printing / Slicing (CLI tools - GUI via Flatpak)
        # ========================================================================
        # prusa-slicer - removed, using Flatpak version (com.prusa3d.PrusaSlicer)
        # Note: openscad available as Flatpak for generating STLs from code

        # ========================================================================
        # CNC Machining & CAM
        # ========================================================================
        # Note: FreeCAD Path workbench provides CAM functionality
        # Additional G-code tools:
        # linuxcnc              # Full CNC control system (system-level, see docs)

        # ========================================================================
        # Digital IC / FPGA Design and Simulation
        # ========================================================================
        yosys                   # Open-source synthesis suite
        nextpnr                 # Place and route for FPGAs
        iverilog                # Icarus Verilog simulator
        gtkwave                 # Waveform viewer for simulation results

        # ========================================================================
        # Stock Trading / Financial Analysis (CLI tools)
        # ========================================================================
        # Note: TradingView available via Flatpak for GUI charting
        ledger                  # Double-entry accounting CLI
        hledger                 # Haskell variant of ledger
        # ta-lib                # Technical analysis library (Python bindings in env)

        # ========================================================================
        # AI/ML Monitoring & Dashboards
        # ========================================================================
        # Note: prometheus and grafana already in basePackages
        # Additional monitoring tools for engineering:
        prometheus-node-exporter # System metrics exporter
        grafana-loki            # Log aggregation (includes promtail)
        # netdata               # Real-time system monitoring (system service)
      ];
    in
    basePackages ++ giteaDevAiPackages ++ aiCommandLinePackages ++ ENGINEERING_TOOLS_PLACEHOLDER;

  # ========================================================================
  # ZSH Configuration
  # ========================================================================

  programs.zsh = {
    enable = true;
    enableCompletion = true;
    syntaxHighlighting.enable = true;
    #autosuggestions.enable = false;

    history = {
      size = 100000;
      path = "${config.xdg.dataHome}/zsh/history";
    };

    shellAliases = {
      # Basic modern replacements
      ll = "eza -l --icons";
      la = "eza -la --icons";
      lt = "eza --tree --icons";
      cat = "bat";
      du = "dust";
      df = "duf";

      # NixOS specific
      nrs = "sudo nixos-rebuild switch";
      nrt = "sudo nixos-rebuild test";
      nrb = "sudo nixos-rebuild boot";
      hms = "home-manager switch";
      nfu = "nix flake update";
      nfc = "nix flake check";
      nfb = "nix build";
      nfd = "nix develop";

      # Nix development
      nix-dev = "nix develop -c $SHELL";
      nix-search = "nix search nixpkgs";
      nix-shell-pure = "nix-shell --pure";

      # Prefer uv over pip for Python package management
      pip = "uv pip";
      pip3 = "uv pip";

      # Git shortcuts
      gs = "git status";
      ga = "git add";
      gc = "git commit";
      gp = "git push";
      gl = "git pull";
      gd = "git diff";
      gco = "git checkout";
      gb = "git branch";

      # Lazy tools
      lg = "lazygit";
      hf-sync = "hf-model-sync";
      # AI services now managed via ai-optimizer Podman setup
      # Use: cd ~/.config/ai-optimizer && docker-compose up/down
      ai-stack = "podman-ai-stack";
      gpt = "gpt-cli";
      cursor = "code-cursor";
      obsidian-ai = "obsidian-ai-bootstrap";

      # Find shortcuts
      ff = "fd";
      rg = "rg --smart-case";
    };

    # NixOS 25.11+: Use 'initContent' instead of 'initExtra'
    initContent = ''
      # Powerlevel10k First-Run Setup Wizard
      P10K_MARKER="$HOME/.config/p10k/.configured"
      P10K_WIZARD="$HOME/.local/bin/p10k-setup-wizard.sh"

      # Run setup wizard on first shell launch
      if [[ ! -f "$P10K_MARKER" && -f "$P10K_WIZARD" ]]; then
        echo ""
        echo "╔══════════════════════════════════════════════════════╗"
        echo "║  Welcome to your new ZSH setup!                     ║"
        echo "║  Let's configure Powerlevel10k...                   ║"
        echo "╚══════════════════════════════════════════════════════╝"
        echo ""
        "$P10K_WIZARD"
        echo ""
        echo "Please restart your shell to see the changes: exec zsh"
        return
      fi

      # Powerlevel10k instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Load Powerlevel10k theme
      source ${pkgs.zsh-powerlevel10k}/share/zsh-powerlevel10k/powerlevel10k.zsh-theme

      # P10k configuration (dynamic - adapts to user preferences)
      [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh

      # Enhanced command history with mcfly
      if command -v mcfly &> /dev/null; then
        eval "$(mcfly init zsh)"
      fi

      # FZF configuration
      export FZF_DEFAULT_COMMAND='fd --type f --hidden --follow --exclude .git'
      export FZF_CTRL_T_COMMAND="$FZF_DEFAULT_COMMAND"
      export FZF_ALT_C_COMMAND='fd --type d --hidden --follow --exclude .git'

      # Nix-specific environment
      export NIX_PATH=$HOME/.nix-defexpr/channels''${NIX_PATH:+:}$NIX_PATH

      # Better error messages
      export NIXPKGS_ALLOW_UNFREE=1
      '';
  };

  # ========================================================================
  # Cryptography & Secret Management
  # ========================================================================

  programs.gpg = {
    enable = true;
  };

  services.gpg-agent = {
    enable = true;
    # COSMIC relies on GCR SSH agent for SSH duties so we keep gpg-agent scoped to GPG only.
    enableSshSupport = false;
    enableExtraSocket = true;
    defaultCacheTtl = 3600;
    defaultCacheTtlSsh = 3600;
    pinentry.package = pkgs.pinentry-gnome3;
  };

  programs.password-store = {
    enable = true;
    package = pkgs.pass;
  };

  services.gnome-keyring = {
    enable = true;
    # Secrets + PKCS#11 back up COSMIC's keyring UI; SSH agent is handled by GCR.
    components = [
      "secrets"
      "pkcs11"
    ];
  };

  # ========================================================================
  # Rootless Podman Storage Configuration
  # ========================================================================
  # Configure overlay storage driver for rootless podman (user-level only).
  # System-level podman stays on VFS to prevent boot issues from systemd mounts.
  # Overlay with fuse-overlayfs provides efficient layer storage without VFS bloat.
  #
  # Benefits:
  # - Prevents VFS bloat (424GB+ from duplicate layers)
  # - Copy-on-write efficiency for container layers
  # - No systemd overlay mounts during boot (no boot failures)
  # - User-level storage in ~/.local/share (safe, isolated)
  #
  # Requirements:
  # - fuse-overlayfs package (added to system packages)
  # - kernel.unprivileged_userns_clone = 1 (already configured)
  # - subuid/subgid ranges (handled by autoSubUidGidRange = true)

  xdg.configFile."containers/storage.conf".text = ''
    [storage]
    driver = "overlay"
    graphroot = "${config.home.homeDirectory}/.local/share/containers/storage"
    rootless_storage_path = "${config.home.homeDirectory}/.local/share/containers/storage"
    runroot = "/run/user/''${UID}/containers"

    [storage.options]
    # Use fuse-overlayfs for rootless overlay (safer than kernel overlay)
    mount_program = "${pkgs.fuse-overlayfs}/bin/fuse-overlayfs"
  '';

  # ========================================================================
  # Git Configuration
  # ========================================================================
  # Using GitHub no-reply email (username@users.noreply.github.com) to:
  # - Protect your privacy (email not exposed in commits)
  # - Comply with GitHub email privacy settings
  # - Prevent push rejections due to GH007 errors

  programs.git = {
    enable = true;
    package = pkgs.git;

    settings =
      {
        init.defaultBranch = "main";
        pull.rebase = false;
        core.editor = "DEFAULTEDITOR";

        alias = {
          st = "status";
          co = "checkout";
          br = "branch";
          ci = "commit";
          unstage = "reset HEAD --";
          last = "log -1 HEAD";
          visual = "log --oneline --graph --decorate --all";
        };
      }
      // GIT_USER_SETTINGS_PLACEHOLDER;
  };

  # ========================================================================
  # Direnv - Automatic Development Environment Loading
  # ========================================================================
  # direnv automatically loads and unloads environment variables when entering
  # and leaving project directories. Combined with nix-direnv, it provides:
  # - Automatic activation of nix shells when cd'ing into projects
  # - Persistent dev shells (prevents garbage collection)
  # - Integration with VSCode and other editors
  # - No need to manually run 'nix develop' every time
  #
  # Usage: Add .envrc to your project with:
  #   use flake
  # Then run: direnv allow

  programs.direnv = {
    enable = true;
    nix-direnv.enable = true;

    # Silent mode - reduce terminal output noise
    enableBashIntegration = true;
    enableZshIntegration = true;

    # Configuration
    config = {
      global = {
        # Warn if direnv takes longer than 5 seconds to load
        warn_timeout = "5s";
      };
    };
  };

  # ========================================================================
  # Zellij - Modern Terminal Workspace
  # ========================================================================
  # Zellij is a modern terminal multiplexer (alternative to tmux) with:
  # - Floating panes and intuitive UI
  # - Client-server architecture (reconnect to sessions)
  # - Visual hints and discoverable keybindings
  # - Written in Rust for performance
  #
  # Usage:
  #   zellij           # Start new session
  #   zellij attach    # Reconnect to last session
  #   zellij ls        # List sessions
  #
  # Default keybindings (after Ctrl+g):
  #   Ctrl+g → p   # Panes mode (split, move, etc.)
  #   Ctrl+g → t   # Tabs mode
  #   Ctrl+g → s   # Scroll mode
  #   Ctrl+g → q   # Quit

  programs.zellij = {
    enable = true;

    # Configuration
    settings = {
      # Theme
      theme = "default";

      # Simplified mode (fewer modes for easier learning)
      simplified_ui = false;

      # Pane frames (borders around panes)
      pane_frames = true;

      # Default shell
      default_shell = "zsh";

      # Mouse support
      mouse_mode = true;

      # Copy on select
      copy_on_select = true;

      # Session serialization (save session layout)
      session_serialization = true;

      # Scroll buffer size (lines)
      scroll_buffer_size = 10000;
    };
  };

  # ========================================================================
  # Vim Configuration (minimal)
  # ========================================================================

  programs.vim = {
    enable = true;
    defaultEditor = false;  # Use DEFAULTEDITOR instead

    settings = {
      number = true;
      relativenumber = true;
      expandtab = true;
      tabstop = 2;
      shiftwidth = 2;
    };
  };

  # ========================================================================
  # VSCodium (Insiders) Configuration (Declarative)
  # ========================================================================

  programs.vscode = {
    enable = true;
    package = pkgs.vscodium;

    # Extensions installed declaratively
    # Note: NixOS 25.11+ requires extensions and userSettings under profiles.default
    profiles.default = {
      extensions =
      let
        fetchExtension = name:
          let
            path = lib.splitString "." name;
          in
            if lib.hasAttrByPath path pkgs.vscode-extensions then
              lib.getAttrFromPath path pkgs.vscode-extensions
            else
              null;
        extensionNames = [
          "jnoortheen.nix-ide"
          "arrterian.nix-env-selector"
          "eamodio.gitlens"
          "editorconfig.editorconfig"
          "esbenp.prettier-vscode"
          "ms-python.python"
          "ms-python.black-formatter"
          "ms-python.vscode-pylance"
          "ms-toolsai.jupyter"
          "ms-toolsai.jupyter-keymap"
          "ms-toolsai.jupyter-renderers"
          # AI coding assistants (locally hosted capable)
          "continue.continue"
          "codeium.codeium"
        ];
        curated = lib.filter (pkg: pkg != null) (map fetchExtension extensionNames);
        marketplaceExtensionNames = [
          # Keep Claude Code available; remove deprecated Codex/ChatGPT entries
          "Anthropic.claude-code"
          "Google.gemini-code-assist"
          "Kombai.kombai"  # Design-to-code AI tool (local-compatible)
        ];
        fetchMarketplaceExtension = name:
          let
            path = lib.splitString "." name;
          in
            if pkgs ? vscode-marketplace && lib.hasAttrByPath path pkgs.vscode-marketplace then
              lib.getAttrFromPath path pkgs.vscode-marketplace
            else
              null;
        marketplaceExtensions = lib.filter (pkg: pkg != null) (map fetchMarketplaceExtension marketplaceExtensionNames);
      in
        curated ++ marketplaceExtensions;

      # VSCodium settings (declarative)
      # Note: Claude Code paths will be added by bash script (dynamic)
      userSettings = {
      # Editor Configuration
      "editor.fontSize" = 14;
      "editor.fontFamily" = "'Fira Code', 'Droid Sans Mono', 'monospace'";
      "editor.fontLigatures" = true;
      "editor.formatOnSave" = true;
      "editor.formatOnPaste" = true;
      "editor.tabSize" = 2;
      "editor.insertSpaces" = true;
      "editor.detectIndentation" = true;
      "editor.minimap.enabled" = true;
      "editor.bracketPairColorization.enabled" = true;
      "editor.guides.bracketPairs" = true;

      # Nix-specific settings
      "nix.enableLanguageServer" = true;
      "nix.serverPath" = "nil";
      "nix.formatterPath" = "nixpkgs-fmt";
      "[nix]" = {
        "editor.defaultFormatter" = "jnoortheen.nix-ide";
        "editor.tabSize" = 2;
      };

      # Python & Jupyter integration
      "python.defaultInterpreterPath" = pythonAiInterpreterPath;
      "python.terminal.activateEnvironment" = true;
      "python.languageServer" = "Pylance";
      "python.analysis.typeCheckingMode" = "basic";
      "python.analysis.autoImportCompletions" = true;
      "python.formatting.provider" = "black";
      "python.testing.pytestEnabled" = true;
      "python.testing.unittestEnabled" = false;
      "python.dataScience.jupyterServerURI" = "local";
      "jupyter.askForKernelRestart" = false;
      "jupyter.jupyterServerType" = "local";
      "jupyter.notebookFileRoot" = "${config.home.homeDirectory}";
      "[python]" = {
        "editor.defaultFormatter" = "ms-python.black-formatter";
        "editor.formatOnSave" = true;
      };
      "[jupyter]" = {
        "editor.defaultFormatter" = "ms-toolsai.jupyter";
      };

      # Local AI endpoints
      "huggingface.endpoint" = "${huggingfaceTgiEndpoint}";
      "huggingface.defaultModel" = "${huggingfaceModelId}";
      "huggingface.telemetry.enableTelemetry" = false;
      "continue.defaultModel" = "Llama 4 Scout (TGI-8085)";
      "continue.enableTelemetry" = false;
      "continue.telemetryEnabled" = false;
      "continue.serverUrl" = "${openWebUiUrl}";
      "continue.models" = [
        {
          title = "Llama 3.2 Instruct (llama.cpp)";
          provider = "openai";
          model = "llama3.2";
          baseUrl = "${llamaCppHost}/v1";
        }
        {
          title = "DeepSeek R1 Distill 7B (coding)";
          provider = "openai";
          model = huggingfaceModelId;
          baseUrl = "${huggingfaceTgiEndpoint}/v1";
        }
        {
          title = "Llama 4 Scout 17B";
          provider = "openai";
          model = huggingfaceScoutModelId;
          baseUrl = "${huggingfaceScoutTgiEndpoint}/v1";
        }
        {
          title = "Phi-4 (llama.cpp)";
          provider = "openai";
          model = "phi4";
          baseUrl = "${llamaCppHost}/v1";
        }
      ];
      "codeium.enableTelemetry" = false;
      "chatgpt.gpt3.apiBaseUrl" = "${huggingfaceTgiEndpoint}/v1";
      "chatgpt.gpt3.model" = "${huggingfaceModelId}";
      "chatgpt.response.showNotification" = false;

      # Git configuration
      "git.path" = gitExecutablePath;
      "git.enableSmartCommit" = true;
      "git.autofetch" = true;
      "gitlens.codeLens.enabled" = true;

      # Terminal
      "terminal.integrated.defaultProfile.linux" = "zsh";
      "terminal.integrated.fontSize" = 13;
      "terminal.integrated.env.linux" = {
        "OPENAI_API_BASE" = "${huggingfaceTgiEndpoint}/v1";
        "LLAMA_CPP_BASE_URL" = "${llamaCppHost}/v1";
        "GPT_CLI_BASE_URL" = "${huggingfaceTgiEndpoint}/v1";
        "ANTHROPIC_BASE_URL" = "http://localhost:8094";
        "HYBRID_COORDINATOR_URL" = "http://localhost:8092";
        "AIDB_MCP_URL" = "http://localhost:8091";
      };

      # Claude Code integration (managed declaratively so the wrapper path is always correct)
      "claudeCode.executablePath" = claudeWrapperPath;
      "claudeCode.claudeProcessWrapper" = claudeWrapperPath;
      "claudeCode.environmentVariables" = [
        {
          name = "PATH";
          value = claudePathValue;
        }
        {
          name = "NODE_PATH";
          value = claudeNodeModulesPath;
        }
        {
          name = "ANTHROPIC_BASE_URL";
          value = "http://localhost:8094";
        }
        {
          name = "HYBRID_COORDINATOR_URL";
          value = "http://localhost:8092";
        }
        {
          name = "AIDB_MCP_URL";
          value = "http://localhost:8091";
        }
      ];
      "claudeCode.autoStart" = true;
      "claudeCode.enableContextSharing" = false;
      "claudeCode.preferLocalInference" = true;

      # Additional AI CLI wrappers (single config per tool, no duplicates)
      "codex.executablePath" = codexWrapperPath;
      "codex.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
        {
          name = "HYBRID_COORDINATOR_URL";
          value = "http://localhost:8092";
        }
        {
          name = "AIDB_MCP_URL";
          value = "http://localhost:8091";
        }
      ];
      "codex.autoStart" = true;

      "openai.executablePath" = openaiWrapperPath;
      "openai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "openai.autoStart" = false;

      "gooseai.executablePath" = gooseAiWrapperPath;
      "gooseai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "gooseai.autoStart" = false;

      # Theme
      "workbench.colorTheme" = "Default Dark Modern";

      # File associations
      "files.associations" = {
        "*.nix" = "nix";
        "flake.lock" = "json";
      };

      # Miscellaneous
      "files.autoSave" = "afterDelay";
      "files.autoSaveDelay" = 1000;
      "explorer.confirmDelete" = false;
      "explorer.confirmDragAndDrop" = false;
      };
    };
  };

  home.activation.vscodiumPersistSettings =
    lib.hm.dag.entryBefore [ "linkGeneration" ] ''
      set -eu

      settings="$HOME/.config/VSCodium/User/settings.json"
      rm -f "$settings.hm-bak" 2>/dev/null || true
      backup_dir="$HOME/.local/share/nixos-quick-deploy/state/vscodium"
      backup="$backup_dir/settings.json"

      if [ -f "$settings" ] && [ ! -L "$settings" ]; then
        mkdir -p "$backup_dir"
        cp "$settings" "$backup" 2>/dev/null || true
      fi
    '';

  home.activation.vscodiumMakeSettingsMutable =
    lib.hm.dag.entryAfter [ "reloadSystemd" ] ''
      set -eu

      settings="$HOME/.config/VSCodium/User/settings.json"
      settings_dir="$(dirname "$settings")"
      backup_dir="$HOME/.local/share/nixos-quick-deploy/state/vscodium"
      backup="$backup_dir/settings.json"
      mkdir -p "$settings_dir"

      restore_from_backup() {
        if [ -f "$backup" ]; then
          cp "$backup" "$settings" 2>/dev/null
          return 0
        fi
        return 1
      }

      if [ -L "$settings" ]; then
        target="$(readlink -f "$settings" 2>/dev/null || true)"
        rm -f "$settings"
        if ! restore_from_backup; then
          case "$target" in
            /nix/store/*)
              if [ -n "$target" ] && [ -f "$target" ]; then
                cp "$target" "$settings" 2>/dev/null || printf '{}' >"$settings"
              else
                printf '{}' >"$settings"
              fi
              ;;
            *)
              printf '{}' >"$settings"
              ;;
          esac
        fi
      elif [ ! -e "$settings" ]; then
        restore_from_backup || printf '{}' >"$settings"
      fi

      if [ -f "$settings" ]; then
        chmod u+rw "$settings" 2>/dev/null || true
        mkdir -p "$backup_dir"
        cp "$settings" "$backup" 2>/dev/null || true
      fi
    '';

  # Clear transient failed units (e.g. podman healthcheck runs, dashboard collector)
  home.activation.resetFailedUserUnits =
    lib.hm.dag.entryAfter [ "reloadSystemd" ] ''
      set -eu
      if command -v systemctl >/dev/null 2>&1; then
        systemctl --user reset-failed >/dev/null 2>&1 || true
      fi
    '';

  # GPT4All: Make settings and model storage mutable
  home.activation.gpt4allMakeSettingsMutable =
    lib.hm.dag.entryAfter [ "reloadSystemd" ] ''
      set -eu

      # GPT4All stores configuration in .ini file
      config_dir="$HOME/.local/share/nomic.ai/GPT4All"
      config_file="$config_dir/GPT4All.ini"
      backup_dir="$HOME/.local/share/nixos-quick-deploy/state/gpt4all"
      backup="$backup_dir/GPT4All.ini"

      # Create directories for models and config
      mkdir -p "$config_dir"
      mkdir -p "$backup_dir"

      restore_from_backup() {
        if [ -f "$backup" ]; then
          cp "$backup" "$config_file" 2>/dev/null
          return 0
        fi
        return 1
      }

      # Handle symlinked config files from Nix store
      if [ -L "$config_file" ]; then
        target="$(readlink -f "$config_file" 2>/dev/null || true)"
        rm -f "$config_file"
        if ! restore_from_backup; then
          case "$target" in
            /nix/store/*)
              if [ -n "$target" ] && [ -f "$target" ]; then
                cp "$target" "$config_file" 2>/dev/null || cat >"$config_file" <<'EOF'
[General]
modelPath=$HOME/.local/share/nomic.ai/GPT4All
EOF
              else
                cat >"$config_file" <<'EOF'
[General]
modelPath=$HOME/.local/share/nomic.ai/GPT4All
EOF
              fi
              ;;
            *)
              cat >"$config_file" <<'EOF'
[General]
modelPath=$HOME/.local/share/nomic.ai/GPT4All
EOF
              ;;
          esac
        fi
      elif [ ! -e "$config_file" ]; then
        restore_from_backup || cat >"$config_file" <<'EOF'
[General]
modelPath=$HOME/.local/share/nomic.ai/GPT4All
EOF
      fi

      # Ensure config file is writable and backed up
      if [ -f "$config_file" ]; then
        chmod u+rw "$config_file" 2>/dev/null || true
        cp "$config_file" "$backup" 2>/dev/null || true
      fi
    '';

  # Remove legacy flatpak-managed-install artifacts so systemd no longer reports
  # a degraded user session after the service was retired.
  home.activation.cleanupFlatpakManagedArtifacts =
    lib.hm.dag.entryBefore [ "reloadSystemd" ] ''
      set -eu

      flag_file="$${XDG_RUNTIME_DIR:-/run/user/$$(id -u)}/allow-flatpak-managed-install"
      service_dir="$HOME/.config/systemd/user"
      unit_path="$service_dir/flatpak-managed-install.service"

      remove_path() {
        local target="$1"
        if [ -z "$target" ]; then
          return 0
        fi
        if [ -L "$target" ] || [ -e "$target" ]; then
          rm -f "$target" 2>/dev/null || true
        fi
      }

      remove_path "$flag_file"
      remove_path "$unit_path"

      for wants in \
        "$service_dir/default.target.wants/flatpak-managed-install.service" \
        "$service_dir/graphical-session.target.wants/flatpak-managed-install.service" \
        "$service_dir/multi-user.target.wants/flatpak-managed-install.service"
      do
        remove_path "$wants"
      done

      if command -v systemctl >/dev/null 2>&1; then
        systemctl --user reset-failed flatpak-managed-install.service >/dev/null 2>&1 || true
      fi
    '';

  # Ensure Podman Desktop (Flatpak) can see the rootless Podman socket.
  home.activation.configurePodmanDesktopFlatpak =
    lib.hm.dag.entryBefore [ "reloadSystemd" ] ''
      set -eu

      app_id="io.podman_desktop.PodmanDesktop"

      if command -v flatpak >/dev/null 2>&1; then
        if flatpak info --user "$app_id" >/dev/null 2>&1 || flatpak info --system "$app_id" >/dev/null 2>&1; then
          flatpak override --user --filesystem=xdg-run/podman "$app_id" >/dev/null 2>&1 || true
        fi
      fi

      if command -v podman >/dev/null 2>&1; then
        if command -v systemctl >/dev/null 2>&1; then
          systemctl --user enable --now podman.socket >/dev/null 2>&1 || true
        fi

        socket_path="$${XDG_RUNTIME_DIR:-/run/user/$$(id -u)}/podman/podman.sock"
        if [ -S "$socket_path" ]; then
          if ! podman system connection list --format "{{.Name}}" 2>/dev/null | grep -q .; then
            podman system connection add local "unix://$socket_path" --default >/dev/null 2>&1 || true
          fi
        fi
      fi
    '';
  home.activation.ensurePodmanAiStackDirs =
    lib.hm.dag.entryBefore [ "writeBoundary" ] ''
      set -eu
      data_root="$HOME/${podmanAiStackDataDir}"
      required_paths="
        $data_root
        $data_root/llama-cpp-models
        $data_root/open-webui
        $data_root/qdrant
        $data_root/mindsdb
        $data_root/aidb
        $data_root/aidb-cache
        $data_root/telemetry
      "

      for path in $required_paths; do
        if [ -L "$path" ] || { [ -e "$path" ] && [ ! -d "$path" ]; }; then
          rm -f "$path" 2>/dev/null || true
        fi
        mkdir -p "$path"
      done
    '';

  # Auto-start Podman AI stack on first deployment (if enabled)
  # This runs after all files are linked, so podman-ai-stack helper should be available
  home.activation.startPodmanAiStack =
    lib.mkIf LOCAL_AI_STACK_ENABLED_PLACEHOLDER (
      lib.hm.dag.entryAfter [ "linkGeneration" ] ''
        set -eu
        
        # Auto-start is optional - AI stack can be started manually
        # This activation hook only runs if podman-ai-stack is in PATH
        if [ -x "$HOME/.local/bin/podman-ai-stack" ]; then
          # Check if this is the first time (no containers exist yet)
          if ! ${pkgs.podman}/bin/podman ps -a --filter "label=${podmanAiStackLabelKey}=${podmanAiStackLabelValue}" --format "{{.Names}}" 2>/dev/null | grep -q .; then
            echo "Starting Podman AI stack for the first time..."
            echo "This will pull container images, which may take several minutes."
            echo "You can monitor progress with: podman-ai-stack logs"

            # Start in background to avoid blocking home-manager switch
            (
              sleep 2  # Give systemd a moment to settle
              "$HOME/.local/bin/podman-ai-stack" up || {
                echo "Info: Failed to start Podman AI stack automatically." >&2
                echo "You can start it manually later with: podman-ai-stack up" >&2
                exit 0  # Don't fail the activation
              }
            ) &
          else
            echo "Podman AI stack containers already exist. Skipping auto-start."
            echo "Use 'podman-ai-stack up' to start them manually."
          fi
        else
          # Not a warning - auto-start is optional
          echo "Info: AI stack auto-start not configured (podman-ai-stack not in PATH)"
          echo "To start manually, run one of:"
          echo "  - ./scripts/podman-ai-stack.sh up"
          echo "  - ./scripts/hybrid-ai-stack.sh up"
          echo "  - cd ai-stack/compose && podman-compose up -d"
        fi
      ''
    );

  # ========================================================================
  # Alacritty Terminal Configuration
  # ========================================================================

  programs.alacritty = {
    enable = true;
    settings = {
      window = {
        opacity = 0.95;
        padding = {
          x = 10;
          y = 10;
        };
      };
      font = {
        size = 11.0;
        normal = {
          family = "MesloLGS NF";
        };
      };
      colors = {
        primary = {
          background = "0x1e1e1e";
          foreground = "0xd4d4d4";
        };
      };
    };
  };

  # ========================================================================
  # Session Variables
  # ========================================================================

  home.sessionVariables =
    {
      EDITOR = "DEFAULTEDITOR";
      VISUAL = "DEFAULTEDITOR";
      NIXPKGS_ALLOW_UNFREE = "1";
      MANGOHUD = if glfMangoHudInjectsIntoApps then "1" else "0";
      MANGOHUD_CONFIGFILE = "${config.home.homeDirectory}/.config/MangoHud/MangoHud.conf";
      MANGOHUD_DESKTOP_MODE = if glfMangoHudDesktopMode then "1" else "0";
      # NPM Configuration
      NPM_CONFIG_PREFIX = "$HOME/.npm-global";
      # AI Development Tools
      AIDER_DEFAULT_MODEL = "gpt-4o-mini";
      AIDER_LOG_DIR = "$HOME/.local/share/aider/logs";
      TEA_AI_MODEL = "gpt-4o-mini";
      # Hugging Face Configuration
      HF_HOME = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_HUB_CACHE = "$HOME/${huggingfaceCacheDir}";
      TRANSFORMERS_CACHE = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_TGI_ENDPOINT = "${huggingfaceTgiEndpoint}";
      HUGGINGFACE_SCOUT_TGI_ENDPOINT = "${huggingfaceScoutTgiEndpoint}";
      HUGGINGFACE_MODEL_ID = "${huggingfaceModelId}";
      HUGGINGFACE_SCOUT_MODEL_ID = "${huggingfaceScoutModelId}";
      HUGGINGFACE_TOKEN_PATH = "$HOME/.config/huggingface/token";
      HF_HUB_ENABLE_HF_TRANSFER = "1";
      # LLM Service Endpoints
      LLAMA_CPP_BASE_URL = "${llamaCppHost}/v1";
      OPEN_WEBUI_URL = "${openWebUiUrl}";
      GPT_CLI_DEFAULT_MODEL = "${huggingfaceModelId}";
      GPT_CLI_DEFAULT_PROVIDER = "openai";
      GPT_CLI_BASE_URL = "${huggingfaceTgiEndpoint}/v1";
      NIXOS_QUICK_DEPLOY_ROOT = "NIXOS_QUICK_DEPLOY_ROOT_PLACEHOLDER";
      # Podman AI Stack
      PODMAN_AI_STACK_NETWORK = "local-ai";
      PODMAN_AI_STACK_DATA_ROOT = "$HOME/${podmanAiStackDataDir}";
      AI_STACK_ENV_FILE = "$HOME/.config/nixos-ai-stack/.env";
      AI_STACK_DATA = "$HOME/.local/share/nixos-ai-stack";
      # Security & Credentials
      GNUPGHOME = "${config.home.homeDirectory}/.gnupg";
      PASSWORD_STORE_DIR = "${config.home.homeDirectory}/.local/share/password-store";
      # Ensure COSMIC sessions find the GNOME Keyring sockets started via systemd --user.
      GNOME_KEYRING_CONTROL = "$XDG_RUNTIME_DIR/keyring";
      SSH_AUTH_SOCK = "$XDG_RUNTIME_DIR/keyring/ssh";
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      GITEA_WORK_DIR = "$HOME/${giteaFlatpakDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaFlatpakConfigDir}";
    }
    // lib.optionalAttrs (!config.services.flatpak.enable) {
      GITEA_WORK_DIR = "$HOME/${giteaNativeDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaNativeConfigDir}";
    };

  # Note: Podman rootless storage configuration is handled within the
  # services.podman block below (line ~3312) to avoid duplicate attribute errors.
  # Previous placeholder-based injection was removed to prevent conflicts.

  # ========================================================================
  # Session Path
  # ========================================================================
  # Ensure critical directories are in PATH for all shells and desktop sessions
  # This fixes issues where home-manager, claude-wrapper, and custom scripts
  # are not accessible after login or in new terminal sessions

  home.sessionPath = [
    "$HOME/.local/bin"           # Custom user scripts and wrappers
    "$HOME/.npm-global/bin"      # NPM global packages (claude-wrapper, etc.)
  ];

  # ========================================================================
  # Home Files
  # ========================================================================

  home.file =
    {
    # Remove legacy flatpak-managed-install units and symlinks managed by older
    # releases so systemd stops referencing the retired service.
    ".config/systemd/user/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/default.target.wants/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/graphical-session.target.wants/flatpak-managed-install.service".enable = false;
    ".config/systemd/user/multi-user.target.wants/flatpak-managed-install.service".enable = false;

    # Create local bin directory
    ".local/bin/.keep".text = "";

    # Create Jupyter notebooks directory
    "notebooks/.keep".text = "# Jupyter notebooks directory\n";

    # Create Jupyter data directories
    ".local/share/jupyter/.keep".text = "";
    ".config/jupyter/.keep".text = "";

    # Declarative VSCodium wrapper so the Claude CLI stays on PATH
    ".local/bin/codium-wrapped" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        export NPM_CONFIG_PREFIX="$HOME/.npm-global"
        export PATH="$HOME/.npm-global/bin:$HOME/.local/bin:$PATH"

        codium_bin="''${CODIUM_BIN:-${pkgs.vscodium-insiders}/bin/codium-insiders}"
        if [[ ! -x "''${codium_bin}" ]]; then
          if command -v codium-insiders >/dev/null 2>&1; then
            codium_bin="$(command -v codium-insiders)"
          else
            echo "codium-wrapped: unable to locate VSCodium Insiders binary" >&2
            exit 127
          fi
        fi

        exec "''${codium_bin}" "$@"
      '';
      executable = true;
    };

    ".local/bin/codium" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail
        exec "$HOME/.local/bin/codium-wrapped" "$@"
      '';
      executable = true;
    };

    # Launcher for the Gitea editor that prefers Flatpak but falls back to native binaries
    ".local/bin/gitea-editor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ${giteaFlatpakAppId} >/dev/null 2>&1; then
          exec flatpak run ${giteaFlatpakAppId} "$@"
        elif command -v gitea >/dev/null 2>&1; then
          exec gitea "$@"
        elif command -v tea >/dev/null 2>&1; then
          exec tea "$@"
        else
          echo "error: gitea editor is not installed. Install via Flatpak or enable the native package." >&2
          exit 127
        fi
      '';
      executable = true;
    };

    # Helper to bridge local repositories with aider for AI-driven workflows
    ".local/bin/gitea-ai-assistant" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        usage() {
          echo "Usage: gitea-ai-assistant <repository-path> [-- <aider-args>...]" >&2
          exit 1
        }

        if [[ $# -lt 1 ]]; then
          usage
        fi

        repo_path="$1"
        shift

        if [[ "$repo_path" == "--" ]]; then
          usage
        fi

        if [[ ! -d "$repo_path/.git" ]]; then
          echo "error: $repo_path is not a git repository" >&2
          exit 2
        fi

        repo_path="$(realpath "$repo_path")"

        if [[ $# -gt 0 && "$1" == "--" ]]; then
          shift
        fi

        log_dir="$AIDER_LOG_DIR"
        if [[ -z "$log_dir" ]]; then
          log_dir="$HOME/.local/share/aider/logs"
        fi
        mkdir -p "$log_dir"

        model="$AIDER_DEFAULT_MODEL"
        if [[ -z "$model" ]]; then
          model="gpt-4o-mini"
        fi

        exec aider --model "$model" --repo "$repo_path" "$@"
      '';
      executable = true;
    };

    ".config/openskills/install.sh" = {
      text = ''
        #!/usr/bin/env bash
        #
        # OpenSkills automation hook – append the commands that install your project-specific tools here.
        #
        set -euo pipefail

        echo "OpenSkills custom tooling hook – no actions defined."
      '';
      executable = true;
    };
    
    # AI Agent Setup Helper
    ".local/bin/ai-agent-setup" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail
        
        # AI Agent Stack Setup Script
        # Installs cutting-edge agent packages not in nixpkgs
        
        usage() {
          cat <<'USAGE'
        AI Agent Stack Setup
        
        Usage: ai-agent-setup <command>
        
        Commands:
          install     Install all agent packages from requirements.txt
          update      Update all agent packages to latest versions
          check       Check which packages are installed
          models      Pull recommended models for agents
          test        Run a quick agent test
          help        Show this message
        
        Examples:
          ai-agent-setup install     # Install agent packages
          ai-agent-setup models      # Pull Qwen models for agents
          ai-agent-setup test        # Test smolagents with local LLM
        USAGE
        }
        
        REQUIREMENTS_FILE="$HOME/.config/ai-agents/requirements.txt"
        
        cmd_install() {
          echo "Installing AI Agent packages..."
          
          if command -v uv >/dev/null 2>&1; then
            echo "Using uv for fast installation..."
            uv pip install -r "$REQUIREMENTS_FILE"
          else
            echo "Using pip..."
            pip install -r "$REQUIREMENTS_FILE"
          fi
          
          echo ""
          echo "✓ Agent packages installed!"
          echo ""
          echo "Quick start:"
          echo "  python -c 'from smolagents import CodeAgent; print(\"smolagents ready\")'"
          echo "  python -c 'from langgraph.graph import StateGraph; print(\"langgraph ready\")'"
          echo "  python -c 'from crewai import Agent; print(\"crewai ready\")'"
        }
        
        cmd_update() {
          echo "Updating AI Agent packages..."
          
          if command -v uv >/dev/null 2>&1; then
            uv pip install --upgrade -r "$REQUIREMENTS_FILE"
          else
            pip install --upgrade -r "$REQUIREMENTS_FILE"
          fi
          
          echo "✓ Agent packages updated!"
        }
        
        cmd_check() {
          echo "Checking installed agent packages..."
          echo ""
          
          local packages=(
            "smolagents"
            "langgraph"
            "crewai"
            "instructor"
            "llmlingua"
            "langfuse"
            "mcp"
          )
          
          for pkg in "''${packages[@]}"; do
            if python -c "import $pkg" 2>/dev/null; then
              version=$(python -c "import $pkg; print(getattr($pkg, '__version__', 'installed'))" 2>/dev/null || echo "installed")
              echo "✓ $pkg: $version"
            else
              echo "✗ $pkg: not installed"
            fi
          done
        }
        
        cmd_models() {
          echo "Preparing recommended models for AI agents..."
          
          if ! curl -s http://localhost:8080/health >/dev/null 2>&1; then
            echo "Error: llama.cpp server not available. Start the Podman AI stack first:"
            echo "  podman-ai-stack up"
            exit 1
          fi
          
          echo ""
          echo "llama.cpp uses GGUF models stored in:"
          echo "  ~/.local/share/podman-ai-stack/llama-cpp-models/"
          echo ""
          echo "Download recommended models (examples):"
          echo "  qwen2.5-coder-7b-instruct-q4_k_m.gguf"
          echo "  qwen3-8b-instruct-q4_k_m.gguf"
          echo "  nomic-embed-text-v1.5.q4_0.gguf"
          echo ""
          echo "Use huggingface-cli or wget to fetch GGUF files."
        }
        
        cmd_test() {
          echo "Testing AI Agent setup..."
          echo ""
          
          python <<'PYTEST'
        try:
            from smolagents import CodeAgent
            print("✓ smolagents imported successfully")
            
            # Check if local LLM is available
            import httpx
            try:
                response = httpx.get("http://localhost:8080/health", timeout=5)
                if response.status_code == 200:
                    print("✓ Local llama.cpp server is running")
                    models = httpx.get("http://localhost:8080/v1/models", timeout=5).json().get("data", [])
                    print(f"  Available models: {len(models)}")
                else:
                    print("⚠ llama.cpp server responded but with error")
            except:
                print("⚠ No local LLM server detected (start with: podman-ai-stack up)")
            
            print("")
            print("Agent stack is ready for use!")
            print("")
            print("Example usage:")
            print("  from smolagents import CodeAgent, HfApiModel")
            print("  model = HfApiModel(model_id='http://localhost:8080/v1')")
            print("  agent = CodeAgent(tools=[], model=model)")
            print("  result = agent.run('Write a hello world function')")
            
        except ImportError as e:
            print(f"✗ Import error: {e}")
            print("  Run: ai-agent-setup install")
        PYTEST
        }
        
        if [[ $# -eq 0 ]]; then
          usage
          exit 0
        fi
        
        case "$1" in
          install)
            cmd_install
            ;;
          update)
            cmd_update
            ;;
          check)
            cmd_check
            ;;
          models)
            cmd_models
            ;;
          test)
            cmd_test
            ;;
          help|--help|-h)
            usage
            ;;
          *)
            echo "Unknown command: $1" >&2
            usage >&2
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    # Security Manager - Firewall and monitoring dashboard helper
    ".local/bin/security-manager" = {
      text = ''
        #!/usr/bin/env bash
        # security-manager - Security & Firewall Management Helper
        set -euo pipefail
        
        SCRIPT_NAME="$(basename "$0")"
        CYAN=$'\033[0;36m'
        GREEN=$'\033[0;32m'
        YELLOW=$'\033[0;33m'
        RED=$'\033[0;31m'
        RESET=$'\033[0m'
        
        usage() {
          cat <<EOF
        ''${CYAN}Security & Firewall Manager for NixOS''${RESET}
        
        Usage: $SCRIPT_NAME <command>
        
        Commands:
          status          Show firewall and security service status
          rules           Display current iptables rules
          ports           Show open ports and listening services
          dashboards      List available monitoring dashboards
          enable-monitoring   Show how to enable Prometheus/Grafana
          flatseal        Launch Flatseal for Flatpak permissions
          netdata         Open Netdata dashboard
          help            Show this message
        EOF
        }
        
        print_section() {
          echo ""
          echo "''${CYAN}━━━ $1 ━━━''${RESET}"
        }
        
        check_service() {
          local service="$1"
          local name="''${2:-$service}"
          if systemctl is-active --quiet "$service" 2>/dev/null; then
            echo "  ''${GREEN}✓''${RESET} $name: RUNNING"
            return 0
          elif systemctl is-enabled --quiet "$service" 2>/dev/null; then
            echo "  ''${YELLOW}○''${RESET} $name: ENABLED (not running)"
            return 1
          else
            echo "  ''${RED}✗''${RESET} $name: DISABLED"
            return 2
          fi
        }
        
        subcmd_status() {
          print_section "Firewall Status"
          check_service "firewall" "NixOS Firewall" || true
          
          print_section "Security Services"
          check_service "fail2ban" "Fail2ban (SSH protection)" || true
          
          print_section "Monitoring Services"
          check_service "netdata" "Netdata (real-time monitoring)" || true
          check_service "prometheus" "Prometheus (metrics collection)" || true
          check_service "grafana" "Grafana (dashboards)" || true
          
          print_section "Network Status"
          echo "  Default route:"
          ip route | head -1 | sed 's/^/    /'
          echo "  DNS servers:"
          grep "nameserver" /etc/resolv.conf 2>/dev/null | sed 's/^/    /' || echo "    (none found)"
        }
        
        subcmd_rules() {
          print_section "Firewall Rules (requires sudo)"
          echo ""
          echo "INPUT chain (incoming connections):"
          sudo iptables -L INPUT -n -v --line-numbers 2>/dev/null || echo "  (need sudo or iptables not installed)"
          
          echo ""
          echo "FORWARD chain:"
          sudo iptables -L FORWARD -n -v --line-numbers 2>/dev/null | head -20
          
          echo ""
          echo "OUTPUT chain (outgoing connections):"
          sudo iptables -L OUTPUT -n -v --line-numbers 2>/dev/null | head -10
        }
        
        subcmd_ports() {
          print_section "Listening Ports & Services"
          echo ""
          echo "TCP Ports:"
          ss -tlnp 2>/dev/null | head -30 || netstat -tlnp 2>/dev/null | head -30
          
          echo ""
          echo "UDP Ports:"
          ss -ulnp 2>/dev/null | head -10 || netstat -ulnp 2>/dev/null | head -10
        }
        
        subcmd_dashboards() {
          print_section "Available Monitoring Dashboards"
          echo ""
          
          # Netdata
          if ${pkgs.curl}/bin/curl -s -o /dev/null --connect-timeout 1 http://localhost:19999 2>/dev/null; then
            echo "  ''${GREEN}✓''${RESET} Netdata: http://localhost:19999"
          else
            echo "  ''${RED}✗''${RESET} Netdata: Not accessible (service may not be running)"
          fi
          
          # Prometheus
          if ${pkgs.curl}/bin/curl -s -o /dev/null --connect-timeout 1 http://localhost:9090 2>/dev/null; then
            echo "  ''${GREEN}✓''${RESET} Prometheus: http://localhost:9090"
          else
            echo "  ''${YELLOW}○''${RESET} Prometheus: Not enabled (see 'enable-monitoring' command)"
          fi
          
          # Grafana
          if ${pkgs.curl}/bin/curl -s -o /dev/null --connect-timeout 1 http://localhost:3001 2>/dev/null; then
            echo "  ''${GREEN}✓''${RESET} Grafana: http://localhost:3001"
          else
            echo "  ''${YELLOW}○''${RESET} Grafana: Not enabled (see 'enable-monitoring' command)"
          fi
          
          # Gitea
          if ${pkgs.curl}/bin/curl -s -o /dev/null --connect-timeout 1 http://localhost:3000 2>/dev/null; then
            echo "  ''${GREEN}✓''${RESET} Gitea: http://localhost:3000"
          fi
          
          echo ""
          echo "To open dashboards in browser:"
          echo "  nix-shell -p firefox --run 'firefox http://localhost:19999'"
        }
        
        subcmd_enable_monitoring() {
          print_section "How to Enable Full Monitoring Stack"
          echo ""
          echo "Edit /etc/nixos/configuration.nix and change these settings:"
          echo ""
          cat <<'NIXCODE'
          # Enable Prometheus
          services.prometheus = {
            enable = true;
            exporters.node.enable = true;
          };
        
          # Enable Grafana
          services.grafana = {
            enable = true;
            settings.server.http_port = 3001;
            settings.security.admin_password = "changeme";  # CHANGE THIS!
          };
        
          # Enable Fail2ban
          services.fail2ban = {
            enable = true;
            maxretry = 3;
            bantime = "1h";
          };
        NIXCODE
          echo ""
          echo "Then rebuild NixOS:"
          echo "  sudo nixos-rebuild switch"
        }
        
        subcmd_flatseal() {
          print_section "Launching Flatseal"
          if flatpak list | grep -q "Flatseal"; then
            flatpak run com.github.tchx84.Flatseal &
            disown
            echo "Flatseal launched. Use it to manage Flatpak app permissions."
          else
            echo "''${RED}Flatseal not installed.''${RESET}"
            echo "Install with: flatpak install flathub com.github.tchx84.Flatseal"
          fi
        }
        
        subcmd_netdata() {
          print_section "Opening Netdata Dashboard"
          if ${pkgs.curl}/bin/curl -s -o /dev/null --connect-timeout 1 http://localhost:19999 2>/dev/null; then
            nix-shell -p firefox --run "firefox http://localhost:19999" &
            disown
            echo "Opening Netdata at http://localhost:19999"
          else
            echo "''${RED}Netdata not running.''${RESET}"
            echo "Start with: sudo systemctl start netdata"
          fi
        }
        
        # Main
        case "''${1:-help}" in
          status)
            subcmd_status
            ;;
          rules)
            subcmd_rules
            ;;
          ports)
            subcmd_ports
            ;;
          dashboards)
            subcmd_dashboards
            ;;
          enable-monitoring)
            subcmd_enable_monitoring
            ;;
          flatseal)
            subcmd_flatseal
            ;;
          netdata)
            subcmd_netdata
            ;;
          help|-h|--help)
            usage
            ;;
          *)
            echo "''${RED}Unknown command: $1''${RESET}" >&2
            usage >&2
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    # NPM Configuration
    ".npmrc".text = ''
      prefix=''${HOME}/.npm-global
    '';

    # Git configuration template
    # Note: Set your name and email with:
    #   git config --global user.name "Your Name"
    #   git config --global user.email "you@example.com"
    ".gitconfig".text = ''
      [user]
      	# TODO: Set your name and email then run this command in the terminal: home-manager switch -b backup --flake ~/.dotfiles/home-manager
      	# name = Your Name
      	# email = you@example.com

      [init]
      	defaultBranch = main

      [pull]
      	rebase = false

      [core]
      	editor = ${if (config.home.sessionVariables.EDITOR or "") != "" then config.home.sessionVariables.EDITOR else "vim"}

      [alias]
      	st = status
      	co = checkout
      	br = branch
      	ci = commit
      	unstage = reset HEAD --
      	last = log -1 HEAD
      	visual = log --oneline --graph --decorate --all
    '';

    # Hugging Face configuration and cache keepers
    ".config/MangoHud/.keep".text = "";
    ".config/MangoHud/MangoHud.conf".text =
      if glfMangoHudConfigFileContents != "" then
        glfMangoHudConfigFileContents
      else
        "";
    ".config/huggingface/.keep".text = "";
    ".config/huggingface/README".text = huggingfaceReadme;
    
    # AI Agent Stack Configuration (December 2025)
    ".config/ai-agents/.keep".text = "";
    ".config/ai-agents/requirements.txt".text = ''
      # ==========================================================================
      # AI Agent Stack - Pip Requirements
      # ==========================================================================
      # Install: pip install -r ~/.config/ai-agents/requirements.txt
      # Or use uv: uv pip install -r ~/.config/ai-agents/requirements.txt
      # ==========================================================================
      
      # Core Agent Frameworks
      smolagents>=1.0.0           # Hugging Face lightweight agents
      langgraph>=0.2.0            # Stateful agent workflows
      crewai>=0.60.0              # Multi-agent orchestration
      crewai-tools>=0.10.0        # CrewAI tool integrations
      
      # RAG Optimization
      semantic-text-splitter>=0.10.0  # Semantic chunking
      rank-bm25>=0.2.0            # BM25 for hybrid search
      flashrank>=0.3.0            # Fast reranking
      
      # Structured Outputs
      instructor>=1.4.0           # Structured LLM outputs
      outlines>=0.0.40            # Grammar-constrained generation
      
      # Context Compression
      llmlingua>=0.2.0            # Token compression
      
      # Memory & Observability
      mem0ai>=0.1.0               # Conversation memory
      langfuse>=2.30.0            # LLM tracing
      
      # MCP Integration
      mcp>=1.0.0                  # Model Context Protocol client
      
      # Code Execution
      e2b>=1.0.0                  # Code sandbox
      
      # Document Processing
      unstructured>=0.15.0        # Document parsing
      
      # LlamaIndex (if not in nixpkgs)
      llama-index>=0.11.0
      llama-index-core>=0.11.0
      llama-index-embeddings-huggingface>=0.3.0
      
      # ChromaDB (if not in nixpkgs)
      chromadb>=0.5.0
      
      # LiteLLM (unified API)
      litellm>=1.50.0
    '';
    
    ".config/ai-agents/README.md".text = ''
      # AI Agent Stack for Mobile Workstations
      
      ## Quick Start
      
      ```bash
      # Install agent packages
      pip install -r ~/.config/ai-agents/requirements.txt
      
      # Or with uv (faster)
      uv pip install -r ~/.config/ai-agents/requirements.txt
      ```
      
      ## Token Optimization Best Practices
      
      ### 1. Use smolagents for Simple Tasks
      smolagents uses code-based actions instead of verbose JSON,
      reducing token usage by 30-50%.
      
      ```python
      from smolagents import CodeAgent, HfApiModel
      
      # Connect to local Ollama
      model = HfApiModel(model_id="http://localhost:11434/v1")
      agent = CodeAgent(tools=[], model=model)
      result = agent.run("Create a fibonacci function")
      ```
      
      ### 2. Semantic Chunking for RAG
      ```python
      from semantic_text_splitter import TextSplitter
      
      splitter = TextSplitter(capacity=512)
      chunks = splitter.chunks(document)
      ```
      
      ### 3. Context Compression
      ```python
      from llmlingua import PromptCompressor
      
      compressor = PromptCompressor()
      compressed = compressor.compress_prompt(
          context=long_context,
          target_token=500
      )
      # Up to 20x compression!
      ```
      
      ### 4. Hybrid Search
      ```python
      from rank_bm25 import BM25Okapi
      
      # Combine keyword + semantic search
      bm25_scores = bm25.get_scores(query)
      vector_scores = model.similarity(query, docs)
      final_scores = reciprocal_rank_fusion([bm25_scores, vector_scores])
      ```
      
      ## Recommended Models for Mobile Workstation
      
      | Task | Model | VRAM | Notes |
      |------|-------|------|-------|
      | Code | Qwen2.5-Coder-1.5B | 2GB | Fast completions |
      | Code | Qwen2.5-Coder-7B | 6GB | Better quality |
      | General | Qwen3-8B | 6GB | Good reasoning |
      | Complex | Qwen3-14B | 10GB | Best quality |
      | Embeddings | nomic-embed-text | 1GB | Fast & accurate |
      
      ## MCP Servers
      
      Connect to MCP servers for enhanced tool capabilities:
      
      ```bash
      # Filesystem access
      mcp connect filesystem --root ~/projects
      
      # GitHub integration
      mcp connect github
      
      # PostgreSQL
      mcp connect postgres --uri postgresql://localhost/mydb
      ```
      
      ## Agentic Workflow Pattern
      
      ```
      User Query
          │
          ▼
      ┌─────────────┐
      │ Planner     │  (Small model - Qwen3-1.5B)
      │ Agent       │  - Decomposes task
      └─────────────┘  - Minimal tokens
          │
          ▼
      ┌─────────────┐
      │ Researcher  │  (Medium model - Qwen3-8B)
      │ Agent       │  - RAG retrieval
      └─────────────┘  - Context compression
          │
          ▼
      ┌─────────────┐
      │ Coder       │  (Code model - Qwen2.5-Coder-7B)
      │ Agent       │  - Code generation
      └─────────────┘  - Structured outputs
          │
          ▼
      ┌─────────────┐
      │ Reviewer    │  (Small model - Qwen3-1.5B)
      │ Agent       │  - Validation
      └─────────────┘  - Final check
          │
          ▼
      Final Output
      ```
      
      This multi-model approach optimizes token usage by using
      small models for simple tasks and reserving larger models
      for complex reasoning.
    '';
    "${huggingfaceCacheDir}/.keep".text = "";
    "${openWebUiDataDir}/.keep".text = "";
    "${openWebUiDataDir}/README".text = openWebUiReadme;
    "${podmanAiStackDataDir}/.keep".text = "";
    "${podmanAiStackDataDir}/README".text = podmanAiStackReadme;
    "${podmanAiStackDataDir}/llama-cpp-models/.keep".text = "";
    "${podmanAiStackDataDir}/open-webui/.keep".text = "";
    "${podmanAiStackDataDir}/qdrant/.keep".text = "";
    "${podmanAiStackDataDir}/mindsdb/.keep".text = "";
    ".config/systemd/user/podman-user-wait-network-online.service.d/60-nm-online.conf".text = ''
      [Service]
      ExecStart=
      ExecStart=${podmanWaitForNetworkScript}
    '';

  }
  // lib.optionalAttrs (builtins.pathExists ./p10k-setup-wizard.sh) {
    # P10k Setup Wizard
    ".local/bin/p10k-setup-wizard.sh" = {
      source = ./p10k-setup-wizard.sh;
      executable = true;
    };
  }
  // (lib.mkIf LOCAL_AI_STACK_ENABLED_PLACEHOLDER {
    ".config/systemd/user/podman-local-ai-network.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=120
      TimeoutStopSec=60
      RestartSec=5
    '';

    ".config/systemd/user/podman-local-ai-llama-cpp.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=600
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "ghcr.io/ggml-org/llama.cpp:server"}
    '';

    ".config/systemd/user/podman-local-ai-open-webui.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=1800
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "ghcr.io/open-webui/open-webui:main"}
    '';

    ".config/systemd/user/podman-local-ai-qdrant.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=600
      TimeoutStopSec=180
      RestartSec=10
      ExecStartPre=${podmanEnsureImage "docker.io/qdrant/qdrant:latest"}
    '';

    ".config/systemd/user/podman-local-ai-mindsdb.service.d/override.conf".text = ''
      [Unit]
      X-SwitchMethod=keep-old

      [Service]
      TimeoutStartSec=900
      TimeoutStopSec=240
      RestartSec=15
      ExecStartPre=${podmanEnsureImage "docker.io/mindsdb/mindsdb:latest"}
    '';
  })
  // {
    ".config/obsidian/ai-integrations/.keep".text = "";
    ".config/obsidian/ai-integrations/README".text = obsidianAiReadme;

    # Helper to sync Hugging Face models into the local cache
    ".local/bin/hf-model-sync" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if [[ $# -lt 1 ]]; then
          echo "Usage: hf-model-sync <model-id> [-- <extra-args>]" >&2
          exit 1
        fi

        model="$1"
        shift

        cache_root="''${HF_HOME:-$HOME/${huggingfaceCacheDir}}"
        mkdir -p "''${cache_root}/models"

        exec ${pythonAiEnv}/bin/huggingface-cli download "''${model}" "$@" \
          --local-dir "''${cache_root}/models/''${model}" \
          --cache-dir "''${cache_root}"
      '';
      executable = true;
    };


    # Launch Open WebUI via Podman for local AI experimentation
    ".local/bin/open-webui-run" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"
        image="''${OPEN_WEBUI_IMAGE:-ghcr.io/open-webui/open-webui:main}"
        port="''${OPEN_WEBUI_PORT:-${toString openWebUiPort}}"
        data_dir="''${OPEN_WEBUI_DATA_DIR:-$HOME/${openWebUiDataDir}}"
        network="''${PODMAN_AI_STACK_NETWORK:-local-ai}"

        mkdir -p "''${data_dir}"

        if ! ${pkgs.podman}/bin/podman network exists "''${network}" >/dev/null 2>&1; then
          ${pkgs.podman}/bin/podman network create "''${network}" >/dev/null
        fi

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          echo "Open WebUI container '""''${container_name}""' is already running" >&2
          exit 0
        fi

        exec ${pkgs.podman}/bin/podman run --rm \
          --name "''${container_name}" \
          --network "''${network}" \
          -p "''${port}:8080" \
          -v "''${data_dir}:/app/backend/data" \
          -e "OPENAI_API_BASE=http://host.containers.internal:${toString llamaCppPort}/v1" \
          -e "HF_HOME=''${HF_HOME:-$HOME/${huggingfaceCacheDir}}" \
          "''${image}"
      '';
      executable = true;
    };

    # Stop the Open WebUI container gracefully
    ".local/bin/open-webui-stop" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          exec ${pkgs.podman}/bin/podman stop "''${container_name}"
        else
          echo "Open WebUI container '""''${container_name}""' is not running" >&2
          exit 0
        fi
      '';
      executable = true;
    };

    ".local/bin/gpt-cli" = {
      text = ''
        #!${pythonAiInterpreterPath}
        import argparse
        import json
        import os
        import sys
        import textwrap
        import urllib.error
        import urllib.request

        try:
          from openai import OpenAI
        except Exception:
          OpenAI = None  # type: ignore


        def _read_prompt(args: argparse.Namespace) -> str:
          if args.prompt:
            return " ".join(args.prompt)

          data = sys.stdin.read()
          if not data.strip():
            raise SystemExit("gpt-cli: provide a prompt as arguments or via stdin")
          return data


        def _stream_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          stream = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
            stream=True,
          )

          for chunk in stream:
            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
              sys.stdout.write(chunk.choices[0].delta.content)
              sys.stdout.flush()
          print()


        def _complete_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          completion = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
          )
          print(completion.choices[0].message.content.strip())


        def main() -> None:
          parser = argparse.ArgumentParser(
            prog="gpt-cli",
            description="Talk to any OpenAI-compatible endpoint (including llama.cpp).",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog=textwrap.dedent(
              """
              Examples:
                gpt-cli "summarize the latest git commits"
                gpt-cli --system "You are a SQL assistant" < query.sql
              """
            ),
          )
          parser.add_argument("prompt", nargs=argparse.REMAINDER, help="Prompt text or leave empty to read stdin")
          parser.add_argument("--model", "-m", default=os.environ.get("GPT_CLI_DEFAULT_MODEL", "gpt-4o-mini"))
          parser.add_argument(
            "--base-url",
            default=os.environ.get("GPT_CLI_BASE_URL", os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")),
            help="Override the OpenAI-compatible base URL",
          )
          parser.add_argument("--system", default=os.environ.get("GPT_CLI_SYSTEM", "You are a helpful AI assistant."))
          parser.add_argument("--temperature", type=float, default=float(os.environ.get("GPT_CLI_TEMPERATURE", "0.2")))
          parser.add_argument("--stream", action="store_true", help="Stream tokens as they arrive")

          args = parser.parse_args()
          prompt = _read_prompt(args)

          if OpenAI is None:
            raise SystemExit("gpt-cli: openai python package is unavailable in the current environment")
          api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACEHUB_API_TOKEN") or "local"
          client = OpenAI(base_url=args.base_url.rstrip("/"), api_key=api_key)
          if args.stream:
            _stream_openai(client, args.model, args.system, prompt, args.temperature)
          else:
            _complete_openai(client, args.model, args.system, prompt, args.temperature)


        if __name__ == "__main__":
          main()
      '';
      executable = true;
    };

    ".local/bin/podman-ai-stack" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        root="''${NIXOS_QUICK_DEPLOY_ROOT:-}"
        if [[ -z "$root" && -f "$HOME/.config/nixos-quick-deploy/env" ]]; then
          root=$(awk -F= '/^NIXOS_QUICK_DEPLOY_ROOT=/{print $2}' "$HOME/.config/nixos-quick-deploy/env" | tail -n 1)
        fi

        if [[ -z "$root" ]]; then
          echo "podman-ai-stack: NIXOS_QUICK_DEPLOY_ROOT is not set." >&2
          echo "Run the quick deploy script again to regenerate your home-manager config." >&2
          exit 1
        fi

        exec "$root/scripts/hybrid-ai-stack.sh" "$@"
      '';
      executable = true;
    };

    ".config/nixos-quick-deploy/env".text = ''
      NIXOS_QUICK_DEPLOY_ROOT=NIXOS_QUICK_DEPLOY_ROOT_PLACEHOLDER
    '';

    ".local/bin/ai-servicectl" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        declare -a SYSTEM_COMPONENTS=(gitea)
        declare -a ALL_COMPONENTS=(gitea stack)
        declare -A SYSTEM_UNITS=(
          [gitea]="gitea.service"
        )

        usage() {
          cat <<'USAGE'
usage: ai-servicectl <command> [component...]

Commands:
  start     Start one or more components (defaults to 'all')
  stop      Stop one or more components (defaults to 'all')
  restart   Restart one or more components (defaults to 'all')
  status    Show a concise status summary (defaults to 'all')
  logs      Stream logs for a single component
  list      Show available components
  help      Show this message

Components:
  gitea, stack
  Groups: all, system, stack
USAGE
        }

        expand_components() {
          local -a input=("$@")
          local -a expanded=()
          local item
          for item in "''${input[@]}"; do
            case "$item" in
              all)
                expanded+=("''${ALL_COMPONENTS[@]}")
                ;;
              system)
                expanded+=("''${SYSTEM_COMPONENTS[@]}")
                ;;
              stack)
                expanded+=("stack")
                ;;
              *)
                expanded+=("$item")
                ;;
            esac
          done

          declare -A seen=()
          local -a deduped=()
          for item in "''${expanded[@]}"; do
            if [[ -n "$item" && -z "''${seen[$item]:-}" ]]; then
              seen[$item]=1
              deduped+=("$item")
            fi
          done

          printf '%s\n' "''${deduped[@]}"
        }

        ensure_stack_helper() {
          if ! command -v podman-ai-stack >/dev/null 2>&1; then
            echo "ai-servicectl: podman-ai-stack helper is not installed" >&2
            exit 1
          fi
        }

        system_unit_for() {
          local component="$1"
          local unit="''${SYSTEM_UNITS[$component]:-}"
          if [[ -z "$unit" ]]; then
            echo "ai-servicectl: unknown component '$component'" >&2
            exit 1
          fi
          printf '%s\n' "$unit"
        }

        run_action() {
          local action="$1"
          local component="$2"
          case "$component" in
            stack)
              ensure_stack_helper
              case "$action" in
                start) podman-ai-stack up ;;
                stop) podman-ai-stack down ;;
                restart) podman-ai-stack restart ;;
                status) podman-ai-stack status ;;
                logs) podman-ai-stack logs ;;
                *) echo "ai-servicectl: unsupported action '$action' for stack" >&2; exit 1 ;;
              esac
              ;;
            *)
              local unit
              unit=$(system_unit_for "$component")
              case "$action" in
                start) sudo systemctl start "$unit" ;;
                stop) sudo systemctl stop "$unit" ;;
                restart) sudo systemctl restart "$unit" ;;
                status)
                  if systemctl is-active --quiet "$unit"; then
                    echo "$component: active"
                  else
                    echo "$component: inactive"
                  fi
                  ;;
                logs) sudo journalctl -u "$unit" -f ;;
                *)
                  echo "ai-servicectl: unsupported action '$action'" >&2
                  exit 1
                  ;;
              esac
              ;;
          esac
        }

        cmd="''${1:-}"
        shift || true

        case "$cmd" in
          start|stop|restart)
            if [[ "$#" -eq 0 ]]; then
              set -- all
            fi
            mapfile -t components < <(expand_components "$@")
            for component in "''${components[@]}"; do
              run_action "$cmd" "$component"
            done
            ;;
          status)
            if [[ "$#" -eq 0 ]]; then
              set -- all
            fi
            mapfile -t components < <(expand_components "$@")
            for component in "''${components[@]}"; do
              run_action status "$component"
            done
            ;;
          logs)
            if [[ "$#" -eq 0 ]]; then
              echo "ai-servicectl: specify a component for logs" >&2
              exit 1
            fi
            if [[ "$#" -gt 1 ]]; then
              echo "ai-servicectl: logs supports exactly one component" >&2
              exit 1
            fi
            mapfile -t components < <(expand_components "$@")
            run_action logs "''${components[0]}"
            ;;
          list)
            echo "Available components:"
            printf '  - %s\n' "''${ALL_COMPONENTS[@]}"
            ;;
          help|-h|--help|"")
            usage
            ;;
          *)
            echo "ai-servicectl: unknown command '$cmd'" >&2
            usage
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    ".local/bin/code-cursor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ai.cursor.Cursor >/dev/null 2>&1; then
          exec flatpak run ai.cursor.Cursor "$@"
        fi

        echo "code-cursor: install the Cursor Flatpak (ai.cursor.Cursor) to use this helper" >&2
        exit 127
      '';
      executable = true;
    };

    ".local/bin/obsidian-ai-bootstrap" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        vault="''${1:-$HOME/Documents/ObsidianVault}"
        plugin_dir="''${2:-textgenerator}"
        plugin_url="''${OBSIDIAN_AI_PLUGIN_URL:-https://github.com/nhaouari/obsidian-textgenerator-plugin/releases/latest/download/obsidian-textgenerator-plugin.zip}"

        if [[ "$vault" == "--help" || "$vault" == "-h" ]]; then
          cat <<USAGE
Usage: obsidian-ai-bootstrap [vault-path] [plugin-directory]

Install AI-centric community plugins (Text Generator by default) into an Obsidian vault.

Environment variables:
  OBSIDIAN_AI_PLUGIN_URL   Override plugin bundle URL (zip file)
  OBSIDIAN_AI_BACKEND_URL  Override API endpoint (defaults to \$OPEN_WEBUI_URL)
USAGE
          exit 0
        fi

        if [[ -z "$vault" ]]; then
          echo "obsidian-ai-bootstrap: missing vault path" >&2
          exit 1
        fi

        backend_url="''${OBSIDIAN_AI_BACKEND_URL:-${openWebUiUrl}}"
        tmp_zip="$(mktemp -t obsidian-plugin.XXXXXX.zip)"
        trap "rm -f \"$tmp_zip\"" EXIT

        mkdir -p "$vault/.obsidian/plugins/$plugin_dir"

        echo "Downloading Obsidian AI plugin bundle..."
        curl -fsSL "$plugin_url" -o "$tmp_zip"

        unzip -qo "$tmp_zip" -d "$vault/.obsidian/plugins/$plugin_dir"

        cat >"$vault/.obsidian/plugins/$plugin_dir/data.json" <<PLUGINCFG
{
  "openAiBaseUrl": "${huggingfaceTgiEndpoint}/v1",
  "openAiKey": "",
  "defaultModel": "${huggingfaceModelId}",
  "stream": true,
  "useCustomEndpoint": true,
  "customEndpoint": "$backend_url"
}
PLUGINCFG

        echo "Obsidian AI plugins ready in: $vault/.obsidian/plugins/$plugin_dir"
      '';
      executable = true;
    };

    # Default configuration for aider so it respects repository structure
    ".config/aider/config.toml".text = ''
      # Aider configuration tailored for NixOS & Gitea workflows
      [core]
      auto_commits = false
      detect_language = true
      use_git = true

      [files]
      include = ["flake.nix", "home.nix", "configuration.nix", "**/*.nix", "**/*.md"]

      [editor]
      command = "DEFAULTEDITOR"
    '';

    # Tea CLI configuration pointing to the generated AI agent catalog
    ".config/tea/config.yml".text = ''
      default:
        host: http://localhost:3000
        user: gitea-admin

      ai:
        model: gpt-4o-mini
        agent_catalog: "$GITEA_CUSTOM/ai-agents.json"
        editor_command:
          - "$HOME/.local/bin/gitea-ai-assistant"
          - "%REPO%"
    '';

    # P10k configuration (dynamic - loads user preferences)
    ".p10k.zsh".text = ''
      # Powerlevel10k configuration for NixOS
      # This config adapts to your preferences set via p10k-setup-wizard
      # To reconfigure: rm ~/.config/p10k/.configured && exec zsh

      # Load user theme preferences (set by p10k-setup-wizard.sh)
      THEME_FILE="$HOME/.config/p10k/theme.sh"
      if [[ -f "$THEME_FILE" ]]; then
        source "$THEME_FILE"
      else
        # Defaults if not configured yet
        export P10K_STYLE="lean"
        export P10K_COLORS="dark"
        export P10K_SHOW_TIME=false
        export P10K_SHOW_OS=true
        export P10K_SHOW_CONTEXT=false
        export P10K_TRANSIENT=true
      fi

      # Enable instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Build prompt elements based on user preferences
      left_elements=(dir vcs prompt_char)
      [[ "$P10K_SHOW_OS" == "true" ]] && left_elements=(os_icon "''${left_elements[@]}")

      right_elements=(status command_execution_time background_jobs)
      [[ "$P10K_SHOW_TIME" == "true" ]] && right_elements=(time "''${right_elements[@]}")
      [[ "$P10K_SHOW_CONTEXT" == "true" ]] && right_elements+=(context)

      typeset -g POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=("''${left_elements[@]}")
      typeset -g POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=("''${right_elements[@]}")

      # Visual style
      typeset -g POWERLEVEL9K_MODE=nerdfont-complete
      typeset -g POWERLEVEL9K_ICON_PADDING=moderate

      # Prompt layout based on style
      case "$P10K_STYLE" in
        lean|pure)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
        classic|rainbow)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=true
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
      esac

      # Transient prompt
      [[ "$P10K_TRANSIENT" == "true" ]] && typeset -g POWERLEVEL9K_TRANSIENT_PROMPT=always

      # Enhanced Color schemes with better contrast
      case "$P10K_COLORS" in
        high-contrast-dark)
          # High contrast bright colors for dark terminals (RECOMMENDED)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=46
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=196
          ;;
        custom-high-contrast)
          # Maximum contrast for accessibility
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=15           # White
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=10     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=11  # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=13 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=9   # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=15       # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=10
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=9
          ;;
        light)
          # High contrast for light backgrounds
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=24
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=28
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=130
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=21
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=124
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=24
          ;;
        solarized)
          # Solarized Dark colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=81           # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=106    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=221 # Brighter yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=125 # Brighter magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=81
          ;;
        gruvbox)
          # Gruvbox colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=214
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=142
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=208
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=175
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=167
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=223
          ;;
        nord)
          # Nord colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=111          # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=150    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=147 # Brighter purple
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=210 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=153
          ;;
        dracula)
          # Dracula colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=141
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=121    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=177 # Brighter pink
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=212
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=183
          ;;
        *)
          # Dark (default) - bright colors
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          ;;
      esac

      # Common settings
      typeset -g POWERLEVEL9K_DIR_SHORTEN_STRATEGY=truncate_to_last
      typeset -g POWERLEVEL9K_DIR_SHORTEN_DIR_LENGTH=3
      typeset -g POWERLEVEL9K_STATUS_OK=false
      typeset -g POWERLEVEL9K_LINUX_NIXOS_ICON='❄️'
    '';
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      "${giteaFlatpakConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaFlatpakConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaFlatpakDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the Gitea Flatpak deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    }
    // {
      "${giteaNativeConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaNativeConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaNativeDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the native Gitea deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    };

  services.podman = lib.mkIf LOCAL_AI_STACK_ENABLED_PLACEHOLDER {
    enable = true;

    # Rootless storage tuning for AI stack containers
    settings.storage = {
      storage = {
        driver = "overlay";
        runroot = "/run/user/${let
          hmUid = if config.home ? uidNumber then config.home.uidNumber else null;
          osUsers =
            if config ? users && config.users ? users then config.users.users else {};
          osUser = osUsers.${config.home.username} or null;
          osUserUid = if osUser != null && osUser ? uid then osUser.uid else null;
          accountUsers =
            if config ? accounts && config.accounts ? users then config.accounts.users else {};
          accountUser = accountUsers.${config.home.username} or null;
          accountUid =
            if accountUser != null && accountUser ? uid then accountUser.uid else null;
          resolvedUid =
            if hmUid != null then hmUid
            else if osUserUid != null then osUserUid
          else if accountUid != null then accountUid
          else 1000;
          in toString resolvedUid}/containers";
        graphroot = "${config.home.homeDirectory}/.local/share/containers/storage";
        rootless_storage_path = "${config.home.homeDirectory}/.local/share/containers/storage";
      };
      storage.options = {
        mount_program = "${pkgs.fuse-overlayfs}/bin/fuse-overlayfs";
      };
    };

    networks."${podmanAiStackNetworkName}" = {
      description = "Isolated network for the local AI development stack";
      autoStart = false;
      labels = {
        "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
      };
    };

    containers = lib.mkMerge [
      # llama.cpp container (llama.cpp backend)
      # Uses the official llama.cpp server image
      # For AMD ROCm, build a custom image or use CPU mode
      (lib.mkIf (llmBackend == "llama_cpp") {
        "${podmanAiStackLlamaCppContainerName}" = {
          image = "ghcr.io/ggml-org/llama.cpp:server";
          description = "llama.cpp server for local LLM inference";
          autoStart = false;
          autoUpdate = "local";
          network = [ "${podmanAiStackNetworkName}.network" ];
          networkAlias = [ "llama-cpp" "llm" ];
          ports = [ "${toString llamaCppPort}:8080" ];
          volumes = [
            "${config.home.homeDirectory}/${podmanAiStackDataDir}/llama-cpp-models:/models"
          ];
          environment = {
            # llama.cpp/llama.cpp configuration
            HOST = "0.0.0.0";
            PORT = "8080";
            # Models will be pulled on first start
            MODEL_PATH = "/models";
            # AMD ROCm settings
            HSA_OVERRIDE_GFX_VERSION = "11.0.0";
            ROCM_PATH = "/opt/rocm";
          };
          labels = {
            "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
            "nixos.quick-deploy.llm-backend" = "llama_cpp";
            "nixos.quick-deploy.llm-models" = llmModels;
          };
        };
      })

      # Open WebUI (works with both backends via the 'llm' network alias)
      {
        "${podmanAiStackOpenWebUiContainerName}" = {
          image = "ghcr.io/open-webui/open-webui:main";
          description = "Open WebUI interface for the local AI stack";
          autoStart = false;
          autoUpdate = "local";
          network = [ "${podmanAiStackNetworkName}.network" ];
          networkAlias = [ "open-webui" ];
          ports = [ "${toString openWebUiPort}:8080" ];
          volumes = [
            "${config.home.homeDirectory}/${podmanAiStackDataDir}/open-webui:/app/backend/data"
          ];
          environment = {
            # llama.cpp uses OpenAI-compatible API
            OPENAI_API_BASE = "http://llama-cpp:${toString llamaCppPort}/v1";
          };
          labels = {
            "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
          };
        };
      }

      # Qdrant vector database (always included)
      {
        "${podmanAiStackQdrantContainerName}" = {
          image = "docker.io/qdrant/qdrant:v1.16.2";
          description = "Qdrant vector database for embeddings";
          autoStart = false;
          autoUpdate = "local";
          network = [ "${podmanAiStackNetworkName}.network" ];
          networkAlias = [ "qdrant" ];
          ports = [
            "${toString qdrantHttpPort}:6333"
            "${toString qdrantGrpcPort}:6334"
          ];
          volumes = [
            "${config.home.homeDirectory}/${podmanAiStackDataDir}/qdrant:/qdrant/storage"
          ];
          labels = {
            "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
          };
        };
      }

      # MindsDB orchestration (always included)
      {
        "${podmanAiStackMindsdbContainerName}" = {
          image = "docker.io/mindsdb/mindsdb:latest";  # Rolling release
          description = "MindsDB orchestration layer for AI workflows";
          autoStart = false;
          autoUpdate = "local";
          network = [ "${podmanAiStackNetworkName}.network" ];
          networkAlias = [ "mindsdb" ];
          ports = [
            "${toString mindsdbApiPort}:47334"
            "${toString mindsdbGuiPort}:7735"
          ];
          volumes = [
            "${config.home.homeDirectory}/${podmanAiStackDataDir}/mindsdb:/var/lib/mindsdb"
          ];
          labels = {
            "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
          };
        };
      }
    ];
  };

  # ========================================================================
  # Gitea Native Service (runs alongside Flatpak when present)
  # ========================================================================

  systemd.user.services =
    lib.mkMerge [
      # DISABLED: flatpak-managed-install systemd service
      # Reason: Direct flatpak remote installation is more reliable and avoids timeout issues
      # The deployment script now uses flatpak_bulk_install_apps() which calls
      # flatpak --noninteractive --assumeyes install --user flathub <apps...>
      # This provides better error handling and progress reporting than the systemd service.
      #
      # (lib.mkIf config.services.flatpak.enable {
      #   "flatpak-managed-install" = {
      #     Unit = {
      #       Description = "Declarative Flatpak managed installer";
      #       Documentation = [
      #         "https://nix-community.github.io/nix-flatpak/"
      #         "man:flatpak(1)"
      #       ];
      #       After = [ "graphical-session.target" "network-online.target" ];
      #       Wants = [ "network-online.target" ];
      #       ConditionPathExists = "/run/user/%U/allow-flatpak-managed-install";
      #       X-SwitchMethod = "keep-old";
      #     };
      #     Service = {
      #       Type = "oneshot";
      #       ExecStart = lib.mkForce flatpakManagedInstallScriptExe;
      #       ExecCondition = "${pkgs.coreutils}/bin/test -x ${pkgs.flatpak}/bin/flatpak";
      #       ExecStartPre = [
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.local/share/flatpak"
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.config/flatpak"
      #         "${pkgs.coreutils}/bin/mkdir -p %h/.var/app"
      #       ];
      #       Environment = [
      #         "HOME=%h"
      #         "XDG_RUNTIME_DIR=%t"
      #         "DBUS_SESSION_BUS_ADDRESS=unix:path=%t/bus"
      #       ];
      #       TimeoutStartSec = 3600;
      #       Restart = lib.mkForce "no";
      #       RemainAfterExit = false;
      #       StandardOutput = "journal";
      #       StandardError = "journal";
      #       SuccessExitStatus = "0 1";
      #     };
      #   };
      # })
      (lib.mkIf (glfMangoHudDesktopMode && glfMangoHudHasEntries && pkgs ? mangohud) {
        "mangohud-desktop" = {
          Unit = {
            Description = "MangoHud desktop overlay";
            Documentation = [ "https://github.com/flightlessmango/MangoHud" ];
            After = [ "graphical-session.target" ];
            PartOf = [ "graphical-session.target" ];
            ConditionPathExists = "%h/.config/MangoHud/MangoHud.conf";
          };
          Service = {
            Type = "simple";
            Environment = [
              "MANGOHUD=1"
              "MANGOHUD_CONFIGFILE=%h/.config/MangoHud/MangoHud.conf"
            ];
            ExecStart = "${pkgs.mangohud}/bin/mangoapp";
            Restart = "on-failure";
            RestartSec = 5;
            StandardOutput = "journal";
            StandardError = "journal";
          };
          Install = {
            WantedBy = [ "graphical-session.target" ];
          };
        };
      })
      {
        "gitea-dev" = {
          Unit = {
            Description = "Gitea development forge (user)";
            After = [ "network.target" ];
            PartOf = [ "default.target" ];
          };
          Service = {
            Environment = [
              "GITEA_WORK_DIR=%h/${giteaNativeDataDir}"
              "GITEA_CUSTOM=%h/${giteaNativeConfigDir}"
            ];
            ExecStart = "${pkgs.gitea}/bin/gitea web --config %h/${giteaNativeConfigDir}/app.ini";
            WorkingDirectory = "%h/${giteaNativeDataDir}";
            Restart = "on-failure";
            RestartSec = 3;
            TimeoutStopSec = 60;
          };
          Install = {
            WantedBy = [ "default.target" ];
          };
        };
        # Jupyter Lab server (user service for interactive development)
        # Disabled by default - start manually with: systemctl --user start jupyter-lab
        "jupyter-lab" = {
          Unit = {
            Description = "Jupyter Lab server for interactive AI/ML development";
            Documentation = [ "https://jupyter.org/documentation" ];
            After = [ "network.target" ];
            # Don't fail if network isn't ready
            Wants = [ "network.target" ];
          };
          Service = {
            Type = "simple";
            Environment = [
              "HOME=%h"
              "JUPYTER_DATA_DIR=%h/.local/share/jupyter"
              "JUPYTER_CONFIG_DIR=%h/.config/jupyter"
              "JUPYTER_RUNTIME_DIR=%h/.local/share/jupyter/runtime"
            ];
            # Create required directories before starting
            ExecStartPre = "${pkgs.writeShellScript "jupyter-setup" ''
              set -e
              mkdir -p "$HOME/.local/share/jupyter"
              mkdir -p "$HOME/.config/jupyter"
              mkdir -p "$HOME/notebooks"
            ''}";
            ExecStart = "${pkgs.writeShellScript "jupyter-start" ''
              exec ${pythonAiEnv}/bin/jupyter-lab \
                --ip=127.0.0.1 \
                --port=8888 \
                --no-browser \
                --notebook-dir="$HOME/notebooks"
            ''}";
            # Use home directory as fallback working directory
            WorkingDirectory = "%h";
            Restart = "on-failure";
            RestartSec = 10;
            TimeoutStopSec = 30;
          };
          Install = {
            # Disabled by default - notebooks should be started on demand
            # Enable with: systemctl --user enable --now jupyter-lab
            # WantedBy = [ "default.target" ];
          };
        };
      }
    ];

  # ========================================================================
  # Flatpak Integration - Manual Setup Instructions
  # ========================================================================
  # NOTE: Flatpak is installed at system level via:
  #   services.flatpak.enable = true  (in ~/.config/home-manager/configuration.nix)
  #
  # INSTALLATION INSTRUCTIONS (Run these once after system setup):
  #
  # 1. Add Flathub repository (one-time setup):
  #    flatpak remote-add --if-not-exists flathub \
  #      https://dl.flathub.org/repo/flathub.flatpakrepo
  #
  # 2. Install Flatpak applications (use commands below):
  #    # System Tools
  #    flatpak install -y flathub com.github.tchx84.Flatseal
  #    flatpak install -y flathub org.gnome.FileRoller
  #    flatpak install -y flathub net.nokyan.Resources
  #
  #    # Media Players
  #    flatpak install -y flathub org.videolan.VLC
  #    flatpak install -y flathub io.mpv.Mpv
  #
  #    # Web Browser
  #    flatpak install -y flathub org.mozilla.firefox
  #
  #    # Productivity
  #    flatpak install -y flathub md.obsidian.Obsidian
  #
  # 3. OR: Copy the list below and use this command:
  #    for app in com.github.tchx84.Flatseal org.gnome.FileRoller \
  #                net.nokyan.Resources org.videolan.VLC io.mpv.Mpv \
  #                org.mozilla.firefox md.obsidian.Obsidian; do
  #      flatpak install -y flathub "$app"
  #    done
  #
  # DECLARATIVE FLATPAK APPS (for reference - install manually):
  # ====================================================================
  # System Tools
  # flatpak install -y flathub com.github.tchx84.Flatseal
  # flatpak install -y flathub org.gnome.FileRoller
  # flatpak install -y flathub net.nokyan.Resources
  #
  # Media Players
  # flatpak install -y flathub org.videolan.VLC
  # flatpak install -y flathub io.mpv.Mpv
  #
  # Web Browsers
  # flatpak install -y flathub org.mozilla.firefox
  #
  # Productivity & Office
  # flatpak install -y flathub md.obsidian.Obsidian
  # # flatpak install -y flathub org.libreoffice.LibreOffice
  # # flatpak install -y flathub app.standard-notes.StandardNotes
  # # flatpak install -y flathub org.joplin.Joplin
  #
  # Development & Content Tools (GUI Applications)
  # # flatpak install -y flathub io.github.gitui.gitui
  # # flatpak install -y flathub fr.handbrake.ghb
  # # flatpak install -y flathub org.audacityteam.Audacity
  # # flatpak install -y flathub org.gimp.GIMP
  # # flatpak install -y flathub org.inkscape.Inkscape
  # # flatpak install -y flathub org.pitivi.Pitivi
  # # flatpak install -y flathub org.blender.Blender
  # # flatpak install -y flathub org.darktable.Darktable
  #
  # Additional Web Browsers (If needed)
  # # flatpak install -y flathub com.google.Chrome
  #
  # Internet & Communication (Desktop Apps)
  # # flatpak install -y flathub org.telegram.desktop
  # # flatpak install -y flathub com.slack.Slack
  # # flatpak install -y flathub org.thunderbird.Thunderbird
  # # flatpak install -y flathub io.Riot.Riot
  # # flatpak install -y flathub com.obsproject.Studio
  #
  # Database & Tools (GUI Applications)
  # # flatpak install -y flathub org.dbeaver.DBeaverCommunity
  # # flatpak install -y flathub com.beekeeperstudio.Studio
  # # flatpak install -y flathub com.mongodb.Compass
  #
  # Remote Access & Virtualization (GUI)
  # # flatpak install -y flathub org.remmina.Remmina
  # # flatpak install -y flathub com.freerdp.FreeRDP
  # # flatpak install -y flathub org.virt_manager.virt-manager
  #
  # Security & Privacy Tools (GUI Applications)
  # # flatpak install -y flathub org.gnome.Secrets
  # # flatpak install -y flathub org.keepassxc.KeePassXC
  # # flatpak install -y flathub com.github.Eloston.UngoogledChromium
  # # flatpak install -y flathub com.tutanota.Tutanota
  #
  # Entertainment & Gaming
  # # flatpak install -y flathub com.valvesoftware.Steam
  # # flatpak install -y flathub org.DolphinEmu.dolphin-emu
  # # flatpak install -y flathub net.rpcs3.RPCS3
  # # flatpak install -y flathub org.libretro.RetroArch
  #
  # ====================================================================
  # ALTERNATIVE: Use COSMIC App Store
  # ====================================================================
  # Simply open the COSMIC App Store from your application menu
  # and search for desired applications. Click Install to download
  # from Flathub. This is the most user-friendly method!
  #
  # MANAGE PERMISSIONS:
  # ====================================================================
  # flatpak run com.github.tchx84.Flatseal
  # (or open Flatseal from app menu)
  #
  # Then select app from sidebar and toggle permissions as needed.

  # services.flatpak: Declarative Flatpak management via nix-flatpak
  # When using flakes with the nix-flatpak module provided via flake imports, this section
  # defines all Flatpak applications declaratively.
  # When nix-flatpak is NOT available (channel-based install), this section
  # is ignored and you can install apps manually via flatpak CLI.
  #
  services.flatpak =
    let
      packagesElemTypePath = [ "services" "flatpak" "packages" "type" "elemType" ];
      packageOptionTypePath = [ "services" "flatpak" "package" "type" ];
      remoteTypePath = [ "services" "flatpak" "remotes" "type" "elemType" ];
      flatpakPackagesElemType =
        if lib.hasAttrByPath packagesElemTypePath options then
          lib.attrByPath packagesElemTypePath options null
        else
          null;
      flatpakPackageOptionType =
        if lib.hasAttrByPath packageOptionTypePath options then
          lib.attrByPath packageOptionTypePath options null
        else
          null;
      flatpakRemoteType =
        if lib.hasAttrByPath remoteTypePath options then
          lib.attrByPath remoteTypePath options null
        else
          null;
      checkCandidate = type: candidate:
        if type == null then true else (builtins.tryEval (type.check candidate)).success;
      selectCandidate = type: defaultCandidate: candidates:
        let
          found = lib.findFirst (candidate: checkCandidate type candidate) null candidates;
        in
          if found != null then found else defaultCandidate;
      mkFlathubRemote =
        selectCandidate
          flatpakRemoteType
          { name = flathubRemoteName; location = flathubRemoteUrl; }
          [
            { name = flathubRemoteName; location = flathubRemoteUrl; }
            { name = flathubRemoteName; url = flathubRemoteUrl; }
          ];
      mkFlathubPackage =
        appId:
          selectCandidate
            flatpakPackagesElemType
            { inherit appId; origin = flathubRemoteName; }
            [
              { inherit appId; origin = flathubRemoteName; }
              { inherit appId; remote = flathubRemoteName; }
            ];

    in
      {
        enable = true;
        remotes = [ mkFlathubRemote ];
        packages = map mkFlathubPackage flathubPackages;

        # Optional: Set permissions globally for all Flatpak packages
        # permissions = {
        #   "org.freedesktop.Flatpak" = {
        #     # Grant host filesystem access
        #     Context.filesystems = [
        #       "home"
        #       "/mnt"
        #     ];
        #   };
        # };
      }
      // lib.optionalAttrs (flatpakPackageOptionType != null) {
        package = selectCandidate flatpakPackageOptionType pkgs.flatpak [ pkgs.flatpak ];
      };

  # ========================================================================
  # Home Manager Auto-Upgrade Service (Optional)
  # ========================================================================
  # Automatically update your Home Manager configuration on a schedule.
  # This service uses flakes and pulls updates from your configuration directory.
  #
  # To enable: Set 'services.home-manager.autoUpgrade.enable = true;'
  # Schedule: Runs daily at 03:00 by default
  #
  # Reference: Home Manager news 2025-10-25
  # ========================================================================
  services.home-manager.autoUpgrade = {
    enable = false;  # Set to true to enable automatic updates
    frequency = "daily";  # Options: "daily", "weekly", "monthly"

    # Enable flake support (recommended for this deployment)
    useFlake = true;

    # Flake directory (uses the symlinked config location)
    flakeDir = "${config.home.homeDirectory}/.config/home-manager";
  };

}
