# NixOS Quick Deploy - Home Manager Configuration
# Generated by: nixos-quick-deploy.sh vVERSIONPLACEHOLDER
# Template Hash: HASHPLACEHOLDER
# This hash is used to detect when the template changes
# If you edit this file manually, your edits will be preserved
# until the template itself changes (new packages added to script)

{ config, pkgs, options, nixAiToolsPackages ? {}, ... }:

let
  lib = pkgs.lib;
  # Collect available derivations from the external nix-ai-tools flake so the
  # generated configuration gracefully degrades if certain outputs are missing.
  nixAiToolsPackageList =
    let
      candidateNames = [ "default" "nix-ai-tools" ];
    in
    lib.concatMap
      (name:
        lib.optional (lib.hasAttr name nixAiToolsPackages)
          (lib.getAttr name nixAiToolsPackages))
      candidateNames;
  giteaFlatpakAppId = "io.gitea.Gitea";
  giteaFlatpakConfigDir = ".var/app/${giteaFlatpakAppId}/config/gitea";
  giteaFlatpakDataDir = ".var/app/${giteaFlatpakAppId}/data/gitea";
  giteaNativeConfigDir = ".config/gitea";
  giteaNativeDataDir = ".local/share/gitea";
  giteaAiConfigFile = "ai-agents.json";
  huggingfaceCacheDir = ".cache/huggingface";
  huggingfaceModelId = "meta-llama/Meta-Llama-3-8B-Instruct";
  huggingfaceTgiEndpoint = "http://127.0.0.1:8080";
  huggingfaceTgiContainerEndpoint = "http://host.containers.internal:8080";
  ollamaPort = 11434;
  ollamaHost = "http://127.0.0.1:${toString ollamaPort}";
  openWebUiPort = 8081;
  openWebUiUrl = "http://127.0.0.1:${toString openWebUiPort}";
  openWebUiDataDir = ".local/share/open-webui";
  podmanAiStackDataDir = ".local/share/podman-ai-stack";
  podmanAiStackNetworkName = "local-ai";
  podmanAiStackLabelKey = "nixos.quick-deploy.ai-stack";
  podmanAiStackLabelValue = "true";
  podmanAiStackOllamaContainerName = "${podmanAiStackNetworkName}-ollama";
  podmanAiStackOpenWebUiContainerName = "${podmanAiStackNetworkName}-open-webui";
  podmanAiStackQdrantContainerName = "${podmanAiStackNetworkName}-qdrant";
  podmanAiStackMindsdbContainerName = "${podmanAiStackNetworkName}-mindsdb";
  qdrantHttpPort = 6333;
  qdrantGrpcPort = 6334;
  mindsdbApiPort = 47334;
  mindsdbGuiPort = 7735;
  claudeWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/claude-wrapper";
  claudeNodeModulesPath = "${config.home.homeDirectory}/.npm-global/lib/node_modules";
  gptCodexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gpt-codex-wrapper";
  codexWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/codex-wrapper";
  openaiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/openai-wrapper";
  gooseAiWrapperPath = "${config.home.homeDirectory}/.npm-global/bin/gooseai-wrapper";
  nixProfileBinPath = "${config.home.homeDirectory}/.nix-profile/bin";
  nodeExecutablePath = lib.makeBinPath [ pkgs.nodejs_22 ];
  claudePathValue = "${nixProfileBinPath}:${nodeExecutablePath}:/run/current-system/sw/bin:\${env:PATH}";
  aiPathValue = claudePathValue;
  aiNodeModulesPath = claudeNodeModulesPath;
  flathubRemoteName = "flathub";
  flathubRemoteUrl = "https://dl.flathub.org/repo/flathub.flatpakrepo";
  flathubRemoteFallbackUrl = "https://flathub.org/repo/flathub.flatpakrepo";
  # Duplicate desktop entries for COSMIC Settings appear on some releases.
  # Hide upstream variants and publish a single consistent launcher.
  cosmicSettingsDesktopFileNames = [
    "com.system76.CosmicSettings.desktop"
    "org.pop_os.CosmicSettings.desktop"
    "cosmic-settings.desktop"
  ];
  cosmicOnlyShowInEnvironments = [ "COSMIC" ];
  cosmicOnlyShowInValue =
    let
      joined = lib.concatStringsSep ";" cosmicOnlyShowInEnvironments;
    in
    if cosmicOnlyShowInEnvironments == [ ] then "" else "${joined};";
  commonPythonOverrides = import ./python-overrides.nix;

  # --------------------------------------------------------------------------
  # GLF (Gaming/Lifestyle Features) defaults. The deployment script injects
  # @GLF_HOME_DEFINITIONS@ with tuned values, but we fall back to safe
  # placeholders so the template remains evaluatable on its own.
  glfDefaultValues = {
    glfMangoHudPresets = {
      disabled = "";
      light = "";
      full = "";
    };
    glfMangoHudProfile = "disabled";
    glfMangoHudConfig = "";
    glfMangoHudConfigFileContents = "";
    glfLutrisWithGtk = pkgs.lutris;
    glfGamingPackages = [ ];
    glfSteamPackage = pkgs.steam;
    glfSteamCompatPackages = [ ];
    glfSystemUtilities = [ ];
  };

  glfOverrideValues =
    let
      overrides = rec {
        @GLF_HOME_DEFINITIONS@
      };
    in overrides;

  glfHomeValues = glfDefaultValues // glfOverrideValues;

  inherit (glfHomeValues)
    glfMangoHudPresets
    glfMangoHudProfile
    glfMangoHudConfig
    glfMangoHudConfigFileContents
    glfLutrisWithGtk
    glfGamingPackages
    glfSteamPackage
    glfSteamCompatPackages
    glfSystemUtilities;
  gpuMonitoringPackages =
    # Populated by nixos-quick-deploy.sh to enable vendor-specific GPU monitors.
    with pkgs; @GPU_MONITORING_PACKAGES@;
  nvtopPackagesAttr = if pkgs ? nvtopPackages then pkgs.nvtopPackages else { };
  fallbackNvtopPackages =
    if gpuMonitoringPackages != [ ] then
      [ ]
    else
      (lib.optionals (pkgs ? nvtop) [ pkgs.nvtop ])
      ++ (lib.optionals (nvtopPackagesAttr ? default) [ nvtopPackagesAttr.default ])
      ++ (lib.optionals (nvtopPackagesAttr ? nvidia) [ nvtopPackagesAttr.nvidia ])
      ++ (lib.optionals (nvtopPackagesAttr ? amd) [ nvtopPackagesAttr.amd ])
      ++ (lib.optionals (nvtopPackagesAttr ? intel) [ nvtopPackagesAttr.intel ]);
  # ============================================================================
  # Flatpak Applications (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Edit the list below to tailor the default Flatpak apps.
  # Comment out entries you do not need or append new App IDs.
  # Keep the DEFAULT_FLATPAK_APPS array in nixos-quick-deploy.sh in sync.
  flathubPackages = [
    # ====================================================================
    # SYSTEM TOOLS & UTILITIES (Recommended - Essential GUI Tools)
    # ====================================================================
    "com.github.tchx84.Flatseal"         # Flatpak permissions manager GUI
    "org.gnome.FileRoller"                # Archive manager (zip, tar, 7z, rar) - GUI
    "net.nokyan.Resources"                # System monitor (CPU, GPU, RAM, Network) - GUI

    # ====================================================================
    # MEDIA PLAYERS (Desktop Applications)
    # ====================================================================
    "org.videolan.VLC"                    # VLC media player (universal format support)
    "io.mpv.Mpv"                          # MPV video player (modern, lightweight)

    # ====================================================================
    # WEB BROWSERS
    # ====================================================================
    "org.mozilla.firefox"                 # Firefox browser (Flatpak, better sandbox isolation)

    # ====================================================================
    # PRODUCTIVITY & OFFICE (Popular for Work)
    # ====================================================================
    "md.obsidian.Obsidian"                # Note-taking with markdown, vault sync, plugins

    # ====================================================================
    # AI & LLM WORKBENCHES (Graphical tooling for local + cloud models)
    # ====================================================================
    # NOTE: The following apps are not available for all architectures
    # If you're on x86_64, you can uncomment these:
    # "ai.cursor.Cursor"                    # Cursor / Code-Cursor AI pair-programming IDE
    # "com.lmstudio.LMStudio"               # LM Studio for managing local LLM weights & servers

    # ====================================================================
    # DEVELOPMENT PLATFORM MANAGEMENT
    # ====================================================================
    # NOTE: Gitea Flatpak not available for all architectures (use system service instead)
    # "io.gitea.Gitea"                      # Gitea desktop (web UI) for Git/AIDB workflows
    "io.podman_desktop.PodmanDesktop"     # Podman Desktop GUI for managing containers
    "org.sqlitebrowser.sqlitebrowser"     # GUI browser for SQLite databases used by AIDB

    # ====================================================================
    # DATABASE TOOLS (AI/ML Data Management)
    # ====================================================================
    "com.dbeaver.DBeaverCommunity"        # Universal database tool (PostgreSQL, MySQL, SQLite, etc.)
  ];
  flatpakManagedInstallRuntimeInputs = [
    pkgs.coreutils
    pkgs.gawk
    pkgs.gnugrep
    pkgs.gnused
    pkgs.findutils
    pkgs.util-linux
    pkgs.flatpak
    pkgs.ostree
  ];
  flatpakManagedInstallScript =
    let
      packageArgs = lib.concatMapStringsSep " " (appId: lib.escapeShellArg appId) flathubPackages;
    in
    pkgs.writeShellApplication {
      name = "aidb-flatpak-managed-install";
      runtimeInputs = flatpakManagedInstallRuntimeInputs;
      text = ''
        set -euo pipefail

        remote_name=${flathubRemoteName}
        remote_url=${flathubRemoteUrl}
        remote_fallback_url=${flathubRemoteFallbackUrl}
        availability_message=""

        log() {
          printf '[%s] %s\n' "$(date --iso-8601=seconds)" "$*"
        }

        backup_legacy_flatpak_configs() {
          local -a targets=(
            "$HOME/.config/flatpak"
            "$HOME/.local/share/flatpak/overrides"
            "$HOME/.local/share/flatpak/remotes.d"
          )
          local backup_root="$HOME/.local/share/flatpak/managed-backups"
          local timestamp
          local performed=false
          local encountered_error=false

          timestamp="$(date +%Y%m%d_%H%M%S)"

          for path in "''${targets[@]}"; do
            if [[ ! -e "$path" && ! -L "$path" ]]; then
              continue
            fi

            if [[ -d "$path" && ! -L "$path" ]]; then
              if [[ -z "$(find "$path" -mindepth 1 -print -quit 2>/dev/null)" ]]; then
                continue
              fi
            fi

            local relative="''${path#"$HOME"/}"
            if [[ "$relative" == "$path" ]]; then
              relative="$(basename "$path")"
            fi

            local relative_dir="''${relative%/*}"
            if [[ "$relative_dir" == "$relative" ]]; then
              relative_dir="."
            fi

            local dest_dir="$backup_root/$timestamp/$relative_dir"
            local dest_path
            dest_path="$dest_dir/$(basename "$path")"

            if mkdir -p "$dest_dir" 2>/dev/null \
              && cp -a "$path" "$dest_path" 2>/dev/null; then
              rm -rf "$path" 2>/dev/null || true
              performed=true
              log "Backed up legacy Flatpak path $path -> $dest_path"
            else
              encountered_error=true
              log "Failed to back up legacy Flatpak path $path" >&2
            fi
          done

          mkdir -p "$HOME/.config/flatpak" 2>/dev/null || true

          if [[ "$performed" == true ]]; then
            log "Legacy Flatpak configuration preserved under $backup_root/$timestamp"
          fi

          if [[ "$encountered_error" == true ]]; then
            return 1
          fi

          return 0
        }

        reset_flatpak_repo_if_corrupted() {
          local repo_dir="$HOME/.local/share/flatpak/repo"
          local repo_config="$repo_dir/config"
          local repo_parent="$HOME/.local/share/flatpak"
          local repair_output=""

          mkdir -p "$repo_parent" 2>/dev/null || true

          # Check if repository is valid and complete
          if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
            return 0
          fi

          # Detect corrupted repository (exists but missing essential directories)
          if [[ -e "$repo_dir" ]]; then
            if [[ ! -f "$repo_config" || ! -d "$repo_dir/objects" ]]; then
              log "Detected corrupted Flatpak repository, removing and reinitializing..." >&2
              rm -rf "$repo_dir" 2>/dev/null || true
            fi
          fi

          if [[ ! -e "$repo_dir" ]]; then
            log "Initializing Flatpak repository under ''${repo_dir#"$HOME"/}"
          fi

          if ! mkdir -p "$repo_dir" 2>/dev/null; then
            log "Unable to recreate $repo_dir" >&2
            return 1
          fi

          # Try ostree initialization first (more reliable for fresh repos)
          if command -v ostree >/dev/null 2>&1; then
            local ostree_output=""
            ostree_output="$(
              ostree --repo="$repo_dir" init --mode=bare-user-only 2>&1
            )"
            local ostree_status=$?

            if [[ -n "$ostree_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line"
              done <<<"$ostree_output"
            fi

            if [[ $ostree_status -eq 0 && -f "$repo_config" ]]; then
              log "Flatpak repository initialized via ostree"
              # Run flatpak repair to finalize the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            fi

            # ostree init failed - manually create essential directory structure
            log "ostree init failed, creating repository structure manually..."

            # Remove any partial initialization and start fresh
            rm -rf "$repo_dir" 2>/dev/null || true
            mkdir -p "$repo_dir" 2>/dev/null || true

            # Create essential directories
            if ! (mkdir -p "$repo_dir/objects" "$repo_dir/tmp" \
                  "$repo_dir/refs/heads" "$repo_dir/refs/remotes" \
                  "$repo_dir/state" 2>/dev/null); then
              log "Failed to create repository directory structure" >&2
              return 1
            fi

            # Create minimal config file for bare-user-only mode
            if ! cat > "$repo_config" 2>/dev/null <<'OSTREE_CONFIG'
[core]
repo_version=1
mode=bare-user-only
OSTREE_CONFIG
            then
              log "Failed to create repository config file" >&2
              return 1
            fi

            # Verify the manual structure was created
            if [[ -f "$repo_config" && -d "$repo_dir/objects" ]]; then
              log "Flatpak repository structure created manually"
              # Run flatpak repair to finalize and validate the repo
              flatpak --user repair >/dev/null 2>&1 || true
              return 0
            else
              log "Repository structure verification failed" >&2
              return 1
            fi
          fi

          # Fall back to flatpak repair
          repair_output="$(
            flatpak --user repair 2>&1
          )"
          local repair_status=$?

          if [[ -n "$repair_output" ]]; then
            while IFS= read -r line; do
              log "  ↳ $line"
            done <<<"$repair_output"
          fi

          if [[ $repair_status -ne 0 ]]; then
            log "flatpak repair reported an error while attempting to recover the repository" >&2
          fi

          if [[ -f "$repo_config" ]]; then
            log "Flatpak repository initialized"
            return 0
          fi

          log "Flatpak repository configuration still missing after recovery attempts" >&2
          return 1
        }

        check_app_availability() {
          local app_id="$1"
          local user_output
          local user_status
          local system_output
          local system_status

          availability_message=""

          user_output="$(flatpak --user remote-info "$remote_name" "$app_id" 2>&1 || true)"
          user_status=$?
          if [[ $user_status -eq 0 ]]; then
            return 0
          fi

          system_output="$(flatpak remote-info "$remote_name" "$app_id" 2>&1 || true)"
          system_status=$?
          if [[ $system_status -eq 0 ]]; then
            return 0
          fi

          availability_message="$user_output"
          if [[ -n "$availability_message" && -n "$system_output" ]]; then
            availability_message+=$'
'
          fi
          availability_message+="$system_output"

          if printf '%s
' "$availability_message" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
            return 3
          fi

          return 1
        }

        ensure_remote() {
          if flatpak --user remotes --columns=name | awk 'NR == 1 && $1 == "Name" { next } { print $1 }' | grep -Fxq "$remote_name"; then
            log "Remote $remote_name already configured"
            return 0
          fi

          local -a remote_sources=()
          remote_sources+=("$remote_url")
          if [[ -n "$remote_fallback_url" && "$remote_fallback_url" != "$remote_url" ]]; then
            remote_sources+=("$remote_fallback_url")
          fi

          log "Adding Flatpak remote $remote_name"

          local source=""
          for source in "''${remote_sources[@]}"; do
            local from_output=""
            if from_output=$(flatpak --user remote-add --if-not-exists --from "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source (--from)"
              return 0
            fi

            if [[ -n "$from_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$from_output"
            fi

            local direct_output=""
            if direct_output=$(flatpak --user remote-add --if-not-exists "$remote_name" "$source" 2>&1); then
              log "Remote $remote_name added from $source"
              return 0
            fi

            if [[ -n "$direct_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$direct_output"
            fi
          done

          log "Failed to add remote $remote_name after trying: ''${remote_sources[*]}" >&2
          return 1
        }

        install_app() {
          local app_id="$1"

          if flatpak --user info "$app_id" >/dev/null 2>&1; then
            log "Flatpak $app_id already installed"
            return 0
          fi

          local availability_status=0
          check_app_availability "$app_id"
          availability_status=$?
          if [[ $availability_status -ne 0 ]]; then
            if [[ $availability_status -eq 3 ]]; then
              log "Flatpak $app_id not available on $remote_name for this architecture; skipping"
              if [[ -n "$availability_message" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$availability_message"
              fi
              return 0
            fi

            log "Unable to query metadata for $app_id prior to installation" >&2
            if [[ -n "$availability_message" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$availability_message"
            fi
            return 1
          fi

          local attempt=1
          while (( attempt <= 3 )); do
            local install_output=""
            if install_output=$(flatpak --noninteractive --user install "$remote_name" "$app_id" 2>&1); then
              log "Installed $app_id"
              return 0
            fi

            if printf '%s
' "$install_output" | grep -Eiq 'No remote refs found similar|No entry for|Nothing matches'; then
              log "Flatpak $app_id not available on $remote_name; skipping"
              if [[ -n "$install_output" ]]; then
                while IFS= read -r line; do
                  log "  ↳ $line"
                done <<<"$install_output"
              fi
              return 0
            fi

            log "Attempt $attempt failed for $app_id" >&2
            if [[ -n "$install_output" ]]; then
              while IFS= read -r line; do
                log "  ↳ $line" >&2
              done <<<"$install_output"
            fi
            sleep $(( attempt * 2 ))
            (( attempt += 1 ))
          done

          log "Giving up on $app_id after repeated failures" >&2
          return 1
        }

        backup_legacy_flatpak_configs || true

        if ! reset_flatpak_repo_if_corrupted; then
          log "Flatpak repository recovery failed" >&2
          exit 1
        fi

        ensure_remote || exit 1

        # shellcheck disable=SC2206
        packages=( ${packageArgs} )
        if [ ''${#packages[@]} -eq 0 ]; then
          log "No Flatpak packages declared; exiting"
          exit 0
        fi

        failures=0
        for app_id in "''${packages[@]}"; do
          if ! install_app "$app_id"; then
            failures=1
          fi
        done

        flatpak --user update --noninteractive --appstream || log "Appstream refresh failed (continuing)" >&2
        flatpak --user update --noninteractive || log "Flatpak update failed (continuing)" >&2

        exit $failures
      '';
    };
  nixAiHelpScript =
    pkgs.writeShellApplication {
      name = "nix-ai-help";
      text = ''
        set -euo pipefail

        usage() {
          cat <<'USAGE'
Usage: nix-ai-help [topic]

Topics:
  overview        High-level deployment summary and workflow guidance (default)
  flakes          Flake management, updates, and switch best practices
  home-manager    Home Manager integration details and troubleshooting tips
  flatpak         Declarative Flatpak management overview
  security        Hardening reminders tailored to AIDB developer workstations
  options         Discovering module options and documenting overrides
  resources       Curated references for deeper reading
  help            Display this help message
USAGE
        }

        print_overview() {
          cat <<'OVERVIEW'
NixOS Quick Deploy provisions a reproducible AIDB workstation using:
  • A NixOS flake that stitches together system modules and Home Manager
  • Declarative user configuration driven by home-manager from nix-community
  • nix-flatpak to install GUI tooling under ~/.local/share/flatpak declaratively

Recommended workflow:
  1. Track all customisations inside configuration.nix and home.nix
  2. Apply system changes with: sudo nixos-rebuild switch --flake .#HOSTNAME
  3. Update user profiles with: home-manager switch --flake .#USERNAME
  4. Review build plans using nix flake check before activating major upgrades
OVERVIEW
        }

        print_flakes() {
          cat <<'FLAKES'
Flake hygiene tips inspired by https://wiki.nixos.org/wiki/Flakes:
  • Pin channels through the flake inputs block and use follows= for reuse
  • Refresh inputs routinely: nix flake update --commit-lock-file
  • Validate changes locally: nix flake check and nixos-rebuild test --flake
  • For experimental packages, add an overlay or extra input such as nixpkgs-unstable
FLAKES
        }

        print_home_manager() {
          cat <<'HM'
Home Manager integration (https://github.com/nix-community/home-manager):
  • Enable programs via home-manager.users.<name>.imports in the flake outputs
  • Prefer systemd.user.startServices = lib.mkDefault ... to cooperate with sd-switch
  • Inspect generated options: home-manager help or home-manager options
  • Keep home.stateVersion aligned with the target channel before upgrades
HM
        }

        print_flatpak() {
          cat <<'FLATPAK'
Flatpak automation via nix-flatpak (https://github.com/gmodena/nix-flatpak):
  • Packages listed under xdg.portal.enable and xdg.desktopEntries stay in sync
  • Use aidb-flatpak-managed-install to mirror declarative packages on legacy setups
  • Inspect user services with systemctl --user status flatpak-managed-install.service
FLATPAK
        }

        print_security() {
          cat <<'SECURITY'
Security checklist (see https://wiki.nixos.org/wiki/Security):
  • Harden shells with pam configuration and consider enabling security.apparmor
  • Audit services enabled by configuration.nix using nixos-rebuild test --flake
  • Rotate secrets in ~/.config/gitea and ~/.config/huggingface regularly
  • Track upstream advisories via https://nixos.org/manual/nixos/stable/#sec-upgrading
SECURITY
        }

        print_options() {
          cat <<'OPTIONS'
Discovering options quickly:
  • nix search nixpkgs <pattern> for package discovery
  • nixos-option <path> --json | jq '.' to inspect live system values
  • home-manager option search '<pattern>' to explore user-level modules
  • Web catalogue: https://search.nixos.org/options?channel=25.05
OPTIONS
        }

        print_resources() {
          cat <<'RESOURCES'
Essential references leveraged by this environment:
  • nix-community/home-manager – authoritative module documentation
  • NixOS manual – https://nixos.org/manual/nixos/stable/
  • Populated examples: github.com/nomadics9/NixOS-Flake and github.com/novoid/nixos-config
  • Declarative desktop apps: github.com/gmodena/nix-flatpak and github.com/fufexan/dotfiles
  • Security hardening: https://wiki.nixos.org/wiki/Security
  • COSMIC-focused setups: github.com/rascal999/maxos
RESOURCES
        }

        if [ "$#" -eq 0 ]; then
          topic="overview"
        else
          topic="$1"
        fi

        case "$topic" in
          overview)
            print_overview
            ;;
          flakes)
            print_flakes
            ;;
          home-manager|homemanager)
            print_home_manager
            ;;
          flatpak)
            print_flatpak
            ;;
          security)
            print_security
            ;;
          options)
            print_options
            ;;
          resources)
            print_resources
            ;;
          help|-h|--help)
            usage
            ;;
          *)
            printf 'Unknown topic: %s\n\n' "$topic" >&2
            usage >&2
            exit 1
            ;;
        esac
      '';
    };
  flatpakManagedInstallScriptExe = lib.getExe flatpakManagedInstallScript;
  pythonAi =
    pkgs.python311.override {
      packageOverrides = commonPythonOverrides;
    };
  # ========================================================================
  # Python AI/ML Environment
  # ========================================================================
  # Comprehensive Python environment for AI/ML development including:
  # - Deep Learning: PyTorch, TensorFlow with GPU support
  # - Transformers: HuggingFace transformers, tokenizers, datasets
  # - LLM Frameworks: LangChain, LlamaIndex with all integrations
  # - Vector DBs: Chromadb, Qdrant, Pinecone, FAISS
  # - Data Science: NumPy, Pandas, Polars, Scikit-learn
  # - Visualization: Matplotlib, Seaborn, Gradio
  # - Development: JupyterLab, IPython, Black, Ruff, MyPy
  #
  # Optional packages to add if needed:
  # - jupyter-ai              # Jupyter AI chatbot (requires API keys)
  # - keras                   # High-level neural networks API
  # - xgboost                 # Gradient boosting framework
  # - lightgbm                # Light gradient boosting machine
  # - catboost                # Categorical gradient boosting
  # - optuna                  # Hyperparameter optimization
  # - mlflow                  # ML experiment tracking
  # - wandb                   # Weights & Biases tracking
  # - ray                     # Distributed computing framework
  # - streamlit               # Web app framework for ML

  pythonAiEnv =
    pythonAi.withPackages (ps:
      let
        # Core Python packages that should always be available
        base = with ps; [
          pip
          setuptools
          wheel
          # Jupyter and Interactive Development
          jupyterlab
          ipykernel
          ipython
          ipywidgets
          notebook
          # Data Science Core
          pandas
          numpy
          scikit-learn
          matplotlib
          seaborn
          # Code Quality Tools
          black
          ruff
          mypy
          pylint
          # AI/ML Fundamentals
          accelerate
          datasets
          diffusers
          peft
          safetensors
          sentencepiece
          tokenizers
          transformers
          evaluate
          gradio
          # Data Processing (Modern Alternatives)
          polars               # Fast DataFrame library (Rust-based)
          # LLM & AI APIs (Required)
          openai               # OpenAI API client
          anthropic            # Anthropic API client
          # Note: dask often causes build issues, added conditionally below
          # Deep Learning Frameworks (ALL REQUIRED - NOT OPTIONAL)
          torch
          torchaudio
          torchvision
          tensorflow
          bitsandbytes
          # LangChain Ecosystem
          langchain
          langchain-openai
          langchain-community
          langchain-core
          # LlamaIndex Ecosystem
          llama-index
          llama-index-core
          # Vector Databases & Embeddings
          chromadb
          qdrant-client
          pinecone-client
          faiss
          sentence-transformers
          # MCP & Agent Tooling
          litellm
          tiktoken
          fastapi
          uvicorn
          httpx
          aiohttp
          websockets
          pydantic
          typer
          rich
          sqlalchemy
          psycopg2
          redis
          alembic
          # Specialized AI Tools
          llama-cpp-python
          # Data Processing
          duckdb
          dask
          dask-ml
        ];
      in
        base
    );
  pythonAiInterpreterPath = "${pythonAiEnv}/bin/python3";
  huggingfaceReadme = ''
    Hugging Face configuration lives here.

    - Store your personal access token in the file "token" within this directory (never commit it).
    - CLI caches and credentials are isolated from Git repositories.
    - The hf-model-sync helper will reuse this token and cache when downloading models.
  '';
  openWebUiReadme = ''
    Persistent storage for Open WebUI when launched with the open-webui-run helper.

    - All chat history, uploads, and custom prompts are written here.
    - The helper binds this directory into the container at /app/backend/data.
    - Remove this directory to reset the Open WebUI state safely.
    - When using podman-ai-stack, this path is shared with the Open WebUI container managed by the stack.
  '';
  podmanAiStackReadme = ''
    Podman AI Stack shared storage.

    - ollama/: persistent model cache for the Ollama container.
    - open-webui/: shared chat history for the Open WebUI container.
    - qdrant/: vector database state for embeddings and RAG pipelines.
    - mindsdb/: MindsDB database files for AI-assisted SQL workflows.

    Use the podman-ai-stack helper to manage the lifecycle of the stack.
    The helper orchestrates Home Manager's services.podman quadlets and keeps
    this directory synchronized with container volumes.
  '';
  giteaDomain = "@HOSTNAME@";
  giteaHttpPort = 3000;
  giteaSshPort = 2222;
  giteaRootUrl = "http://${giteaDomain}:${toString giteaHttpPort}/";
  giteaSharedSettings = {
    server = {
      PROTOCOL = "http";
      DOMAIN = giteaDomain;
      HTTP_ADDR = "0.0.0.0";
      HTTP_PORT = giteaHttpPort;
      ROOT_URL = giteaRootUrl;
      STATIC_ROOT_PATH = "%(APP_DATA_PATH)s/public";
      ENABLE_GZIP = true;
      LFS_START_SERVER = true;
      LFS_JWT_SECRET = @GITEA_LFS_JWT_SECRET@;
      DISABLE_SSH = false;
      SSH_DOMAIN = giteaDomain;
      SSH_PORT = giteaSshPort;
      SSH_LISTEN_PORT = giteaSshPort;
      START_SSH_SERVER = true;
      LANDING_PAGE = "explore";
    };
    database = {
      DB_TYPE = "sqlite3";
      PATH = "%(GITEA_WORK_DIR)s/gitea.db";
      LOG_SQL = false;
    };
    repository = {
      ROOT = "%(GITEA_WORK_DIR)s/repositories";
      FORCE_PRIVATE = false;
    };
    packages.ENABLED = true;
    actions = {
      ENABLED = true;
      DEFAULT_ACTIONS_URL = "https://gitea.com";
    };
    indexer = {
      ISSUE_INDEXER_TYPE = "bleve";
      ISSUE_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/issues.bleve";
      REPO_INDEXER_ENABLED = true;
      REPO_INDEXER_PATH = "%(GITEA_WORK_DIR)s/indexers/repos.bleve";
    };
    ui = {
      DEFAULT_THEME = "arc-green";
      THEMES = "arc-green,auto,github";
      DEFAULT_SHOW_FULL_NAME = true;
    };
    service = {
      REGISTER_EMAIL_CONFIRM = false;
      DISABLE_REGISTRATION = false;
      REQUIRE_SIGNIN_VIEW = false;
      ENABLE_NOTIFY_MAIL = false;
    };
    security = {
      INSTALL_LOCK = true;
      PASSWORD_HASH_ALGO = "argon2";
      SECRET_KEY = @GITEA_SECRET_KEY@;
      INTERNAL_TOKEN = @GITEA_INTERNAL_TOKEN@;
    };
    oauth2.JWT_SECRET = @GITEA_JWT_SECRET@;
    log = {
      MODE = "console";
      LEVEL = "info";
    };
    lfs = {
      STORAGE_TYPE = "local";
      PATH = "%(GITEA_WORK_DIR)s/lfs";
    };
  };
  giteaSharedAppIni = lib.generators.toINI { } giteaSharedSettings;
  giteaAiIntegrations = ''
    {
      "agents": [
        {
          "name": "aider-openai",
          "command": [
            "aider",
            "--model",
            "gpt-4o-mini",
            "--repo",
            "%REPO_PATH%",
            "--no-auto-commits"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "AIDER_LOG_DIR": "%HOME%/.local/share/aider/logs"
          },
          "description": "Use aider to provide AI pair-programming suggestions for the current Gitea repository."
        },
        {
          "name": "tea-commit-summarizer",
          "command": [
            "tea",
            "ai",
            "summarize",
            "--repo",
            "%REPO_PATH%",
            "--model",
            "gpt-4o-mini"
          ],
          "environment": {
            "TEA_TOKEN": "ENV[TEA_TOKEN]"
          },
          "description": "Generate commit summaries with the Tea CLI leveraging configured AI providers."
        },
        {
          "name": "gpt-cli-local",
          "command": [
            "%HOME%/.local/bin/gpt-cli",
            "--provider",
            "openai",
            "--model",
            "${huggingfaceModelId}",
            "--base-url",
            "${huggingfaceTgiEndpoint}/v1"
          ],
          "environment": {
            "OPENAI_API_KEY": "ENV[OPENAI_API_KEY]",
            "GPT_CLI_DEFAULT_PROVIDER": "openai"
          },
          "description": "Run ad-hoc completions against the bundled Hugging Face Text Generation Inference endpoint via gpt-cli."
        },
        {
          "name": "podman-ai-stack-status",
          "command": [
            "%HOME%/.local/bin/podman-ai-stack",
            "status"
          ],
          "environment": {},
          "description": "Inspect the health of the local Podman AI stack (Ollama, Open WebUI, Qdrant, MindsDB)."
        },
        {
          "name": "launch-cursor",
          "command": [
            "%HOME%/.local/bin/code-cursor"
          ],
          "environment": {},
          "description": "Open the Cursor IDE configured for local model development sessions."
        }
      ],
      "notes": "Populate the referenced environment variables with the appropriate API tokens to enable AI workflows. The helpers bridge local containers, Cursor, and CLI tooling."
    }
  '';
  obsidianAiReadme = ''
    Obsidian AI integrations bootstrap directory.

    - Run `obsidian-ai-bootstrap` to install the Text Generator and other AI plugins.
    - The helper links plugins to Open WebUI or remote OpenAI-compatible endpoints configured on this system.
    - You can drop additional plugin ZIP files in this directory and rerun the helper to install them declaratively.
  '';
  systemdStartServicesDefault =
    let
      startServicesOption = options.systemd.user.startServices or null;
      allowedValues =
        let
          rawValues =
            if startServicesOption == null || !(startServicesOption ? type) then
              [ ]
            else if lib.isAttrs startServicesOption.type && startServicesOption.type ? enum then
              startServicesOption.type.enum
            else
              [ ];
          attempt = builtins.tryEval rawValues;
        in
        if attempt.success && lib.isList attempt.value then attempt.value else [ ];
      optionDefault =
        if startServicesOption != null && startServicesOption ? default then
          startServicesOption.default
        else
          null;
    in
    if lib.elem "legacy" allowedValues then
      "legacy"
    else if optionDefault != null then
      optionDefault
    else if allowedValues != [ ] then
      lib.head allowedValues
    else
      "legacy";
in

{
  # Declarative Flatpak management is enabled via nix-flatpak in flake.nix
  # The module is already included in the flake's module list, so no manual import is required here

  home.username = "HOMEUSERNAME";
  home.homeDirectory = "HOMEDIR";
  home.stateVersion = "STATEVERSION_PLACEHOLDER";  # Auto-detected from home-manager channel

  programs.home-manager.enable = true;

  # Newer Home Manager releases default to the sd-switch activator, which
  # relies on systemd's notification channel remaining responsive.  During the
  # NixOS deployment performed by nixos-quick-deploy.sh this runs outside of an
  # interactive login session, so the generated home-manager-hyperd.service can
  # hang waiting on that channel and ultimately time out.  Probe the available
  # startServices choices so we can prefer the more forgiving legacy activator
  # whenever it is still supported, while falling back to the upstream default
  # automatically as future Home Manager releases drop the legacy backend.
  systemd.user.startServices = lib.mkDefault systemdStartServicesDefault;
  xdg.desktopEntries =
    let
      hiddenCosmicEntry = {
        type = "Application";
        name = "COSMIC Settings";
        exec = "cosmic-settings";
        icon = "cosmic-settings";
        categories = [ "Settings" "System" ];
        noDisplay = true;
        settings =
          lib.optionalAttrs (cosmicOnlyShowInValue != "") {
            OnlyShowIn = cosmicOnlyShowInValue;
          };
      };
    in
    lib.mkMerge [
      (lib.genAttrs cosmicSettingsDesktopFileNames (_: hiddenCosmicEntry))
      {
        "aidb-cosmic-settings" = {
          name = "COSMIC Settings";
          type = "Application";
          exec = "cosmic-settings";
          icon = "cosmic-settings";
          categories = [ "Settings" "System" ];
          startupNotify = true;
          settings =
            lib.optionalAttrs (cosmicOnlyShowInValue != "") {
              OnlyShowIn = cosmicOnlyShowInValue;
            };
        };
      }
    ];
  # ============================================================================
  # Home Packages (USER CUSTOMIZATION ENTRY POINT)
  # ============================================================================
  # Adjust the lists below to tailor developer tooling.
  # Preflight/runtime critical tools (e.g., podman, jq, curl) should remain enabled.
  home.packages =
    let
      # Fix gpt4all to work with Qt6 6.10+ where GuiPrivate requires explicit find_package
      gpt4all-fixed = pkgs.gpt4all.overrideAttrs (oldAttrs: {
        postPatch = (oldAttrs.postPatch or "") + ''
          # Fix Qt6::GuiPrivate CMake target for Qt 6.10+
          # Qt 6.10 requires explicit find_package for private modules
          sed -i '/find_package(Qt6/a \
find_package(Qt6 COMPONENTS GuiPrivate REQUIRED)' CMakeLists.txt
        '';
      });

      # ALL AI command-line packages are REQUIRED (not optional)
      aiCommandLinePackages = with pkgs; [
        ollama
        gpt4all-fixed  # Fixed for Qt6 6.10+ GuiPrivate compatibility
        llama-cpp
      ];
      basePackages =
        [
          nixAiHelpScript
          # Python (REQUIRED for AIDB and AI model tooling)
          pythonAiEnv
        ]
        ++ nixAiToolsPackageList  # Install helper binaries exported by numtide/nix-ai-tools when available
        ++ (with pkgs; [
          # ========================================================================
          # AIDB v4.0 Requirements (CRITICAL - Must be installed)
          # ========================================================================

          podman                  # Container runtime for AIDB
          podman-compose          # Docker-compose compatibility
          podman-tui              # Terminal dashboard for Podman and containers
          sqlite                  # Tier 1 Guardian database
          openssl                 # Cryptographic operations
          bc                      # Basic calculator
          inotify-tools           # File watching for Guardian

          # ========================================================================
          # Core NixOS Development Tools
          # ========================================================================

          # Nix tools
          nix-tree                # Visualize Nix dependencies
          nix-index               # Index Nix packages for fast searching
          nix-prefetch-git        # Prefetch git repositories
          nixpkgs-fmt             # Nix code formatter
          alejandra               # Alternative Nix formatter
          statix                  # Linter for Nix
          deadnix                 # Find dead Nix code
          nix-output-monitor      # Better build output
          nix-du                  # Disk usage for Nix store
          nixpkgs-review          # Review nixpkgs PRs
          nix-diff                # Compare Nix derivations

          # ========================================================================
          # Development Tools
          # ========================================================================

          # Version control
          # Note: git installed via programs.git below (prevents collision)
          git-crypt               # Transparent file encryption in git
          tig                     # Text-mode interface for git
          lazygit                 # Terminal UI for git commands
          git-lfs                 # Large file storage (required for Hugging Face repos)

          # Text editors
          # Note: vim installed via programs.vim below (prevents collision)
          neovim                  # Modern Vim fork with async support
          # Note: vscodium installed via programs.vscode below
          code-cursor             # Cursor IDE (AI-powered editor)

          # Web browsers are now installed via Flatpak for better sandboxing:
          # Firefox: "org.mozilla.firefox" in services.flatpak.packages
          # Chromium: Available as "com.google.Chrome" if needed
          # (Both still available in home.packages comments if NixOS versions preferred)

          # Modern CLI tools
          ripgrep                 # Fast recursive grep (rg)
          ripgrep-all             # Ripgrep with PDF, archive support
          fd                      # Fast alternative to find
          deno                    # Secure TypeScript runtime for MCP tooling
          bun                     # High-performance JavaScript runtime
          bubblewrap              # Sandboxing utility for tool execution
          firejail                # Sandbox profiles for desktop/CLI apps
          criu                    # Checkpoint/restore utilities
          postgresql              # PostgreSQL client tools (psql)
          redis                   # Redis CLI tools
          fzf                     # Fuzzy finder for command line
          bat                     # Cat clone with syntax highlighting
          eza                     # Modern replacement for ls
          jq                      # JSON processor
          yq                      # YAML processor
          direnv                  # Automatic per-directory environment loading
          nix-direnv              # Direnv integration with Nix flakes
          choose                  # Human-friendly cut/awk alternative
          dust                    # Intuitive disk usage (du)
          duf                     # Disk usage/free utility (df)
          broot                   # Tree view with navigation
          dog                     # DNS lookup utility (dig)
          shellcheck              # Shell script static analysis

          # Terminal tools
          # Note: alacritty installed via programs.alacritty below (prevents collision)
          tmux                    # Terminal multiplexer
          zellij                  # Modern terminal workspace (Rust alternative to tmux)
          screen                  # Terminal session manager
          mosh                    # Mobile shell (SSH alternative)
          asciinema               # Terminal session recorder

          # File management
          ranger                  # Console file manager with VI bindings
          dos2unix                # Convert text file line endings
          unrar                   # Extract RAR archives
          p7zip                   # 7-Zip file archiver
          file                    # File type identification
          rsync                   # Fast incremental file transfer
          rclone                  # Rsync for cloud storage

          # Network tools
          wget                    # Network downloader
          curl                    # Transfer data with URLs
          netcat-gnu              # Network utility for TCP/UDP
          socat                   # Multipurpose relay (SOcket CAT)
          mtr                     # Network diagnostic tool (traceroute/ping)
          nmap                    # Network exploration and security scanner

          # Security & privacy tooling
          clamav                  # Antivirus engine and CLI scanner
          clamtk                  # GTK frontend for ClamAV scanning
          # rkhunter is currently unavailable in nixpkgs; re-enable once restored upstream
          # rkhunter                # Rootkit hunter integrity scanner
          lynis                   # Auditing tool for UNIX-based systems (includes rootkit detection)
          # chkrootkit has been removed from nixpkgs (unmaintained/archived upstream, didn't work on NixOS)
          # Use lynis for comprehensive security auditing including rootkit detection, or aide for file integrity
          aide                    # Advanced Intrusion Detection Environment (file integrity & rootkit detection)
          keepassxc               # Cross-platform password manager (GUI)
          gnupg                   # GNU Privacy Guard for encryption workflows
          seahorse                # GNOME credential manager for GnuPG/SSH
          pinentry-gnome3         # Pinentry dialog compatible with COSMIC/GNOME
          # YubiKey Manager Qt was removed because upstream marked it EOL and nixpkgs flags it insecure.
          # Install `yubikey-manager` (CLI) or `yubioath-flutter` manually if YubiKey support is required.

          # System tools
          htop                    # Interactive process viewer
          btop                    # Resource monitor with modern UI
          gnome-disk-utility # GUI disk manager and formatter
          parted                  # Command-line partitioning utility
          flatpak                 # Flatpak CLI for sandboxed desktop apps
          tree                    # Display directory tree structure
          unzip                   # Extract ZIP archives
          zip                     # Create ZIP archives
          bc                      # Arbitrary precision calculator
          efibootmgr              # Modify EFI Boot Manager variables

          # Observability & monitoring stack
          glances                 # System dashboard with sensor, process, network metrics
          grafana                 # Metrics visualization web UI
          prometheus              # Metrics collection server
          loki                    # Log aggregation backend
          promtail                # Promtail agent for Loki pipelines
          vector                  # Data pipeline for logs and metrics
          cockpit                 # Web-based host management and reporting

          # ========================================================================
          # Programming Languages & Tools
          # ========================================================================


          # Additional languages
          go                      # Go programming language
          rustc                   # Rust compiler
          cargo                   # Rust package manager
          ruby                    # Ruby programming language

          # Development utilities
          gnumake                 # GNU Make build automation
          gcc                     # GNU C/C++ compiler
          nodejs_22               # Node.js JavaScript runtime v22

          # ========================================================================
          # Virtualization & Emulation
          # ========================================================================

          qemu            # Machine emulator and virtualizer
          virtiofsd       # VirtIO filesystem daemon

          # ========================================================================
          # Desktop Environment - Cosmic (Rust-based modern desktop)
          # ========================================================================

          #cosmic-edit             # Cosmic text editor
          #cosmic-files            # Cosmic file manager
          #cosmic-term             # Cosmic terminal

          # ========================================================================
          # ZSH Configuration
          # ========================================================================

          # Note: zsh installed via programs.zsh below (prevents collision)
          zsh-syntax-highlighting # Command syntax highlighting
          #zsh-autosuggestions     # Command suggestions from history
          zsh-completions         # Additional completion definitions
          zsh-powerlevel10k       # Powerlevel10k theme
          grc                     # Generic colorizer for commands
          pay-respects            # Modern replacement for 'fuck'

          # ========================================================================
          # Fonts (Required for Powerlevel10k)
          # ========================================================================

          nerd-fonts.meslo-lg     # MesloLGS Nerd Font (recommended for p10k)
          nerd-fonts.fira-code    # Fira Code Nerd Font with ligatures
          nerd-fonts.jetbrains-mono # JetBrains Mono Nerd Font
          nerd-fonts.hack         # Hack Nerd Font
          font-awesome            # Font Awesome icon font
          powerline-fonts         # Powerline-patched fonts

          # ========================================================================
          # Text Processing
          # ========================================================================

          tldr                    # Simplified man pages
          cht-sh                  # Community cheat sheets
          pandoc                  # Universal document converter

          # ========================================================================
          # AI/ML Development Tools (Code Review Recommendations)
          # ========================================================================

          # Vector Search & Databases
          #meilisearch             # Fast, typo-tolerant search engine (requires service)
          #typesense               # Open-source alternative to Algolia (requires service)
          #weaviate                # Vector search engine with ML models (requires service)

          # ML Ops & Experimentation
          #mlflow                  # ML lifecycle management (use service instead)
          dvc                     # Data version control for ML projects

          # Data Processing & ETL
          #apache-arrow            # Columnar data format (included in Python env)
          duckdb                  # Analytical database (SQL analytics on Parquet)

          # Code Quality for AI Projects
          #bandit                  # Security linter for Python (in Python env)
          #vulture                 # Find dead Python code (in Python env)
          #radon                   # Code complexity metrics (in Python env)

          # API Development & Testing
          httpie                  # Modern HTTP client (better than curl for APIs)
          grpcurl                 # Like curl for gRPC
          k6                      # Load testing tool

          # Documentation & Visualization
          mermaid-cli             # Generate diagrams from markdown
          graphviz                # Graph visualization
          plantuml                # UML diagrams

          # Database Tools
          sqlite-utils            # CLI tool for manipulating SQLite databases
          litecli                 # SQLite CLI with autocomplete
          pgcli                   # PostgreSQL CLI with autocomplete

          # Performance Profiling
          #py-spy                  # Sampling profiler for Python (in Python env)
          hyperfine               # Command-line benchmarking tool

          # Container Security
          trivy                   # Vulnerability scanner for containers
          (pkgs.cosign.overrideAttrs (old: { doCheck = false; }))  # Container signing and verification (tests disabled due to nil pointer issue in test suite)

          # Kubernetes (Optional - for model deployment)
          # Uncomment if deploying ML models to Kubernetes
          #kubectl                 # Kubernetes CLI
          #k9s                     # Kubernetes TUI
          #helm                    # Kubernetes package manager

          # Monitoring & Observability (Enhanced)
          #prometheus-node-exporter  # System metrics (use system service)
          #grafana-agent             # Metrics collector (use system service)

          # ========================================================================
          # Utilities
          # ========================================================================

          mcfly           # Command history search
          navi            # Interactive cheatsheet
          starship        # Shell prompt
          hexedit         # Hex editor
          qrencode        # QR code generator
          age             # Modern encryption tool (for secrets management)
          sops            # Secrets operations (encrypted config files)
        ])
        ++ fallbackNvtopPackages
        ++ gpuMonitoringPackages;
      aiderPackage =
        if pkgs ? aider-chat then
          [ pkgs.aider-chat ]
        else if pkgs ? aider then
          [ pkgs.aider ]
        else
          [ ];
      giteaDevAiPackages =
        [
          pkgs.gitea               # Native Gitea server and CLI for local development
          pkgs.tea                 # Official Gitea CLI for automation and AI workflows
          # The OpenAI Python SDK is bundled via pythonAiEnv to avoid duplicate store paths.
        ]
        ++ aiderPackage;
    in
    basePackages ++ giteaDevAiPackages ++ aiCommandLinePackages;

  # ========================================================================
  # ZSH Configuration
  # ========================================================================

  programs.zsh = {
    enable = true;
    enableCompletion = true;
    syntaxHighlighting.enable = true;
    #autosuggestions.enable = false;

    history = {
      size = 100000;
      path = "${config.xdg.dataHome}/zsh/history";
    };

    shellAliases = {
      # Basic modern replacements
      ll = "eza -l --icons";
      la = "eza -la --icons";
      lt = "eza --tree --icons";
      cat = "bat";
      du = "dust";
      df = "duf";

      # NixOS specific
      nrs = "sudo nixos-rebuild switch";
      nrt = "sudo nixos-rebuild test";
      nrb = "sudo nixos-rebuild boot";
      hms = "home-manager switch";
      nfu = "nix flake update";
      nfc = "nix flake check";
      nfb = "nix build";
      nfd = "nix develop";

      # Nix development
      nix-dev = "nix develop -c $SHELL";
      nix-search = "nix search nixpkgs";
      nix-shell-pure = "nix-shell --pure";

      # Git shortcuts
      gs = "git status";
      ga = "git add";
      gc = "git commit";
      gp = "git push";
      gl = "git pull";
      gd = "git diff";
      gco = "git checkout";
      gb = "git branch";

      # Lazy tools
      lg = "lazygit";
      hf-sync = "hf-model-sync";
      hf-start = "sudo systemctl start huggingface-tgi.service";
      hf-stop = "sudo systemctl stop huggingface-tgi.service";
      hf-restart = "sudo systemctl restart huggingface-tgi.service";
      hf-logs = "journalctl -u huggingface-tgi.service -f";
      open-webui-up = "open-webui-run";
      open-webui-down = "open-webui-stop";
      ollama-list = "ollama list";
      ai-stack = "podman-ai-stack";
      gpt = "gpt-cli";
      cursor = "code-cursor";
      obsidian-ai = "obsidian-ai-bootstrap";

      # Find shortcuts
      ff = "fd";
      rg = "rg --smart-case";
    };

    # NixOS 25.11+: Use 'initContent' instead of 'initExtra'
    initContent = ''
      # Powerlevel10k First-Run Setup Wizard
      P10K_MARKER="$HOME/.config/p10k/.configured"
      P10K_WIZARD="$HOME/.local/bin/p10k-setup-wizard.sh"

      # Run setup wizard on first shell launch
      if [[ ! -f "$P10K_MARKER" && -f "$P10K_WIZARD" ]]; then
        echo ""
        echo "╔══════════════════════════════════════════════════════╗"
        echo "║  Welcome to your new ZSH setup!                     ║"
        echo "║  Let's configure Powerlevel10k...                   ║"
        echo "╚══════════════════════════════════════════════════════╝"
        echo ""
        "$P10K_WIZARD"
        echo ""
        echo "Please restart your shell to see the changes: exec zsh"
        return
      fi

      # Powerlevel10k instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Load Powerlevel10k theme
      source ${pkgs.zsh-powerlevel10k}/share/zsh-powerlevel10k/powerlevel10k.zsh-theme

      # P10k configuration (dynamic - adapts to user preferences)
      [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh

      # Enhanced command history with mcfly
      if command -v mcfly &> /dev/null; then
        eval "$(mcfly init zsh)"
      fi

      # FZF configuration
      export FZF_DEFAULT_COMMAND='fd --type f --hidden --follow --exclude .git'
      export FZF_CTRL_T_COMMAND="$FZF_DEFAULT_COMMAND"
      export FZF_ALT_C_COMMAND='fd --type d --hidden --follow --exclude .git'

      # Nix-specific environment
      export NIX_PATH=$HOME/.nix-defexpr/channels''${NIX_PATH:+:}$NIX_PATH

      # Better error messages
      export NIXPKGS_ALLOW_UNFREE=1
      '';
  };

  # ========================================================================
  # Cryptography & Secret Management
  # ========================================================================

  programs.gpg = {
    enable = true;
  };

  services.gpg-agent = {
    enable = true;
    # COSMIC relies on GNOME Keyring for SSH agent duties so we keep gpg-agent scoped to GPG only.
    enableSshSupport = false;
    enableExtraSocket = true;
    defaultCacheTtl = 3600;
    defaultCacheTtlSsh = 3600;
    pinentry.package = pkgs.pinentry-gnome3;
  };

  programs.password-store = {
    enable = true;
    package = pkgs.pass;
  };

  services.gnome-keyring = {
    enable = true;
    # Secrets + PKCS#11 back up COSMIC's keyring UI while ssh replaces the vanilla agent we disabled above.
    components = [
      "secrets"
      "ssh"
      "pkcs11"
    ];
  };

  # ========================================================================
  # Git Configuration
  # ========================================================================
  # Using GitHub no-reply email (username@users.noreply.github.com) to:
  # - Protect your privacy (email not exposed in commits)
  # - Comply with GitHub email privacy settings
  # - Prevent push rejections due to GH007 errors

  programs.git = {
    enable = true;
    package = pkgs.git;

    settings = {
      user = {
        # Git author information (uncomment + customize before committing):
        # name = "Your Name";
        # email = "you@example.com";
      };

      init.defaultBranch = "main";
      pull.rebase = false;
      core.editor = "DEFAULTEDITOR";

      alias = {
        st = "status";
        co = "checkout";
        br = "branch";
        ci = "commit";
        unstage = "reset HEAD --";
        last = "log -1 HEAD";
        visual = "log --oneline --graph --decorate --all";
      };
    };
  };

  # ========================================================================
  # Direnv - Automatic Development Environment Loading
  # ========================================================================
  # direnv automatically loads and unloads environment variables when entering
  # and leaving project directories. Combined with nix-direnv, it provides:
  # - Automatic activation of nix shells when cd'ing into projects
  # - Persistent dev shells (prevents garbage collection)
  # - Integration with VSCode and other editors
  # - No need to manually run 'nix develop' every time
  #
  # Usage: Add .envrc to your project with:
  #   use flake
  # Then run: direnv allow

  programs.direnv = {
    enable = true;
    nix-direnv.enable = true;

    # Silent mode - reduce terminal output noise
    enableBashIntegration = true;
    enableZshIntegration = true;

    # Configuration
    config = {
      global = {
        # Warn if direnv takes longer than 5 seconds to load
        warn_timeout = "5s";
      };
    };
  };

  # ========================================================================
  # Zellij - Modern Terminal Workspace
  # ========================================================================
  # Zellij is a modern terminal multiplexer (alternative to tmux) with:
  # - Floating panes and intuitive UI
  # - Client-server architecture (reconnect to sessions)
  # - Visual hints and discoverable keybindings
  # - Written in Rust for performance
  #
  # Usage:
  #   zellij           # Start new session
  #   zellij attach    # Reconnect to last session
  #   zellij ls        # List sessions
  #
  # Default keybindings (after Ctrl+g):
  #   Ctrl+g → p   # Panes mode (split, move, etc.)
  #   Ctrl+g → t   # Tabs mode
  #   Ctrl+g → s   # Scroll mode
  #   Ctrl+g → q   # Quit

  programs.zellij = {
    enable = true;

    # Configuration
    settings = {
      # Theme
      theme = "default";

      # Simplified mode (fewer modes for easier learning)
      simplified_ui = false;

      # Pane frames (borders around panes)
      pane_frames = true;

      # Default shell
      default_shell = "zsh";

      # Mouse support
      mouse_mode = true;

      # Copy on select
      copy_on_select = true;

      # Session serialization (save session layout)
      session_serialization = true;

      # Scroll buffer size (lines)
      scroll_buffer_size = 10000;
    };
  };

  # ========================================================================
  # Vim Configuration (minimal)
  # ========================================================================

  programs.vim = {
    enable = true;
    defaultEditor = false;  # Use DEFAULTEDITOR instead

    settings = {
      number = true;
      relativenumber = true;
      expandtab = true;
      tabstop = 2;
      shiftwidth = 2;
    };
  };

  # ========================================================================
  # VSCodium Configuration (Declarative)
  # ========================================================================

  programs.vscode = {
    enable = true;
    package = pkgs.vscodium;

    # NixOS 25.11: Use profiles.default for extensions and settings
    profiles.default = {
      # Extensions installed declaratively
      extensions =
        let
          fetchExtension = name:
            let
              path = lib.splitString "." name;
            in
              if lib.hasAttrByPath path pkgs.vscode-extensions then
                lib.getAttrFromPath path pkgs.vscode-extensions
              else
                null;
          extensionNames = [
            "jnoortheen.nix-ide"
            "arrterian.nix-env-selector"
            "eamodio.gitlens"
            "editorconfig.editorconfig"
            "esbenp.prettier-vscode"
            "ms-python.python"
            "ms-python.black-formatter"
            "ms-python.vscode-pylance"
            "ms-toolsai.jupyter"
            "ms-toolsai.jupyter-keymap"
            "ms-toolsai.jupyter-renderers"
            "continue.continue"
            "codeium.codeium"
          ];
          curated = lib.filter (pkg: pkg != null) (map fetchExtension extensionNames);
          marketplaceExtensionNames = [
            "Anthropic.claude-code"
            "gencay.vscode-chatgpt"
            "openai.chatgpt"
            "OpenAI.gpt-codex"
            "OpenAI.codex-ide"
            "GooseAI.gooseai-vscode"
          ];
          fetchMarketplaceExtension = name:
            let
              path = lib.splitString "." name;
            in
              if pkgs ? vscode-marketplace && lib.hasAttrByPath path pkgs.vscode-marketplace then
                lib.getAttrFromPath path pkgs.vscode-marketplace
              else
                null;
          marketplaceExtensions = lib.filter (pkg: pkg != null) (map fetchMarketplaceExtension marketplaceExtensionNames);
        in
          curated ++ marketplaceExtensions;

      # VSCodium settings (declarative)
      # Note: Claude Code paths will be added by bash script (dynamic)
      userSettings = {
      # Editor Configuration
      "editor.fontSize" = 14;
      "editor.fontFamily" = "'Fira Code', 'Droid Sans Mono', 'monospace'";
      "editor.fontLigatures" = true;
      "editor.formatOnSave" = true;
      "editor.formatOnPaste" = true;
      "editor.tabSize" = 2;
      "editor.insertSpaces" = true;
      "editor.detectIndentation" = true;
      "editor.minimap.enabled" = true;
      "editor.bracketPairColorization.enabled" = true;
      "editor.guides.bracketPairs" = true;

      # Nix-specific settings
      "nix.enableLanguageServer" = true;
      "nix.serverPath" = "nil";
      "nix.formatterPath" = "nixpkgs-fmt";
      "[nix]" = {
        "editor.defaultFormatter" = "jnoortheen.nix-ide";
        "editor.tabSize" = 2;
      };

      # Python & Jupyter integration
      "python.defaultInterpreterPath" = pythonAiInterpreterPath;
      "python.terminal.activateEnvironment" = true;
      "python.languageServer" = "Pylance";
      "python.analysis.typeCheckingMode" = "basic";
      "python.analysis.autoImportCompletions" = true;
      "python.formatting.provider" = "black";
      "python.testing.pytestEnabled" = true;
      "python.testing.unittestEnabled" = false;
      "python.dataScience.jupyterServerURI" = "local";
      "jupyter.askForKernelRestart" = false;
      "jupyter.jupyterServerType" = "local";
      "jupyter.notebookFileRoot" = "${config.home.homeDirectory}";
      "[python]" = {
        "editor.defaultFormatter" = "ms-python.black-formatter";
        "editor.formatOnSave" = true;
      };
      "[jupyter]" = {
        "editor.defaultFormatter" = "ms-toolsai.jupyter";
      };

      # Local AI endpoints
      "huggingface.endpoint" = "${huggingfaceTgiEndpoint}";
      "huggingface.defaultModel" = "${huggingfaceModelId}";
      "huggingface.telemetry.enableTelemetry" = false;
      "continue.defaultModel" = "Ollama (Llama 3)";
      "continue.enableTelemetry" = false;
      "continue.telemetryEnabled" = false;
      "continue.serverUrl" = "${openWebUiUrl}";
      "continue.models" = [
        {
          title = "Ollama (Llama 3)";
          provider = "ollama";
          model = "llama3";
          baseUrl = ollamaHost;
        }
        {
          title = "Hugging Face TGI";
          provider = "openai";
          model = huggingfaceModelId;
          baseUrl = "${huggingfaceTgiEndpoint}/v1";
        }
      ];
      "codeium.enableTelemetry" = false;
      "chatgpt.gpt3.apiBaseUrl" = "${huggingfaceTgiEndpoint}/v1";
      "chatgpt.gpt3.model" = "${huggingfaceModelId}";
      "chatgpt.response.showNotification" = false;

      # Git configuration
      "git.enableSmartCommit" = true;
      "git.autofetch" = true;
      "gitlens.codeLens.enabled" = true;

      # Terminal
      "terminal.integrated.defaultProfile.linux" = "zsh";
      "terminal.integrated.fontSize" = 13;
      "terminal.integrated.env.linux" = {
        "OPENAI_API_BASE" = "${huggingfaceTgiEndpoint}/v1";
        "OLLAMA_HOST" = ollamaHost;
        "GPT_CLI_BASE_URL" = "${huggingfaceTgiEndpoint}/v1";
      };

      # Claude Code integration (managed declaratively so the wrapper path is always correct)
      "claude-code.executablePath" = claudeWrapperPath;
      "claude-code.claudeProcessWrapper" = claudeWrapperPath;
      "claude-code.environmentVariables" = [
        {
          name = "PATH";
          value = claudePathValue;
        }
        {
          name = "NODE_PATH";
          value = claudeNodeModulesPath;
        }
      ];
      "claude-code.autoStart" = false;
      "claudeCode.executablePath" = claudeWrapperPath;
      "claudeCode.claudeProcessWrapper" = claudeWrapperPath;
      "claudeCode.environmentVariables" = [
        {
          name = "PATH";
          value = claudePathValue;
        }
        {
          name = "NODE_PATH";
          value = claudeNodeModulesPath;
        }
      ];
      "claudeCode.autoStart" = false;

      # Additional AI CLI wrappers
      "gpt-codex.executablePath" = gptCodexWrapperPath;
      "gpt-codex.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "gpt-codex.autoStart" = false;
      "gptCodex.executablePath" = gptCodexWrapperPath;
      "gptCodex.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "gptCodex.autoStart" = false;
      "codex.executablePath" = codexWrapperPath;
      "codex.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "codex.autoStart" = false;
      "codexIDE.executablePath" = codexWrapperPath;
      "codexIDE.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "codexIDE.autoStart" = false;
      "codexIde.executablePath" = codexWrapperPath;
      "codexIde.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "codexIde.autoStart" = false;
      "openai.executablePath" = openaiWrapperPath;
      "openai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "openai.autoStart" = false;
      "gooseai.executablePath" = gooseAiWrapperPath;
      "gooseai.environmentVariables" = [
        {
          name = "PATH";
          value = aiPathValue;
        }
        {
          name = "NODE_PATH";
          value = aiNodeModulesPath;
        }
      ];
      "gooseai.autoStart" = false;

      # Theme
      "workbench.colorTheme" = "Default Dark Modern";

      # File associations
      "files.associations" = {
        "*.nix" = "nix";
        "flake.lock" = "json";
      };

      # Miscellaneous
      "files.autoSave" = "afterDelay";
      "files.autoSaveDelay" = 1000;
      "explorer.confirmDelete" = false;
      "explorer.confirmDragAndDrop" = false;
      };
    };
  };

  # ========================================================================
  # Alacritty Terminal Configuration
  # ========================================================================

  programs.alacritty = {
    enable = true;
    settings = {
      window = {
        opacity = 0.95;
        padding = {
          x = 10;
          y = 10;
        };
      };
      font = {
        size = 11.0;
        normal = {
          family = "MesloLGS NF";
        };
      };
      colors = {
        primary = {
          background = "0x1e1e1e";
          foreground = "0xd4d4d4";
        };
      };
    };
  };

  # ========================================================================
  # Session Variables
  # ========================================================================

  home.sessionVariables =
    {
      EDITOR = "DEFAULTEDITOR";
      VISUAL = "DEFAULTEDITOR";
      NIXPKGS_ALLOW_UNFREE = "1";
      MANGOHUD = if glfMangoHudConfig != "" then "1" else "0";
      MANGOHUD_CONFIG = glfMangoHudConfig;
      # NPM Configuration
      NPM_CONFIG_PREFIX = "$HOME/.npm-global";
      # AI Development Tools
      AIDER_DEFAULT_MODEL = "gpt-4o-mini";
      AIDER_LOG_DIR = "$HOME/.local/share/aider/logs";
      TEA_AI_MODEL = "gpt-4o-mini";
      # Hugging Face Configuration
      HF_HOME = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_HUB_CACHE = "$HOME/${huggingfaceCacheDir}";
      TRANSFORMERS_CACHE = "$HOME/${huggingfaceCacheDir}";
      HUGGINGFACE_TGI_ENDPOINT = "${huggingfaceTgiEndpoint}";
      HUGGINGFACE_MODEL_ID = "${huggingfaceModelId}";
      HUGGINGFACE_TOKEN_PATH = "$HOME/.config/huggingface/token";
      HF_HUB_ENABLE_HF_TRANSFER = "1";
      # LLM Service Endpoints
      OLLAMA_HOST = "${ollamaHost}";
      OPEN_WEBUI_URL = "${openWebUiUrl}";
      GPT_CLI_DEFAULT_MODEL = "${huggingfaceModelId}";
      GPT_CLI_DEFAULT_PROVIDER = "openai";
      GPT_CLI_BASE_URL = "${huggingfaceTgiEndpoint}/v1";
      # Podman AI Stack
      PODMAN_AI_STACK_NETWORK = "local-ai";
      PODMAN_AI_STACK_DATA_ROOT = "$HOME/${podmanAiStackDataDir}";
      # Security & Credentials
      GNUPGHOME = "${config.home.homeDirectory}/.gnupg";
      PASSWORD_STORE_DIR = "${config.home.homeDirectory}/.local/share/password-store";
      # Ensure COSMIC sessions find the GNOME Keyring sockets started via systemd --user.
      GNOME_KEYRING_CONTROL = "$XDG_RUNTIME_DIR/keyring";
      SSH_AUTH_SOCK = "$XDG_RUNTIME_DIR/keyring/ssh";
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      GITEA_WORK_DIR = "$HOME/${giteaFlatpakDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaFlatpakConfigDir}";
    }
    // lib.optionalAttrs (!config.services.flatpak.enable) {
      GITEA_WORK_DIR = "$HOME/${giteaNativeDataDir}";
      GITEA_CUSTOM = "$HOME/${giteaNativeConfigDir}";
    };

@PODMAN_ROOTLESS_STORAGE@

  # ========================================================================
  # Session Path
  # ========================================================================
  # Ensure critical directories are in PATH for all shells and desktop sessions
  # This fixes issues where home-manager, claude-wrapper, and custom scripts
  # are not accessible after login or in new terminal sessions

  home.sessionPath = [
    "$HOME/.local/bin"           # Custom user scripts and wrappers
    "$HOME/.npm-global/bin"      # NPM global packages (claude-wrapper, etc.)
  ];

  # ========================================================================
  # Home Files
  # ========================================================================

  home.file =
    {
    # Create local bin directory
    ".local/bin/.keep".text = "";

    # Declarative VSCodium wrapper so the Claude CLI stays on PATH
    ".local/bin/codium-wrapped" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        export NPM_CONFIG_PREFIX="$HOME/.npm-global"
        export PATH="$HOME/.npm-global/bin:$HOME/.local/bin:$PATH"

        exec codium "$@"
      '';
      executable = true;
    };

    # P10k Setup Wizard
    ".local/bin/p10k-setup-wizard.sh" = {
      source = ./p10k-setup-wizard.sh;
      executable = true;
    };

    # Launcher for the Gitea editor that prefers Flatpak but falls back to native binaries
    ".local/bin/gitea-editor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ${giteaFlatpakAppId} >/dev/null 2>&1; then
          exec flatpak run ${giteaFlatpakAppId} "$@"
        elif command -v gitea >/dev/null 2>&1; then
          exec gitea "$@"
        elif command -v tea >/dev/null 2>&1; then
          exec tea "$@"
        else
          echo "error: gitea editor is not installed. Install via Flatpak or enable the native package." >&2
          exit 127
        fi
      '';
      executable = true;
    };

    # Helper to bridge local repositories with aider for AI-driven workflows
    ".local/bin/gitea-ai-assistant" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        usage() {
          echo "Usage: gitea-ai-assistant <repository-path> [-- <aider-args>...]" >&2
          exit 1
        }

        if [[ $# -lt 1 ]]; then
          usage
        fi

        repo_path="$1"
        shift

        if [[ "$repo_path" == "--" ]]; then
          usage
        fi

        if [[ ! -d "$repo_path/.git" ]]; then
          echo "error: $repo_path is not a git repository" >&2
          exit 2
        fi

        repo_path="$(realpath "$repo_path")"

        if [[ $# -gt 0 && "$1" == "--" ]]; then
          shift
        fi

        log_dir="$AIDER_LOG_DIR"
        if [[ -z "$log_dir" ]]; then
          log_dir="$HOME/.local/share/aider/logs"
        fi
        mkdir -p "$log_dir"

        model="$AIDER_DEFAULT_MODEL"
        if [[ -z "$model" ]]; then
          model="gpt-4o-mini"
        fi

        exec aider --model "$model" --repo "$repo_path" "$@"
      '';
      executable = true;
    };

    # NPM Configuration
    ".npmrc".text = ''
      prefix=''${HOME}/.npm-global
    '';

    # Git configuration template
    # Note: Set your name and email with:
    #   git config --global user.name "Your Name"
    #   git config --global user.email "you@example.com"
    ".gitconfig".text = ''
      [user]
      	# TODO: Set your name and email then run this command in the terminal: home-manager switch -b backup --flake ~/.dotfiles/home-manager
      	# name = Your Name
      	# email = you@example.com

      [init]
      	defaultBranch = main

      [pull]
      	rebase = false

      [core]
      	editor = ${if (config.home.sessionVariables.EDITOR or "") != "" then config.home.sessionVariables.EDITOR else "vim"}

      [alias]
      	st = status
      	co = checkout
      	br = branch
      	ci = commit
      	unstage = reset HEAD --
      	last = log -1 HEAD
      	visual = log --oneline --graph --decorate --all
    '';

    # Hugging Face configuration and cache keepers
    ".config/MangoHud/.keep".text = "";
    ".config/MangoHud/MangoHud.conf".text =
      let
        mangoHudEntries =
          lib.filter (entry: entry != "")
            (lib.splitString "," glfMangoHudConfig);
        mangoHudConfig = lib.concatStringsSep "\n" mangoHudEntries;
      in
      if mangoHudConfig != "" then
        mangoHudConfig + "\n"
      else
        "";
    ".config/huggingface/.keep".text = "";
    ".config/huggingface/README".text = huggingfaceReadme;
    "${huggingfaceCacheDir}/.keep".text = "";
    "${openWebUiDataDir}/.keep".text = "";
    "${openWebUiDataDir}/README".text = openWebUiReadme;
    "${podmanAiStackDataDir}/.keep".text = "";
    "${podmanAiStackDataDir}/README".text = podmanAiStackReadme;
    "${podmanAiStackDataDir}/ollama/.keep".text = "";
    "${podmanAiStackDataDir}/open-webui/.keep".text = "";
    "${podmanAiStackDataDir}/qdrant/.keep".text = "";
    "${podmanAiStackDataDir}/mindsdb/.keep".text = "";
    ".config/obsidian/ai-integrations/.keep".text = "";
    ".config/obsidian/ai-integrations/README".text = obsidianAiReadme;

    # Helper to sync Hugging Face models into the local cache
    ".local/bin/hf-model-sync" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if [[ $# -lt 1 ]]; then
          echo "Usage: hf-model-sync <model-id> [-- <extra-args>]" >&2
          exit 1
        fi

        model="$1"
        shift

        cache_root="''${HF_HOME:-$HOME/${huggingfaceCacheDir}}"
        mkdir -p "''${cache_root}/models"

        exec ${pythonAiEnv}/bin/huggingface-cli download "''${model}" "$@" \
          --local-dir "''${cache_root}/models/''${model}" \
          --cache-dir "''${cache_root}"
      '';
      executable = true;
    };

    # Manage the systemd Hugging Face Text Generation Inference service
    ".local/bin/hf-tgi" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        usage() {
          echo "Usage: hf-tgi {start|stop|restart|status|logs} [journalctl-args]" >&2
          exit 1
        }

        [[ $# -gt 0 ]] || usage

        case "$1" in
          start|stop|restart)
            exec sudo systemctl "$1" huggingface-tgi.service
            ;;
          status)
            exec systemctl status huggingface-tgi.service
            ;;
          logs)
            shift
            exec journalctl -u huggingface-tgi.service "$@"
            ;;
          *)
            usage
            ;;
        esac
      '';
      executable = true;
    };

    # Launch Open WebUI via Podman for local AI experimentation
    ".local/bin/open-webui-run" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"
        image="''${OPEN_WEBUI_IMAGE:-ghcr.io/open-webui/open-webui:latest}"
        port="''${OPEN_WEBUI_PORT:-${toString openWebUiPort}}"
        data_dir="''${OPEN_WEBUI_DATA_DIR:-$HOME/${openWebUiDataDir}}"
        network="''${PODMAN_AI_STACK_NETWORK:-local-ai}"

        mkdir -p "''${data_dir}"

        if ! ${pkgs.podman}/bin/podman network exists "''${network}" >/dev/null 2>&1; then
          ${pkgs.podman}/bin/podman network create "''${network}" >/dev/null
        fi

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          echo "Open WebUI container '""''${container_name}""' is already running" >&2
          exit 0
        fi

        exec ${pkgs.podman}/bin/podman run --rm \
          --name "''${container_name}" \
          --network "''${network}" \
          -p "''${port}:8080" \
          -v "''${data_dir}:/app/backend/data" \
          -e "OLLAMA_BASE_URL=http://host.containers.internal:${toString ollamaPort}" \
          -e "OPENAI_API_BASE=${huggingfaceTgiContainerEndpoint}/v1" \
          -e "HF_HOME=''${HF_HOME:-$HOME/${huggingfaceCacheDir}}" \
          "''${image}"
      '';
      executable = true;
    };

    # Stop the Open WebUI container gracefully
    ".local/bin/open-webui-stop" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        container_name="''${OPEN_WEBUI_CONTAINER_NAME:-open-webui-dev}"

        if ${pkgs.podman}/bin/podman ps --format '{{.Names}}' | grep -q "^''${container_name}$"; then
          exec ${pkgs.podman}/bin/podman stop "''${container_name}"
        else
          echo "Open WebUI container '""''${container_name}""' is not running" >&2
          exit 0
        fi
      '';
      executable = true;
    };

    ".local/bin/gpt-cli" = {
      text = ''
        #!${pythonAiInterpreterPath}
        import argparse
        import json
        import os
        import sys
        import textwrap
        import urllib.error
        import urllib.request

        try:
          from openai import OpenAI
        except Exception:
          OpenAI = None  # type: ignore


        def _read_prompt(args: argparse.Namespace) -> str:
          if args.prompt:
            return " ".join(args.prompt)

          data = sys.stdin.read()
          if not data.strip():
            raise SystemExit("gpt-cli: provide a prompt as arguments or via stdin")
          return data


        def _stream_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          stream = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
            stream=True,
          )

          for chunk in stream:
            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
              sys.stdout.write(chunk.choices[0].delta.content)
              sys.stdout.flush()
          print()


        def _complete_openai(client, model: str, system_prompt: str, user_prompt: str, temperature: float) -> None:
          completion = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt},
            ],
          )
          print(completion.choices[0].message.content.strip())


        def _ollama_request(base_url: str, payload: dict[str, object]) -> urllib.request.Request:
          data = json.dumps(payload).encode("utf-8")
          headers = {"Content-Type": "application/json"}
          return urllib.request.Request(base_url, data=data, headers=headers)


        def _ollama_stream(url: str, payload: dict[str, object]) -> None:
          request = _ollama_request(url, payload | {"stream": True})
          with urllib.request.urlopen(request) as response:
            for raw in response:
              line = raw.decode("utf-8").strip()
              if not line:
                continue
              event = json.loads(line)
              message = event.get("message") or {}
              content = message.get("content")
              if content:
                sys.stdout.write(content)
                sys.stdout.flush()
            print()


        def _ollama_complete(url: str, payload: dict[str, object]) -> None:
          request = _ollama_request(url, payload | {"stream": False})
          with urllib.request.urlopen(request) as response:
            body = json.load(response)
          message = body.get("message") or {}
          content = message.get("content", "")
          print(content.strip())


        def main() -> None:
          parser = argparse.ArgumentParser(
            prog="gpt-cli",
            description="Talk to local Ollama models or any OpenAI-compatible endpoint.",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog=textwrap.dedent(
              """
              Examples:
                gpt-cli "summarize the latest git commits"
                gpt-cli --provider ollama --model llama3 "write unit tests for foo()"
                gpt-cli --system "You are a SQL assistant" < query.sql
              """
            ),
          )
          parser.add_argument("prompt", nargs=argparse.REMAINDER, help="Prompt text or leave empty to read stdin")
          parser.add_argument("--model", "-m", default=os.environ.get("GPT_CLI_DEFAULT_MODEL", "gpt-4o-mini"))
          parser.add_argument(
            "--provider",
            choices=["openai", "ollama"],
            default=os.environ.get("GPT_CLI_DEFAULT_PROVIDER", "openai"),
            help="Select backend provider (default: openai)",
          )
          parser.add_argument(
            "--base-url",
            default=os.environ.get("GPT_CLI_BASE_URL", os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")),
            help="Override the OpenAI/Ollama base URL",
          )
          parser.add_argument("--system", default=os.environ.get("GPT_CLI_SYSTEM", "You are a helpful AI assistant."))
          parser.add_argument("--temperature", type=float, default=float(os.environ.get("GPT_CLI_TEMPERATURE", "0.2")))
          parser.add_argument("--stream", action="store_true", help="Stream tokens as they arrive")

          args = parser.parse_args()
          prompt = _read_prompt(args)

          if args.provider == "openai":
            if OpenAI is None:
              raise SystemExit("gpt-cli: openai python package is unavailable in the current environment")
            api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACEHUB_API_TOKEN")
            if not api_key:
              raise SystemExit("gpt-cli: set OPENAI_API_KEY or HUGGINGFACEHUB_API_TOKEN for OpenAI-compatible backends")

            client = OpenAI(base_url=args.base_url.rstrip("/"), api_key=api_key)
            if args.stream:
              _stream_openai(client, args.model, args.system, prompt, args.temperature)
            else:
              _complete_openai(client, args.model, args.system, prompt, args.temperature)
            return

          base = args.base_url.rstrip("/") or os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
          url = f"{base}/api/chat"
          payload: dict[str, object] = {
            "model": args.model,
            "messages": [
              {"role": "system", "content": args.system},
              {"role": "user", "content": prompt},
            ],
            "stream": args.stream,
            "options": {"temperature": args.temperature},
          }

          try:
            if args.stream:
              _ollama_stream(url, payload)
            else:
              _ollama_complete(url, payload)
          except urllib.error.URLError as exc:
            raise SystemExit(f"gpt-cli: failed to reach Ollama at {base}: {exc}")


        if __name__ == "__main__":
          main()
      '';
      executable = true;
    };

    ".local/bin/podman-ai-stack" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if ! command -v podman >/dev/null 2>&1; then
          echo "podman-ai-stack: podman CLI is required" >&2
          exit 127
        fi

        if ! systemctl --user --help >/dev/null 2>&1; then
          echo "podman-ai-stack: systemd --user is unavailable; log in to a graphical or linger-enabled session" >&2
          exit 1
        fi

        network="''${PODMAN_AI_STACK_NETWORK:-${podmanAiStackNetworkName}}"
        data_root="''${PODMAN_AI_STACK_DATA_ROOT:-$HOME/${podmanAiStackDataDir}}"
        label_key="${podmanAiStackLabelKey}"
        label_value="${podmanAiStackLabelValue}"
        network_unit="podman-''${network}.network"

        mapfile -t container_names <<'EOCONTAINERS'
${podmanAiStackOllamaContainerName}
${podmanAiStackOpenWebUiContainerName}
${podmanAiStackQdrantContainerName}
${podmanAiStackMindsdbContainerName}
EOCONTAINERS

        container_units=()
        for name in "''${container_names[@]}"; do
          container_units+=("podman-''${name}.service")
        done

        usage() {
          cat <<USAGE >&2
Usage: podman-ai-stack <command>

Commands:
  up         Start the Podman network and all AI services
  down       Stop the managed containers and network (volumes kept)
  restart    Restart all services (down + up)
  status     Show systemd and Podman status information
  logs       Stream journald logs from the managed units

Environment overrides:
  PODMAN_AI_STACK_DATA_ROOT  Base directory for persistent bind mounts
  PODMAN_AI_STACK_NETWORK    Custom network name (default: ${podmanAiStackNetworkName})
USAGE
        }

        ensure_directories() {
          mkdir -p "''${data_root}/ollama" "''${data_root}/open-webui" "''${data_root}/qdrant" "''${data_root}/mindsdb"
        }

        start_units() {
          local unit
          for unit in "$@"; do
            systemctl --user start "$unit"
          done
        }

        stop_units() {
          local unit
          for unit in "$@"; do
            systemctl --user stop "$unit" || true
          done
        }

        cmd=""
        if [[ $# -gt 0 ]]; then
          cmd="$1"
          shift
        fi

        [[ -n "$cmd" ]] || { usage; exit 1; }

        case "$cmd" in
          up)
            ensure_directories
            start_units "$network_unit"
            start_units "''${container_units[@]}"
            echo "podman-ai-stack: started services: ${podmanAiStackOllamaContainerName}, ${podmanAiStackOpenWebUiContainerName}, ${podmanAiStackQdrantContainerName}, ${podmanAiStackMindsdbContainerName}"
            ;;
          down)
            stop_units "''${container_units[@]}"
            stop_units "$network_unit"
            ;;
          restart)
            "$0" down
            "$0" up
            ;;
          status)
            echo "-- systemd unit status --"
            for unit in "$network_unit" "''${container_units[@]}"; do
              echo "[$unit]"
              systemctl --user --no-pager status "$unit" || true
              echo
            done

            echo "-- podman ps (running) --"
            podman ps --filter "label=$label_key=$label_value" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
            echo
            echo "-- podman ps -a (all managed containers) --"
            podman ps -a --filter "label=$label_key=$label_value" --format "table {{.Names}}\t{{.Status}}\t{{.CreatedAt}}"
            ;;
          logs)
            log_args=()
            for unit in "$network_unit" "''${container_units[@]}"; do
              log_args+=("-u" "$unit")
            done
            exec journalctl --user -f "''${log_args[@]}" "$@"
            ;;
          *)
            usage
            exit 1
            ;;
        esac
      '';
      executable = true;
    };

    ".local/bin/code-cursor" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        if command -v flatpak >/dev/null 2>&1 && flatpak info ai.cursor.Cursor >/dev/null 2>&1; then
          exec flatpak run ai.cursor.Cursor "$@"
        fi

        echo "code-cursor: install the Cursor Flatpak (ai.cursor.Cursor) to use this helper" >&2
        exit 127
      '';
      executable = true;
    };

    ".local/bin/obsidian-ai-bootstrap" = {
      text = ''
        #!/usr/bin/env bash
        set -euo pipefail

        vault="''${1:-$HOME/Documents/ObsidianVault}"
        plugin_dir="''${2:-textgenerator}"
        plugin_url="''${OBSIDIAN_AI_PLUGIN_URL:-https://github.com/nhaouari/obsidian-textgenerator-plugin/releases/latest/download/obsidian-textgenerator-plugin.zip}"

        if [[ "$vault" == "--help" || "$vault" == "-h" ]]; then
          cat <<USAGE
Usage: obsidian-ai-bootstrap [vault-path] [plugin-directory]

Install AI-centric community plugins (Text Generator by default) into an Obsidian vault.

Environment variables:
  OBSIDIAN_AI_PLUGIN_URL   Override plugin bundle URL (zip file)
  OBSIDIAN_AI_BACKEND_URL  Override API endpoint (defaults to \$OPEN_WEBUI_URL)
USAGE
          exit 0
        fi

        if [[ -z "$vault" ]]; then
          echo "obsidian-ai-bootstrap: missing vault path" >&2
          exit 1
        fi

        backend_url="''${OBSIDIAN_AI_BACKEND_URL:-${openWebUiUrl}}"
        tmp_zip="$(mktemp -t obsidian-plugin.XXXXXX.zip)"
        trap "rm -f \"$tmp_zip\"" EXIT

        mkdir -p "$vault/.obsidian/plugins/$plugin_dir"

        echo "Downloading Obsidian AI plugin bundle..."
        curl -fsSL "$plugin_url" -o "$tmp_zip"

        unzip -qo "$tmp_zip" -d "$vault/.obsidian/plugins/$plugin_dir"

        cat >"$vault/.obsidian/plugins/$plugin_dir/data.json" <<PLUGINCFG
{
  "openAiBaseUrl": "${huggingfaceTgiEndpoint}/v1",
  "openAiKey": "",
  "defaultModel": "${huggingfaceModelId}",
  "stream": true,
  "useCustomEndpoint": true,
  "customEndpoint": "$backend_url"
}
PLUGINCFG

        echo "Obsidian AI plugins ready in: $vault/.obsidian/plugins/$plugin_dir"
      '';
      executable = true;
    };

    # Default configuration for aider so it respects repository structure
    ".config/aider/config.toml".text = ''
      # Aider configuration tailored for NixOS & Gitea workflows
      [core]
      auto_commits = false
      detect_language = true
      use_git = true

      [files]
      include = ["flake.nix", "home.nix", "configuration.nix", "**/*.nix", "**/*.md"]

      [editor]
      command = "DEFAULTEDITOR"
    '';

    # Tea CLI configuration pointing to the generated AI agent catalog
    ".config/tea/config.yml".text = ''
      default:
        host: http://localhost:3000
        user: gitea-admin

      ai:
        model: gpt-4o-mini
        agent_catalog: "$GITEA_CUSTOM/ai-agents.json"
        editor_command:
          - "$HOME/.local/bin/gitea-ai-assistant"
          - "%REPO%"
    '';

    # P10k configuration (dynamic - loads user preferences)
    ".p10k.zsh".text = ''
      # Powerlevel10k configuration for NixOS
      # This config adapts to your preferences set via p10k-setup-wizard
      # To reconfigure: rm ~/.config/p10k/.configured && exec zsh

      # Load user theme preferences (set by p10k-setup-wizard.sh)
      THEME_FILE="$HOME/.config/p10k/theme.sh"
      if [[ -f "$THEME_FILE" ]]; then
        source "$THEME_FILE"
      else
        # Defaults if not configured yet
        export P10K_STYLE="lean"
        export P10K_COLORS="dark"
        export P10K_SHOW_TIME=false
        export P10K_SHOW_OS=true
        export P10K_SHOW_CONTEXT=false
        export P10K_TRANSIENT=true
      fi

      # Enable instant prompt
      if [[ -r "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh" ]]; then
        source "''${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-''${(%):-%n}.zsh"
      fi

      # Build prompt elements based on user preferences
      left_elements=(dir vcs prompt_char)
      [[ "$P10K_SHOW_OS" == "true" ]] && left_elements=(os_icon "''${left_elements[@]}")

      right_elements=(status command_execution_time background_jobs)
      [[ "$P10K_SHOW_TIME" == "true" ]] && right_elements=(time "''${right_elements[@]}")
      [[ "$P10K_SHOW_CONTEXT" == "true" ]] && right_elements+=(context)

      typeset -g POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=("''${left_elements[@]}")
      typeset -g POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=("''${right_elements[@]}")

      # Visual style
      typeset -g POWERLEVEL9K_MODE=nerdfont-complete
      typeset -g POWERLEVEL9K_ICON_PADDING=moderate

      # Prompt layout based on style
      case "$P10K_STYLE" in
        lean|pure)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
        classic|rainbow)
          typeset -g POWERLEVEL9K_PROMPT_ON_NEWLINE=true
          typeset -g POWERLEVEL9K_RPROMPT_ON_NEWLINE=false
          typeset -g POWERLEVEL9K_PROMPT_ADD_NEWLINE=true
          ;;
      esac

      # Transient prompt
      [[ "$P10K_TRANSIENT" == "true" ]] && typeset -g POWERLEVEL9K_TRANSIENT_PROMPT=always

      # Enhanced Color schemes with better contrast
      case "$P10K_COLORS" in
        high-contrast-dark)
          # High contrast bright colors for dark terminals (RECOMMENDED)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=46
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=196
          ;;
        custom-high-contrast)
          # Maximum contrast for accessibility
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=15           # White
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=10     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=11  # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=13 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=9   # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=15       # White
          typeset -g POWERLEVEL9K_PROMPT_CHAR_OK_VIINS_FOREGROUND=10
          typeset -g POWERLEVEL9K_PROMPT_CHAR_ERROR_VIINS_FOREGROUND=9
          ;;
        light)
          # High contrast for light backgrounds
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=24
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=28
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=130
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=21
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=124
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=24
          ;;
        solarized)
          # Solarized Dark colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=81           # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=106    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=221 # Brighter yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=125 # Brighter magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=81
          ;;
        gruvbox)
          # Gruvbox colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=214
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=142
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=208
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=175
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=167
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=223
          ;;
        nord)
          # Nord colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=111          # Brighter blue
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=150    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=147 # Brighter purple
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=210 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=153
          ;;
        dracula)
          # Dracula colors (enhanced)
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=141
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=121    # Brighter green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=228
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=177 # Brighter pink
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=212
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=183
          ;;
        *)
          # Dark (default) - bright colors
          typeset -g POWERLEVEL9K_DIR_FOREGROUND=51           # Bright cyan
          typeset -g POWERLEVEL9K_VCS_CLEAN_FOREGROUND=46     # Bright green
          typeset -g POWERLEVEL9K_VCS_MODIFIED_FOREGROUND=226 # Bright yellow
          typeset -g POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND=201 # Bright magenta
          typeset -g POWERLEVEL9K_STATUS_ERROR_FOREGROUND=196 # Bright red
          typeset -g POWERLEVEL9K_OS_ICON_FOREGROUND=231      # White
          ;;
      esac

      # Common settings
      typeset -g POWERLEVEL9K_DIR_SHORTEN_STRATEGY=truncate_to_last
      typeset -g POWERLEVEL9K_DIR_SHORTEN_DIR_LENGTH=3
      typeset -g POWERLEVEL9K_STATUS_OK=false
      typeset -g POWERLEVEL9K_LINUX_NIXOS_ICON='❄️'
    '';
    }
    // lib.optionalAttrs config.services.flatpak.enable {
      "${giteaFlatpakConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaFlatpakConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaFlatpakDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the Gitea Flatpak deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    }
    // {
      "${giteaNativeConfigDir}/app.ini".text = giteaSharedAppIni;
      "${giteaNativeConfigDir}/${giteaAiConfigFile}".text = giteaAiIntegrations;
      "${giteaNativeDataDir}/README".text = ''
        This directory stores repositories, logs, and AI agent state for the native Gitea deployment.
        It is managed declaratively by Home Manager; manual changes may be overwritten on switch.
      '';
    };

  services.podman = {
    enable = true;

    networks."${podmanAiStackNetworkName}" = {
      description = "Isolated network for the local AI development stack";
      autoStart = false;
      labels = {
        "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
      };
    };

    containers = {
      "${podmanAiStackOllamaContainerName}" = {
        image = "docker.io/ollama/ollama:latest";
        description = "Ollama inference runtime (rootless Podman)";
        autoStart = false;
        autoUpdate = "registry";
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "ollama" ];
        ports = [ "${toString ollamaPort}:11434" ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/ollama:/root/.ollama"
        ];
        environment = {
          OLLAMA_HOST = "0.0.0.0";
        };
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackOpenWebUiContainerName}" = {
        image = "ghcr.io/open-webui/open-webui:latest";
        description = "Open WebUI interface for the local AI stack";
        autoStart = false;
        autoUpdate = "registry";
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "open-webui" ];
        ports = [ "${toString openWebUiPort}:8080" ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/open-webui:/app/backend/data"
        ];
        environment = {
          OLLAMA_BASE_URL = "http://ollama:${toString ollamaPort}";
          OPENAI_API_BASE = "${huggingfaceTgiContainerEndpoint}/v1";
        };
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackQdrantContainerName}" = {
        image = "docker.io/qdrant/qdrant:latest";
        description = "Qdrant vector database for embeddings";
        autoStart = false;
        autoUpdate = "registry";
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "qdrant" ];
        ports = [
          "${toString qdrantHttpPort}:6333"
          "${toString qdrantGrpcPort}:6334"
        ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/qdrant:/qdrant/storage"
        ];
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };

      "${podmanAiStackMindsdbContainerName}" = {
        image = "docker.io/mindsdb/mindsdb:latest";
        description = "MindsDB orchestration layer for AI workflows";
        autoStart = false;
        autoUpdate = "registry";
        network = [ "${podmanAiStackNetworkName}.network" ];
        networkAlias = [ "mindsdb" ];
        ports = [
          "${toString mindsdbApiPort}:47334"
          "${toString mindsdbGuiPort}:7735"
        ];
        volumes = [
          "${config.home.homeDirectory}/${podmanAiStackDataDir}/mindsdb:/var/lib/mindsdb"
        ];
        labels = {
          "${podmanAiStackLabelKey}" = podmanAiStackLabelValue;
        };
      };
    };
  };

  # ========================================================================
  # Gitea Native Service (runs alongside Flatpak when present)
  # ========================================================================

  systemd.user.services =
    lib.mkMerge [
      (lib.mkIf config.services.flatpak.enable {
        "flatpak-managed-install" = {
          Unit = {
            Description = "Declarative Flatpak managed installer";
            Documentation = [
              "https://nix-community.github.io/nix-flatpak/"
              "man:flatpak(1)"
            ];
            After = [ "graphical-session.target" "network-online.target" ];
            Wants = [ "network-online.target" ];
            # Condition prevents auto-start during home-manager activation
            # The deployment script creates this flag file only when it's safe to run
            ConditionPathExists = "/run/user/%U/allow-flatpak-managed-install";
            # PartOf removed - service should only be started explicitly by the deployment
            # script, not automatically during systemd reloads or graphical-session.target
            # activation, to prevent blocking home-manager activation if it fails.
            # X-SwitchMethod prevents home-manager from attempting to start/stop/restart
            # this service during activation, avoiding "timed out waiting on channel" errors
            X-SwitchMethod = "keep-old";
          };
          Service = {
            Type = "oneshot";
            Path = flatpakManagedInstallRuntimeInputs;
            ExecStart = lib.mkForce flatpakManagedInstallScriptExe;
            ExecCondition = "${pkgs.coreutils}/bin/test -x ${pkgs.flatpak}/bin/flatpak";
            ExecStartPre = [
              "${pkgs.coreutils}/bin/mkdir -p %h/.local/share/flatpak"
              "${pkgs.coreutils}/bin/mkdir -p %h/.config/flatpak"
              "${pkgs.coreutils}/bin/mkdir -p %h/.var/app"
            ];
            Environment = [
              "HOME=%h"
              "XDG_RUNTIME_DIR=%t"
              "DBUS_SESSION_BUS_ADDRESS=unix:path=%t/bus"
            ];
            TimeoutStartSec = 600;
            Restart = lib.mkForce "no";
            RemainAfterExit = false;
            StandardOutput = "journal";
            StandardError = "journal";
            # Ignore failure on ExecCondition to prevent blocking
            SuccessExitStatus = "0 1";
          };
          # Install section removed to prevent auto-start on home-manager activation.
          # The nixos-quick-deploy.sh script handles starting this service explicitly
          # via ensure_flatpak_managed_install_service() when appropriate.
          # This prevents the service from blocking home-manager activation if it fails.
        };
      })
      {
        "gitea-dev" = {
          Unit = {
            Description = "Gitea development forge (user)";
            After = [ "network.target" ];
            PartOf = [ "default.target" ];
          };
          Service = {
            Environment = [
              "GITEA_WORK_DIR=%h/${giteaNativeDataDir}"
              "GITEA_CUSTOM=%h/${giteaNativeConfigDir}"
            ];
            ExecStart = "${pkgs.gitea}/bin/gitea web --config %h/${giteaNativeConfigDir}/app.ini";
            WorkingDirectory = "%h/${giteaNativeDataDir}";
            Restart = "on-failure";
            RestartSec = 3;
            TimeoutStopSec = 60;
          };
          Install = {
            WantedBy = [ "default.target" ];
          };
        };
        # Note: Qdrant and Hugging Face TGI are configured as system services in configuration.nix
        # They are disabled by default to prevent startup issues during deployment.
        # Enable them manually after deployment:
        #   sudo systemctl enable --now qdrant
        #   sudo systemctl enable --now huggingface-tgi
        #
        # Jupyter Lab server (user service for interactive development)
        # Disabled by default - enable manually with: systemctl --user enable --now jupyter-lab
        "jupyter-lab" = {
          Unit = {
            Description = "Jupyter Lab server for interactive AI/ML development";
            Documentation = [ "https://jupyter.org/documentation" ];
            After = [ "network.target" ];
          };
          Service = {
            Type = "simple";
            Environment = [
              "JUPYTER_DATA_DIR=%h/.local/share/jupyter"
              "JUPYTER_CONFIG_DIR=%h/.config/jupyter"
              "JUPYTER_RUNTIME_DIR=%h/.local/share/jupyter/runtime"
            ];
            ExecStartPre = [
              "${pkgs.coreutils}/bin/mkdir -p %h/.local/share/jupyter"
              "${pkgs.coreutils}/bin/mkdir -p %h/.config/jupyter"
              "${pkgs.coreutils}/bin/mkdir -p %h/notebooks"
            ];
            ExecStart = ''
              ${pythonAiEnv}/bin/jupyter-lab \
                --ip=127.0.0.1 \
                --port=8888 \
                --no-browser \
                --notebook-dir=%h/notebooks
            '';
            WorkingDirectory = "%h/notebooks";
            Restart = "on-failure";
            RestartSec = 5;
            TimeoutStopSec = 30;
          };
          Install = {
            # Disabled by default to avoid startup issues during deployment
            # WantedBy = [ "default.target" ];
          };
        };
      }
    ];

  # ========================================================================
  # Flatpak Integration - Manual Setup Instructions
  # ========================================================================
  # NOTE: Flatpak is installed at system level via:
  #   services.flatpak.enable = true  (in ~/.config/home-manager/configuration.nix)
  #
  # INSTALLATION INSTRUCTIONS (Run these once after system setup):
  #
  # 1. Add Flathub repository (one-time setup):
  #    flatpak remote-add --if-not-exists flathub \
  #      https://dl.flathub.org/repo/flathub.flatpakrepo
  #
  # 2. Install Flatpak applications (use commands below):
  #    # System Tools
  #    flatpak install -y flathub com.github.tchx84.Flatseal
  #    flatpak install -y flathub org.gnome.FileRoller
  #    flatpak install -y flathub net.nokyan.Resources
  #
  #    # Media Players
  #    flatpak install -y flathub org.videolan.VLC
  #    flatpak install -y flathub io.mpv.Mpv
  #
  #    # Web Browser
  #    flatpak install -y flathub org.mozilla.firefox
  #
  #    # Productivity
  #    flatpak install -y flathub md.obsidian.Obsidian
  #
  # 3. OR: Copy the list below and use this command:
  #    for app in com.github.tchx84.Flatseal org.gnome.FileRoller \
  #                net.nokyan.Resources org.videolan.VLC io.mpv.Mpv \
  #                org.mozilla.firefox md.obsidian.Obsidian; do
  #      flatpak install -y flathub "$app"
  #    done
  #
  # DECLARATIVE FLATPAK APPS (for reference - install manually):
  # ====================================================================
  # System Tools
  # flatpak install -y flathub com.github.tchx84.Flatseal
  # flatpak install -y flathub org.gnome.FileRoller
  # flatpak install -y flathub net.nokyan.Resources
  #
  # Media Players
  # flatpak install -y flathub org.videolan.VLC
  # flatpak install -y flathub io.mpv.Mpv
  #
  # Web Browsers
  # flatpak install -y flathub org.mozilla.firefox
  #
  # Productivity & Office
  # flatpak install -y flathub md.obsidian.Obsidian
  # # flatpak install -y flathub org.libreoffice.LibreOffice
  # # flatpak install -y flathub app.standard-notes.StandardNotes
  # # flatpak install -y flathub org.joplin.Joplin
  #
  # Development & Content Tools (GUI Applications)
  # # flatpak install -y flathub io.github.gitui.gitui
  # # flatpak install -y flathub fr.handbrake.ghb
  # # flatpak install -y flathub org.audacityteam.Audacity
  # # flatpak install -y flathub org.gimp.GIMP
  # # flatpak install -y flathub org.inkscape.Inkscape
  # # flatpak install -y flathub org.pitivi.Pitivi
  # # flatpak install -y flathub org.blender.Blender
  # # flatpak install -y flathub org.darktable.Darktable
  #
  # Additional Web Browsers (If needed)
  # # flatpak install -y flathub com.google.Chrome
  #
  # Internet & Communication (Desktop Apps)
  # # flatpak install -y flathub org.telegram.desktop
  # # flatpak install -y flathub com.slack.Slack
  # # flatpak install -y flathub org.thunderbird.Thunderbird
  # # flatpak install -y flathub io.Riot.Riot
  # # flatpak install -y flathub com.obsproject.Studio
  #
  # Database & Tools (GUI Applications)
  # # flatpak install -y flathub org.dbeaver.DBeaverCommunity
  # # flatpak install -y flathub com.beekeeperstudio.Studio
  # # flatpak install -y flathub com.mongodb.Compass
  #
  # Remote Access & Virtualization (GUI)
  # # flatpak install -y flathub org.remmina.Remmina
  # # flatpak install -y flathub com.freerdp.FreeRDP
  # # flatpak install -y flathub org.virt_manager.virt-manager
  #
  # Security & Privacy Tools (GUI Applications)
  # # flatpak install -y flathub org.gnome.Secrets
  # # flatpak install -y flathub org.keepassxc.KeePassXC
  # # flatpak install -y flathub com.github.Eloston.UngoogledChromium
  # # flatpak install -y flathub com.tutanota.Tutanota
  #
  # Entertainment & Gaming
  # # flatpak install -y flathub com.valvesoftware.Steam
  # # flatpak install -y flathub org.DolphinEmu.dolphin-emu
  # # flatpak install -y flathub net.rpcs3.RPCS3
  # # flatpak install -y flathub org.libretro.RetroArch
  #
  # ====================================================================
  # ALTERNATIVE: Use COSMIC App Store
  # ====================================================================
  # Simply open the COSMIC App Store from your application menu
  # and search for desired applications. Click Install to download
  # from Flathub. This is the most user-friendly method!
  #
  # MANAGE PERMISSIONS:
  # ====================================================================
  # flatpak run com.github.tchx84.Flatseal
  # (or open Flatseal from app menu)
  #
  # Then select app from sidebar and toggle permissions as needed.

  # services.flatpak: Declarative Flatpak management via nix-flatpak
  # When using flakes with the nix-flatpak module provided via flake imports, this section
  # defines all Flatpak applications declaratively.
  # When nix-flatpak is NOT available (channel-based install), this section
  # is ignored and you can install apps manually via flatpak CLI.
  #
  services.flatpak =
    let
      packagesElemTypePath = [ "services" "flatpak" "packages" "type" "elemType" ];
      packageOptionTypePath = [ "services" "flatpak" "package" "type" ];
      remoteTypePath = [ "services" "flatpak" "remotes" "type" "elemType" ];
      flatpakPackagesElemType =
        if lib.hasAttrByPath packagesElemTypePath options then
          lib.attrByPath packagesElemTypePath options null
        else
          null;
      flatpakPackageOptionType =
        if lib.hasAttrByPath packageOptionTypePath options then
          lib.attrByPath packageOptionTypePath options null
        else
          null;
      flatpakRemoteType =
        if lib.hasAttrByPath remoteTypePath options then
          lib.attrByPath remoteTypePath options null
        else
          null;
      checkCandidate = type: candidate:
        if type == null then true else (builtins.tryEval (type.check candidate)).success;
      selectCandidate = type: defaultCandidate: candidates:
        let
          found = lib.findFirst (candidate: checkCandidate type candidate) null candidates;
        in
          if found != null then found else defaultCandidate;
      mkFlathubRemote =
        selectCandidate
          flatpakRemoteType
          { name = flathubRemoteName; location = flathubRemoteUrl; }
          [
            { name = flathubRemoteName; location = flathubRemoteUrl; }
            { name = flathubRemoteName; url = flathubRemoteUrl; }
          ];
      mkFlathubPackage =
        appId:
          selectCandidate
            flatpakPackagesElemType
            { inherit appId; origin = flathubRemoteName; }
            [
              { inherit appId; origin = flathubRemoteName; }
              { inherit appId; remote = flathubRemoteName; }
            ];

    in
      {
        enable = true;
        remotes = [ mkFlathubRemote ];
        packages = map mkFlathubPackage flathubPackages;

        # Optional: Set permissions globally for all Flatpak packages
        # permissions = {
        #   "org.freedesktop.Flatpak" = {
        #     # Grant host filesystem access
        #     Context.filesystems = [
        #       "home"
        #       "/mnt"
        #     ];
        #   };
        # };
      }
      // lib.optionalAttrs (flatpakPackageOptionType != null) {
        package = selectCandidate flatpakPackageOptionType pkgs.flatpak [ pkgs.flatpak ];
      };

}
