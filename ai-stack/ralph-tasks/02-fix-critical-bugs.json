{
  "task_id": "02-fix-critical-bugs",
  "description": "CRITICAL: Fix 12 production-breaking bugs - resource leaks, race conditions, XSS, blocking calls",
  "backend": "aider",
  "max_iterations": 20,
  "require_approval": false,
  "context": {
    "severity": "CRITICAL - These bugs will cause production crashes, security breaches, and memory leaks",
    "categories": "6 CRITICAL bugs, 6 HIGH severity bugs",
    "impact": "File descriptor exhaustion, WebSocket crashes, dashboard freezes, XSS vulnerabilities, memory leaks"
  },
  "bugs_to_fix": {
    "bug_01_resource_leak_client_session": {
      "severity": "CRITICAL",
      "file": "dashboard/backend/api/routes/aistack.py",
      "lines": "25-40",
      "problem": "Creates new aiohttp.ClientSession for EVERY request - file descriptor leak",
      "current_code": "async def fetch_with_fallback(url: str, fallback: Any = None) -> Any:\n    try:\n        async with aiohttp.ClientSession(timeout=REQUEST_TIMEOUT) as session:",
      "why_broken": "Under load (1000 req), creates 1000 sessions = 1000+ file descriptors. OS limit ~1024. Server crashes with 'Too many open files'",
      "required_fix": "Create class AIStackRoutes with __init__ and setup/cleanup methods. ONE session shared across all requests",
      "exact_implementation": "# At top of file\nclass AIStackRoutes:\n    def __init__(self):\n        self.session: Optional[ClientSession] = None\n    \n    async def setup(self):\n        if not self.session:\n            self.session = aiohttp.ClientSession(timeout=REQUEST_TIMEOUT)\n    \n    async def cleanup(self):\n        if self.session:\n            await self.session.close()\n            self.session = None\n    \n    async def fetch_with_fallback(self, url: str, fallback: Any = None) -> Any:\n        if not self.session:\n            await self.setup()\n        try:\n            async with self.session.get(url) as resp:\n                # ... rest of function",
      "integration": "In main.py startup: await aistack_routes.setup(); In shutdown: await aistack_routes.cleanup()",
      "test_command": "for i in {1..1000}; do curl -s http://localhost:8889/api/stats/learning & done; lsof -p $(pgrep -f uvicorn) | wc -l",
      "test_expected": "File descriptor count < 150 (not 1000+)",
      "verification": "grep 'class AIStackRoutes' dashboard/backend/api/routes/aistack.py"
    },
    "bug_02_race_condition_websockets": {
      "severity": "CRITICAL",
      "file": "dashboard/backend/api/main.py",
      "lines": "27, 110, 120, 124-125, 137, 149",
      "problem": "Global active_connections list modified from multiple coroutines without locks",
      "current_code": "active_connections: List[WebSocket] = []  # Line 27\n...\nactive_connections.append(websocket)  # Line 110\n...\nactive_connections.remove(websocket)  # Line 120, 125\n...\nfor connection in active_connections:  # Line 137 - RACE!",
      "why_broken": "Thread A iterates over list while Thread B removes item = RuntimeError: list changed during iteration. Happens at ~10+ concurrent WebSockets",
      "required_fix": "Add asyncio.Lock(), wrap ALL access with 'async with lock:'",
      "exact_implementation": "import asyncio\n\nactive_connections: List[WebSocket] = []\nconnections_lock = asyncio.Lock()  # ADD THIS\n\n# Line 110:\nasync with connections_lock:\n    active_connections.append(websocket)\n\n# Lines 120, 125:\nasync with connections_lock:\n    active_connections.remove(websocket)\n\n# Line 137:\nasync with connections_lock:\n    for connection in active_connections.copy():  # Use copy() for safety\n        try:\n            await connection.send_json(...)\n        except:\n            disconnected.append(connection)\n\n# After loop:\nif disconnected:\n    async with connections_lock:\n        for conn in disconnected:\n            if conn in active_connections:\n                active_connections.remove(conn)",
      "test_command": "python3 -c \"import websocket, threading; [threading.Thread(target=lambda: websocket.create_connection('ws://localhost:8889/ws/metrics')).start() for _ in range(100)]\"",
      "test_expected": "No RuntimeError crash, all 100 connections handled",
      "verification": "grep 'connections_lock = asyncio.Lock' dashboard/backend/api/main.py"
    },
    "bug_03_event_loop_blocking": {
      "severity": "CRITICAL",
      "file": "dashboard/backend/api/services/metrics_collector.py",
      "lines": "139-183",
      "problem": "subprocess.run() is SYNCHRONOUS, blocks async event loop for 5+ seconds",
      "current_code": "result = subprocess.run(\n    [\"podman\", \"ps\", \"--format\", \"{{.Names}}\"],\n    capture_output=True,\n    text=True,\n    timeout=5  # BLOCKS for up to 5 seconds!\n)",
      "why_broken": "While waiting for podman, entire event loop pauses. WebSocket heartbeats timeout, metrics freeze, dashboard appears frozen every 2 seconds",
      "required_fix": "Use asyncio.to_thread() to run subprocess in thread pool",
      "exact_implementation": "import asyncio\n\nresult = await asyncio.to_thread(\n    subprocess.run,\n    [\"podman\", \"ps\", \"--format\", \"{{.Names}}\"],\n    capture_output=True,\n    text=True,\n    timeout=5\n)",
      "apply_to_all": "Find ALL subprocess.run() calls in file (search for 'subprocess.run'), wrap with asyncio.to_thread",
      "test_command": "Open dashboard, watch WebSocket messages. Should receive update every 2s consistently (not pause)",
      "test_expected": "WebSocket messages arrive every 2.0s ±0.1s, no 7+ second gaps",
      "verification": "grep 'asyncio.to_thread' dashboard/backend/api/services/metrics_collector.py | wc -l",
      "verification_expected": "At least 3 (one per subprocess.run call)"
    },
    "bug_04_xss_vulnerability": {
      "severity": "HIGH (Security)",
      "file": "dashboard.html",
      "lines": "3785",
      "problem": "Dependency name inserted into innerHTML without escaping - XSS attack vector",
      "current_code": "html += `\n    <div class=\"data-item\">\n        <div class=\"data-label\">${dep.name}</div>",
      "why_broken": "If API returns dep.name = '<script>alert(document.cookie)</script>', it executes JavaScript, stealing cookies",
      "required_fix": "Create escapeHtml() function, use it for ALL user-controlled data",
      "exact_implementation": "// Add at top of <script> section:\nfunction escapeHtml(unsafe) {\n    if (!unsafe) return '';\n    const div = document.createElement('div');\n    div.textContent = unsafe;\n    return div.innerHTML;\n}\n\n// Line 3785:\nhtml += `\n    <div class=\"data-item\">\n        <div class=\"data-label\">${escapeHtml(dep.name)}</div>\n        <div class=\"data-value\">\n            <span class=\"status-badge ${statusClass}\">${statusIcon} ${escapeHtml(dep.status)}</span>",
      "find_all_innerHTML": "Search dashboard.html for ALL uses of ${variable} inside HTML strings, escape them",
      "test_command": "Mock API to return dep.name = '<script>alert(1)</script>', verify it displays as text (not executes)",
      "test_expected": "Dashboard shows literal text '<script>alert(1)</script>', alert does NOT fire",
      "verification": "grep 'function escapeHtml' dashboard.html && grep 'escapeHtml(dep.name)' dashboard.html"
    },
    "bug_05_memory_leak_intervals": {
      "severity": "HIGH",
      "file": "dashboard.html",
      "lines": "3821, 4092",
      "problem": "setInterval() never cleared - each page reload creates duplicate timers",
      "current_code": "// Line 3821:\nsetInterval(refreshAIDBHealth, 30000);\n\n// Line 4092:\nsetTimeout(refreshAIDBHealth, 2000);",
      "why_broken": "User refreshes page 10x = 10 intervals running simultaneously. After 100 refreshes: 100 timers eating memory, 100 concurrent API calls every 30s",
      "required_fix": "Store interval ID, clear before creating new one",
      "exact_implementation": "// At top of script:\nlet aidbRefreshInterval = null;\n\n// Line 3821:\nif (aidbRefreshInterval) {\n    clearInterval(aidbRefreshInterval);\n}\naidbRefreshInterval = setInterval(refreshAIDBHealth, 30000);\n\n// For ALL setInterval calls in file, apply same pattern\n// Find with: grep -n 'setInterval' dashboard.html",
      "test_command": "Refresh dashboard 10 times, count active timers in DevTools Performance tab",
      "test_expected": "Only 1 of each interval type running (not 10)",
      "verification": "grep 'if.*clearInterval' dashboard.html | wc -l",
      "verification_expected": "At least 3 (one per interval type)"
    },
    "bug_06_no_fetch_timeout": {
      "severity": "CRITICAL",
      "file": "dashboard.html",
      "lines": "3702-3705",
      "problem": "fetch() has NO timeout - hangs forever if service is slow/hung",
      "current_code": "fetch(`${baseUrl}/health/live`).then(r => r.json()).catch(() => null),",
      "why_broken": "AIDB hangs (not closed connection, just slow). Fetch waits forever. Every 30s, another hanging request. After 10 min: 20 hanging requests, browser connection pool exhausted",
      "required_fix": "Use AbortController with 5s timeout for ALL fetch calls",
      "exact_implementation": "// Create helper function:\nfunction fetchWithTimeout(url, timeout = 5000) {\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), timeout);\n    \n    return fetch(url, { signal: controller.signal })\n        .finally(() => clearTimeout(timeoutId));\n}\n\n// Line 3702-3705:\nconst [liveness, readiness, startup, detailed] = await Promise.all([\n    fetchWithTimeout(`${baseUrl}/health/live`).then(r => r.json()).catch(() => null),\n    fetchWithTimeout(`${baseUrl}/health/ready`).then(r => r.json()).catch(() => null),\n    fetchWithTimeout(`${baseUrl}/health/startup`).then(r => r.json()).catch(() => null),\n    fetchWithTimeout(`${baseUrl}/health/detailed`).then(r => r.json()).catch(() => null)\n]);",
      "apply_to_all_fetches": "Find ALL fetch() calls, replace with fetchWithTimeout()",
      "test_command": "podman stop local-ai-aidb; refresh dashboard",
      "test_expected": "Error appears within 5 seconds (not hang forever)",
      "verification": "grep 'function fetchWithTimeout' dashboard.html && grep -c 'fetchWithTimeout(' dashboard.html",
      "verification_expected": "Function exists, used at least 10 times"
    },
    "bug_07_cors_wildcard": {
      "severity": "HIGH (Security)",
      "file": "scripts/dashboard-api-server.py",
      "lines": "309",
      "problem": "Access-Control-Allow-Origin: * allows ANY website to call API",
      "current_code": "response.headers['Access-Control-Allow-Origin'] = '*'",
      "why_broken": "Attacker hosts evil.com with JavaScript that calls your API, steals data via CORS",
      "required_fix": "Whitelist specific origins only",
      "exact_implementation": "allowed_origins = [\n    'http://localhost:8888',\n    'http://127.0.0.1:8888',\n    'http://localhost:8890',\n    'http://127.0.0.1:8890'\n]\n\norigin = request.headers.get('Origin', '')\nif origin in allowed_origins:\n    response.headers['Access-Control-Allow-Origin'] = origin\nelse:\n    response.headers['Access-Control-Allow-Origin'] = 'http://localhost:8888'  # default",
      "also_check": "dashboard/backend/api/main.py CORS config - should already be correct",
      "test_command": "curl -H 'Origin: http://evil.com' http://localhost:8889/api/health; check response headers",
      "test_expected": "Access-Control-Allow-Origin does NOT echo evil.com",
      "verification": "grep 'allowed_origins = \\[' scripts/dashboard-api-server.py"
    },
    "bug_08_query_injection": {
      "severity": "HIGH (Security)",
      "file": "dashboard/backend/api/routes/aistack.py",
      "lines": "149-154",
      "problem": "Prometheus query parameter passed unsanitized - DoS vector",
      "current_code": "@router.get(\"/prometheus/query\")\nasync def proxy_prometheus_query(query: str) -> Dict[str, Any]:\n    prom_url = f\"http://localhost:9090/api/v1/query?query={query}\"",
      "why_broken": "Attacker sends query=rate(metric[999999d]) - forces Prometheus to compute 999,999 days of data, crashes it",
      "required_fix": "Validate query length, URL-encode, add rate limit",
      "exact_implementation": "from urllib.parse import quote\nimport time\nfrom collections import defaultdict\n\n# Module level:\nquery_rate_limit = defaultdict(list)  # IP -> [timestamps]\nMAX_QUERIES_PER_MINUTE = 10\nMAX_QUERY_LENGTH = 500\n\n@router.get(\"/prometheus/query\")\nasync def proxy_prometheus_query(query: str, request: Request) -> Dict[str, Any]:\n    # Validate length\n    if len(query) > MAX_QUERY_LENGTH:\n        raise HTTPException(status_code=400, detail=f\"Query too long (max {MAX_QUERY_LENGTH} chars)\")\n    \n    # Rate limit by IP\n    client_ip = request.client.host\n    now = time.time()\n    query_rate_limit[client_ip] = [t for t in query_rate_limit[client_ip] if now - t < 60]\n    if len(query_rate_limit[client_ip]) >= MAX_QUERIES_PER_MINUTE:\n        raise HTTPException(status_code=429, detail=\"Rate limit exceeded\")\n    query_rate_limit[client_ip].append(now)\n    \n    # URL encode\n    prom_url = f\"http://prometheus:9090/api/v1/query?query={quote(query)}\"",
      "test_command": "curl 'http://localhost:8889/api/prometheus/query?query=rate(foo[999999d])'",
      "test_expected": "Returns 400 Bad Request (doesn't forward to Prometheus)",
      "verification": "grep 'MAX_QUERY_LENGTH' dashboard/backend/api/routes/aistack.py"
    },
    "bug_09_untrusted_response_size": {
      "severity": "HIGH (Reliability)",
      "file": "dashboard/backend/api/routes/aistack.py",
      "lines": "72-115 (get_health_aggregate)",
      "problem": "Service responses inserted directly into details without size validation",
      "current_code": "health_checks[\"aidb\"] = {\n    \"status\": aidb_health.get(\"status\", \"unknown\") if aidb_health else \"unhealthy\",\n    \"details\": aidb_health or {}  # Could be GIGABYTES",
      "why_broken": "Malicious/buggy service returns 1GB JSON. API tries to load it all into memory, OOM crash",
      "required_fix": "Limit response size, validate structure, whitelist fields",
      "exact_implementation": "# In fetch_with_fallback:\nMAX_RESPONSE_SIZE = 1_048_576  # 1MB\n\nasync with self.session.get(url) as resp:\n    if resp.status == 200:\n        # Check content length\n        content_length = resp.headers.get('Content-Length')\n        if content_length and int(content_length) > MAX_RESPONSE_SIZE:\n            logger.error(f\"Response too large: {content_length} bytes\")\n            return fallback\n        \n        # Read with size limit\n        text = await resp.text()\n        if len(text) > MAX_RESPONSE_SIZE:\n            logger.error(f\"Response exceeded {MAX_RESPONSE_SIZE} bytes\")\n            return fallback\n        \n        return json.loads(text)\n\n# In get_health_aggregate, whitelist fields:\nhealth_checks[\"aidb\"] = {\n    \"status\": aidb_health.get(\"status\", \"unknown\"),\n    \"details\": {\n        \"version\": aidb_health.get(\"version\"),\n        \"uptime\": aidb_health.get(\"uptime\"),\n        # Only safe fields, not entire response\n    }\n}",
      "test_command": "Mock service to return 10MB response, verify API rejects it",
      "test_expected": "API logs error, returns fallback (doesn't crash)",
      "verification": "grep 'MAX_RESPONSE_SIZE' dashboard/backend/api/routes/aistack.py"
    },
    "bug_10_null_safety_charat": {
      "severity": "HIGH",
      "file": "dashboard.html",
      "lines": "3755",
      "problem": "Calls .charAt() on potentially undefined status - crashes",
      "current_code": "const status = healthData.status;\nel.textContent = status.charAt(0).toUpperCase() + status.slice(1);",
      "why_broken": "API returns {} empty object. healthData.status is undefined. .charAt() on undefined throws TypeError",
      "required_fix": "Add null checks, type coercion, fallback",
      "exact_implementation": "const status = healthData?.status || 'unknown';\nconst statusStr = typeof status === 'string' ? status : String(status);\nel.textContent = statusStr.charAt(0).toUpperCase() + statusStr.slice(1);",
      "apply_pattern": "Search for ALL .charAt(), .slice(), .toLowerCase() calls on variables from API, add null checks",
      "test_command": "Mock API to return {}, verify dashboard doesn't crash",
      "test_expected": "Shows 'Unknown' status (doesn't throw TypeError)",
      "verification": "grep 'healthData?.status' dashboard.html"
    },
    "bug_11_concurrent_refresh_guard": {
      "severity": "MEDIUM",
      "file": "dashboard.html",
      "lines": "3697-3743 (refreshAIDBHealth function)",
      "problem": "No guard against concurrent refreshAIDBHealth() calls - race condition",
      "current_code": "async function refreshAIDBHealth() {\n    try {\n        const baseUrl = '/aidb';",
      "why_broken": "If refresh takes 15s and interval is 30s, second call starts while first still running. Double API calls, overlapping DOM updates",
      "required_fix": "Add isRefreshing flag guard",
      "exact_implementation": "let isRefreshingAIDB = false;\n\nasync function refreshAIDBHealth() {\n    if (isRefreshingAIDB) {\n        console.log('Refresh already in progress, skipping');\n        return;\n    }\n    \n    isRefreshingAIDB = true;\n    try {\n        const baseUrl = '/aidb';\n        // ... rest of function\n    } catch (error) {\n        console.error('Error refreshing AIDB health:', error);\n    } finally {\n        isRefreshingAIDB = false;\n    }\n}",
      "apply_to_all_refresh_functions": "Find all async refresh functions, add same guard pattern",
      "test_command": "Call refreshAIDBHealth() 10 times rapidly in console, check network tab",
      "test_expected": "Only 1 request in flight at a time",
      "verification": "grep 'isRefreshingAIDB' dashboard.html"
    },
    "bug_12_http_status_check_before_json": {
      "severity": "HIGH",
      "file": "dashboard.html",
      "lines": "3702-3705",
      "problem": "Calls .json() without checking r.ok - 503 responses cause parse errors",
      "current_code": "fetch(`${baseUrl}/health/live`).then(r => r.json()).catch(() => null),",
      "why_broken": "Service returns 503 Service Unavailable with HTML error page. .json() tries to parse HTML, throws SyntaxError. Catch returns null, user sees nothing",
      "required_fix": "Check r.ok before calling r.json(), throw descriptive error",
      "exact_implementation": "fetchWithTimeout(`${baseUrl}/health/live`)\n    .then(r => {\n        if (!r.ok) {\n            throw new Error(`HTTP ${r.status}: ${r.statusText}`);\n        }\n        return r.json();\n    })\n    .catch(err => {\n        console.warn('Failed to fetch health/live:', err.message);\n        return null;\n    })",
      "apply_to_all_json_calls": "Find ALL .then(r => r.json()), add r.ok check",
      "test_command": "Mock service to return 503, verify dashboard logs error (doesn't silent fail)",
      "test_expected": "Console shows 'HTTP 503: Service Unavailable', not 'Unexpected token'",
      "verification": "grep 'if (!r.ok)' dashboard.html | wc -l",
      "verification_expected": "At least 10 (one per fetch → json chain)"
    }
  },
  "implementation_order": [
    "1. Fix bug_01 (resource leak) - CRITICAL",
    "2. Fix bug_02 (race condition) - CRITICAL",
    "3. Fix bug_03 (event loop blocking) - CRITICAL",
    "4. Fix bug_06 (fetch timeout) - CRITICAL",
    "5. Fix bug_04 (XSS) - HIGH security",
    "6. Fix bug_07 (CORS) - HIGH security",
    "7. Fix bug_08 (query injection) - HIGH security",
    "8. Fix bug_09 (response size) - HIGH reliability",
    "9. Fix bug_05 (memory leak intervals) - HIGH",
    "10. Fix bug_10 (null safety) - HIGH",
    "11. Fix bug_11 (concurrent refresh) - MEDIUM",
    "12. Fix bug_12 (HTTP status check) - HIGH"
  ],
  "testing_checklist": [
    "Send 1000 requests, file descriptors < 150",
    "Open 100 WebSockets, no crash",
    "Metrics collect without freezing",
    "XSS attempt displays as text",
    "Refresh page 10x, 1 interval running",
    "Stop AIDB, error within 5s",
    "CORS from evil.com rejected",
    "999999d query rejected",
    "10MB response rejected",
    "Empty {} response doesn't crash",
    "Concurrent refresh only 1 request",
    "503 response logs error cleanly"
  ],
  "success_criteria": {
    "all_tests_must_pass": "Run ALL 12 tests above, ALL must pass",
    "no_regressions": "Existing functionality still works",
    "code_quality": "All fixes follow patterns shown, no shortcuts"
  }
}
