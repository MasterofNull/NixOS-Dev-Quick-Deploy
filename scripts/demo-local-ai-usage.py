#!/usr/bin/env python3
"""
Demonstration: Proper Local AI Stack Usage
Shows how AI agents SHOULD interact with the hybrid learning system
"""

import json
import os
import requests
import time
from datetime import datetime
from typing import Dict, List, Any

# Service endpoints
SERVICE_HOST = os.getenv("SERVICE_HOST", "localhost")
AIDB_MCP = os.getenv("AIDB_URL", "http://localhost")
HYBRID_COORDINATOR = os.getenv("HYBRID_URL", "http://localhost")
LLAMA_CPP = os.getenv("LLAMA_URL", "http://localhost")
QDRANT = os.getenv("QDRANT_URL", "http://localhost")

class LocalAIClient:
    """Proper client for local AI stack usage"""

    def __init__(self):
        self.aidb_url = AIDB_MCP
        self.hybrid_url = HYBRID_COORDINATOR
        self.session = requests.Session()

    def query_with_rag(self, query: str, use_local: bool = True) -> Dict[str, Any]:
        """
        Query with RAG context retrieval
        This is how agents SHOULD query the system
        """
        print(f"\nðŸ“ Query: {query}")
        print(f"   Routing: {'LOCAL' if use_local else 'REMOTE'}")

        # Step 1: Retrieve context from Qdrant via AIDB
        context = self._get_rag_context(query)
        print(f"   ðŸ“š Retrieved {len(context.get('documents', []))} context documents")

        # Step 2: Route through hybrid coordinator
        response = self._route_query(query, context, use_local)

        # Step 3: Record telemetry
        self._record_telemetry(query, use_local, response)

        return response

    def _get_rag_context(self, query: str) -> Dict[str, Any]:
        """Retrieve relevant context from knowledge base"""
        try:
            response = self.session.get(
                f"{self.aidb_url}/documents",
                params={"search": query, "limit": 3},
                timeout=5
            )
            if response.status_code == 200:
                return response.json()
            return {"documents": []}
        except Exception as e:
            print(f"   âš ï¸ RAG retrieval failed: {e}")
            return {"documents": []}

    def _route_query(self, query: str, context: Dict, use_local: bool) -> Dict[str, Any]:
        """Route query through hybrid coordinator"""
        try:
            payload = {
                "query": query,
                "context": context,
                "force_local": use_local,
                "timestamp": datetime.now().isoformat()
            }

            response = self.session.post(
                f"{self.hybrid_url}/query",
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                print(f"   âœ… Response received (tokens: {result.get('tokens_used', 'N/A')})")
                return result
            else:
                print(f"   âŒ Hybrid coordinator error: {response.status_code}")
                return {"error": "coordinator_error", "status": response.status_code}

        except Exception as e:
            print(f"   âŒ Query routing failed: {e}")
            return {"error": str(e)}

    def _record_telemetry(self, query: str, used_local: bool, response: Dict):
        """Record telemetry event for continuous learning"""
        try:
            telemetry = {
                "timestamp": datetime.now().isoformat(),
                "event_type": "query_routed",
                "source": "demo_client",
                "metadata": {
                    "query": query[:100],  # Truncate for privacy
                    "decision": "local" if used_local else "remote",
                    "tokens_saved": response.get("tokens_saved", 0),
                    "success": "error" not in response
                }
            }

            # This would normally go through AIDB, but we'll write directly for demo
            print(f"   ðŸ“Š Telemetry recorded: {telemetry['metadata']['decision']}")

        except Exception as e:
            print(f"   âš ï¸ Telemetry recording failed: {e}")


def demonstrate_proper_usage():
    """Demonstrate how AI agents should use the local stack"""

    print("=" * 70)
    print("LOCAL AI STACK USAGE DEMONSTRATION")
    print("=" * 70)

    client = LocalAIClient()

    # Test queries (simple to complex)
    test_queries = [
        # Simple queries (should use local LLM)
        ("How do I check running containers in Podman?", True),
        ("List all Qdrant collections", True),
        ("What is the NixOS configuration file path?", True),

        # Medium complexity (could go either way)
        ("Explain the hybrid learning architecture", True),
        ("How does the value scoring algorithm work?", True),

        # Complex queries (might need remote)
        ("Design a distributed machine learning pipeline with fault tolerance", False),
    ]

    results = []
    total_tokens_saved = 0

    for query, use_local in test_queries:
        result = client.query_with_rag(query, use_local)
        results.append({
            "query": query,
            "local": use_local,
            "success": "error" not in result,
            "tokens_saved": result.get("tokens_saved", 0)
        })
        total_tokens_saved += result.get("tokens_saved", 0)
        time.sleep(1)  # Rate limiting

    # Summary
    print("\n" + "=" * 70)
    print("DEMONSTRATION SUMMARY")
    print("=" * 70)

    successful = sum(1 for r in results if r["success"])
    local_queries = sum(1 for r in results if r["local"])

    print(f"\nQueries executed: {len(results)}")
    print(f"Successful: {successful}/{len(results)}")
    print(f"Routed locally: {local_queries}/{len(results)} ({local_queries/len(results)*100:.0f}%)")
    print(f"Total tokens saved: {total_tokens_saved:,}")

    if total_tokens_saved > 0:
        cost_per_1k = 0.015  # Claude pricing
        savings = (total_tokens_saved / 1000) * cost_per_1k
        print(f"Cost savings: ${savings:.2f}")

    print("\nðŸ’¡ This is how AI agents SHOULD interact with your local stack!")
    print("   - All queries routed through hybrid coordinator")
    print("   - RAG context retrieval from knowledge base")
    print("   - Telemetry recorded for continuous learning")
    print("   - Token savings tracked and reported")


if __name__ == "__main__":
    demonstrate_proper_usage()
