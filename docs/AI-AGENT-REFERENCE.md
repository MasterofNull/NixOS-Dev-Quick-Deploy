# AI Agent Quick Reference - NixOS Hybrid Learning System

**Purpose**: Fast navigation to task-relevant information for remote AI agents
**Goal**: Reduce context overhead by loading only what's needed for current task
**Principle**: Continuous learning with local context augmentation

---

## ðŸŽ¯ Quick Task Navigation

**Choose your task category below** - only load the documents you need:

### ðŸš€ Getting Started
- [System Overview](/docs/agent-guides/00-SYSTEM-OVERVIEW.md) - What this system is and does
- [Quick Start](/docs/agent-guides/01-QUICK-START.md) - Get up and running fast
- [Service Status](/docs/agent-guides/02-SERVICE-STATUS.md) - Check what's running

### ðŸ”§ Development Tasks
- [NixOS Configuration](/docs/agent-guides/10-NIXOS-CONFIG.md) - Modify system/home configs
- [Container Management](/docs/agent-guides/11-CONTAINER-MGMT.md) - Podman/Docker operations
- [Debugging & Logs](/docs/agent-guides/12-DEBUGGING.md) - Find and fix issues

### ðŸ¤– AI & LLM Operations
- [Local LLM Usage](/docs/agent-guides/20-LOCAL-LLM-USAGE.md) - Use llama.cpp/Ollama for inference
- [RAG & Context Augmentation](/docs/agent-guides/21-RAG-CONTEXT.md) - Reduce remote API costs
- [Continuous Learning](/docs/agent-guides/22-CONTINUOUS-LEARNING.md) - Store learnings & improve

### ðŸ’¾ Data & Storage
- [Qdrant Vector DB](/docs/agent-guides/30-QDRANT-OPERATIONS.md) - Search/store embeddings
- [PostgreSQL Database](/docs/agent-guides/31-POSTGRES-OPS.md) - Structured data storage
- [Error Logging](/docs/agent-guides/32-ERROR-LOGGING.md) - Track and learn from failures

### ðŸ”„ Workflows
- [Hybrid Workflow](/docs/agent-guides/40-HYBRID-WORKFLOW.md) - Local + Remote agent coordination
- [Value Scoring](/docs/agent-guides/41-VALUE-SCORING.md) - Identify high-value interactions
- [Pattern Extraction](/docs/agent-guides/42-PATTERN-EXTRACTION.md) - Reusable solutions

---

## ðŸ“Š System Architecture (High-Level)

```
Remote Agent (You)
    â†“ Query
    â†“
Local Context Layer (Qdrant + PostgreSQL)
    â†“ Augmented Query (with local context)
    â†“
Local LLM (llama.cpp/Ollama) OR Remote API
    â†“ Response
    â†“
Learning System (stores high-value data)
    â†“
Improved Local Context (for next query)
```

**Key Benefit**: Use local context to reduce your token usage by 30-50%

---

## ðŸŽ“ Continuous Learning Principles

**Always follow these principles** when working on tasks:

### 1. **Store Successes**
When a solution works:
```python
# Pseudo-code for what the system does
store_solution({
    "query": "What was the question?",
    "solution": "What worked?",
    "context": "What was relevant?",
    "outcome": "success",
    "value_score": calculate_value(complexity, reusability, novelty)
})
```

### 2. **Store Failures**
When something fails:
```python
store_error({
    "error": "What failed?",
    "attempted_solution": "What was tried?",
    "root_cause": "Why did it fail?",
    "correct_solution": "What actually worked?"
})
```

### 3. **Extract Patterns**
After successful interactions:
- Identify reusable patterns
- Store in `skills-patterns` collection
- Future agents can reference these

### 4. **Check Context First**
Before making remote API calls:
1. Search Qdrant for similar past queries
2. Check error-solutions for known issues
3. Review best-practices for the task type
4. Only use remote API if local context insufficient

---

## ðŸš€ Common Operations (Quick Reference)

### Check System Status
```bash
./scripts/hybrid-ai-stack.sh status
```

### Query Local LLM
```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen-coder", "messages": [{"role": "user", "content": "..."}]}'
```

### Search Vector DB (Python)
```python
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
results = client.search(
    collection_name="codebase-context",
    query_vector=embedding,
    limit=5
)
```

### Store Learning (Python)
```python
client.upsert(
    collection_name="skills-patterns",
    points=[{
        "id": unique_id,
        "vector": embedding,
        "payload": {
            "pattern": "description",
            "example": "code or solution",
            "value_score": 0.85
        }
    }]
)
```

---

## ðŸ“ Service Endpoints

| Service | Port | Health Check | Purpose |
|---------|------|--------------|---------|
| Qdrant | 6333 | `/healthz` | Vector database |
| Ollama | 11434 | `/api/tags` | Embeddings |
| llama.cpp | 8080 | `/health` | GGUF inference |
| Open WebUI | 3001 | `/` | Chat interface |
| PostgreSQL | 5432 | `pg_isready` | Structured data |
| Redis | 6379 | `PING` | Caching |

---

## ðŸ—‚ï¸ Data Collections (Qdrant)

### Collections Available

1. **codebase-context** - Code snippets, function definitions, project structure
2. **skills-patterns** - Reusable solutions, patterns, best practices
3. **error-solutions** - Known errors and their fixes
4. **best-practices** - Curated guidelines for tasks
5. **interaction-history** - All past interactions with outcomes

### When to Use Each Collection

- **Debugging?** â†’ Check `error-solutions` first
- **Implementing feature?** â†’ Search `skills-patterns` and `best-practices`
- **Understanding code?** â†’ Query `codebase-context`
- **Learning from history?** â†’ Review `interaction-history`

---

## ðŸ’¡ Task-Specific Workflows

### Workflow: Fix a Bug

1. **Search `error-solutions`** for similar error
2. If found â†’ Apply known solution â†’ Store success
3. If not found â†’ Debug â†’ Store new solution when fixed
4. Extract pattern if error type is common

**See**: [Debugging Guide](/docs/agent-guides/12-DEBUGGING.md)

### Workflow: Implement New Feature

1. **Search `skills-patterns`** for similar implementations
2. **Check `best-practices`** for this feature type
3. Implement using local LLM if possible (cheaper)
4. Store successful patterns for future use
5. Calculate value score for learning system

**See**: [Development Workflow](/docs/agent-guides/40-HYBRID-WORKFLOW.md)

### Workflow: NixOS Configuration Change

1. **Search `codebase-context`** for similar config patterns
2. Use local LLM to validate syntax
3. Test in isolation first
4. Store working configuration in Qdrant
5. Document any gotchas in `best-practices`

**See**: [NixOS Configuration Guide](/docs/agent-guides/10-NIXOS-CONFIG.md)

---

## ðŸŽ¯ Context Reduction Strategies

### Strategy 1: Search Before Asking
```python
# Instead of loading full docs, search for specific info
results = search_qdrant("how to configure gnome-keyring")
if results.score > 0.8:
    use_local_answer(results)
else:
    ask_remote_api()  # Only if local context insufficient
```

### Strategy 2: Incremental Loading
```markdown
# Load only what you need:
1. Read AI-AGENT-REFERENCE.md (this file) - 500 tokens
2. Identify task category
3. Load ONLY that category's guide - 1000-2000 tokens
4. Total: ~2500 tokens vs 20000+ for full docs
```

### Strategy 3: Use Local LLM for Simple Tasks
```bash
# Use llama.cpp for:
- Code explanation
- Syntax checking
- Simple refactoring
- Pattern matching

# Use Remote API for:
- Complex architectural decisions
- Novel problem solving
- Multi-step planning
```

**See**: [RAG & Context Guide](/docs/agent-guides/21-RAG-CONTEXT.md)

---

## ðŸ“š Complete Documentation Index

### Core System Docs
- [UNIFIED-AI-STACK.md](UNIFIED-AI-STACK.md) - Complete architecture
- [DEPLOYMENT-STATUS.md](/docs/archive/DEPLOYMENT-STATUS.md) - Current status
- [HYBRID-AI-SYSTEM-GUIDE.md](HYBRID-AI-SYSTEM-GUIDE.md) - Implementation guide

### Agent-Specific Guides (Focused)
- `docs/agent-guides/00-SYSTEM-OVERVIEW.md` - High-level overview
- `docs/agent-guides/01-QUICK-START.md` - Get started fast
- `docs/agent-guides/02-SERVICE-STATUS.md` - Check services
- `docs/agent-guides/10-NIXOS-CONFIG.md` - NixOS configuration
- `docs/agent-guides/11-CONTAINER-MGMT.md` - Container operations
- `docs/agent-guides/12-DEBUGGING.md` - Debug & logs
- `docs/agent-guides/20-LOCAL-LLM-USAGE.md` - Use local LLMs
- `docs/agent-guides/21-RAG-CONTEXT.md` - RAG & context augmentation
- `docs/agent-guides/22-CONTINUOUS-LEARNING.md` - Learning workflow
- `docs/agent-guides/30-QDRANT-OPERATIONS.md` - Vector DB ops
- `docs/agent-guides/31-POSTGRES-OPS.md` - Database ops
- `docs/agent-guides/32-ERROR-LOGGING.md` - Error tracking
- `docs/agent-guides/40-HYBRID-WORKFLOW.md` - Local+Remote coordination
- `docs/agent-guides/41-VALUE-SCORING.md` - Value calculation
- `docs/agent-guides/42-PATTERN-EXTRACTION.md` - Pattern mining

### MCP Server Catalogs
- [ai-knowledge-base/mcp-servers/](ai-knowledge-base/mcp-servers/) - Available MCP servers by category

---

## ðŸ”‘ Key File Locations

```
NixOS-Dev-Quick-Deploy/
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ configuration.nix      # System config (source of truth)
â”‚   â””â”€â”€ home.nix               # User config (source of truth)
â”œâ”€â”€ ai-stack/
â”‚   â”œâ”€â”€ compose/
â”‚   â”‚   â””â”€â”€ docker-compose.yml # AI stack definition (single source)
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ index.html         # System monitoring dashboard
â”‚   â””â”€â”€ mcp-servers/
â”‚       â””â”€â”€ hybrid-coordinator/ # Learning system MCP server
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ hybrid-ai-stack.sh     # Main AI stack manager
â”‚   â””â”€â”€ setup-hybrid-learning-auto.sh  # Automated setup
â””â”€â”€ docs/
    â””â”€â”€ agent-guides/          # Focused agent documentation
```

---

## âš¡ Emergency Commands

```bash
# System completely broken?
./nixos-quick-deploy.sh --rollback

# AI stack not responding?
./scripts/hybrid-ai-stack.sh restart

# Need to check logs?
./scripts/hybrid-ai-stack.sh logs

# Qdrant down?
podman restart local-ai-qdrant

# Full system status?
./scripts/hybrid-ai-stack.sh status
```

---

## ðŸ“Š Dashboard & Monitoring

**Open Dashboard**: `firefox ai-stack/dashboard/index.html`

The dashboard shows:
- âœ… Service health (real-time)
- ðŸ“Š Learning metrics (interactions, patterns, value)
- ðŸ”„ Federation status (if multi-node)
- ðŸ“š Quick links to all documentation

**See**: [SYSTEM-DASHBOARD-README.md](SYSTEM-DASHBOARD-README.md)

---

## ðŸŽ“ Learning System Flow

```
1. Receive Task
    â†“
2. Search Local Context (Qdrant)
    â†“
3. Augment Query with Relevant Context
    â†“
4. Execute with Local LLM (if simple) OR Remote API (if complex)
    â†“
5. Store Outcome + Context
    â†“
6. Calculate Value Score
    â†“
7. If High Value â†’ Extract Pattern â†’ Store for Reuse
    â†“
8. Next Task Benefits from This Learning
```

---

## ðŸ’¬ Usage Examples

### Example 1: Fix GNOME Keyring Error
```python
# 1. Search for similar errors
results = search_qdrant("gnome keyring error OS keyring")

# 2. If found (score > 0.8), use that solution
if results[0].score > 0.8:
    apply_solution(results[0].payload["solution"])
else:
    # 3. Debug and find solution
    solution = debug_and_fix()
    # 4. Store for future
    store_solution("gnome-keyring-fix", solution, value_score=0.9)
```

### Example 2: NixOS Config Change
```python
# 1. Check best practices
practices = search_qdrant("nixos configuration best practices")

# 2. Search for similar configs
examples = search_qdrant("enable systemd service nixos")

# 3. Use local LLM to generate config
config = local_llm_generate(prompt=f"Based on {examples}, generate...")

# 4. Test and store
test_config(config)
store_pattern("systemd-service-pattern", config)
```

---

## ðŸš¦ Decision Tree: When to Use What

```
Task Received
    â”‚
    â”œâ”€ Simple/Repetitive? â†’ Use Local LLM (llama.cpp)
    â”‚
    â”œâ”€ Seen Before? â†’ Search Qdrant â†’ Apply Stored Solution
    â”‚
    â”œâ”€ Error/Bug? â†’ Check error-solutions â†’ Apply Known Fix
    â”‚
    â”œâ”€ New Implementation? â†’ Search patterns â†’ Use Best Practices
    â”‚
    â””â”€ Complex/Novel? â†’ Use Remote API â†’ Store Result for Learning
```

---

## ðŸ“– Next Steps

1. **New to the system?** â†’ Read [System Overview](/docs/agent-guides/00-SYSTEM-OVERVIEW.md)
2. **Ready to code?** â†’ Read [Quick Start](/docs/agent-guides/01-QUICK-START.md)
3. **Specific task?** â†’ Jump to relevant guide above
4. **Want full details?** â†’ See [UNIFIED-AI-STACK.md](UNIFIED-AI-STACK.md)

---

**Remember**: The goal is to load **only what you need** for your current task, not everything at once. Use this reference to navigate to the specific information required.

**Last Updated**: 2025-12-20
